{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import matplotlib\n",
    "import glob\n",
    "import operator\n",
    "import psutil\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, GlobalMaxPooling2D, BatchNormalization, Conv2D, MaxPooling2D, Flatten\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify Train Dir: /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus\n",
      "/home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/classify train/testing\n",
      "/home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/classify train/training\n",
      "/home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/classify train/validation\n"
     ]
    }
   ],
   "source": [
    "classify_train_dir = str(input(\"Classify Train Dir: \"))\n",
    "classify_train = os.path.join(classify_train_dir, 'classify train')\n",
    "\n",
    "    \n",
    "TRAINING_DIR = os.path.join(classify_train, 'training')\n",
    "VALIDATION_DIR = os.path.join(classify_train, 'validation')\n",
    "TESTING_DIR = os.path.join(classify_train, 'testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/classify train/training',\n",
       " '/home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/classify train/validation',\n",
       " '/home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/classify train/testing')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_DIR, VALIDATION_DIR, TESTING_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the initial learning rate: 0.0001\n",
      "Enter the maximum number of epochs: 100\n",
      "Enter batch size: 5\n"
     ]
    }
   ],
   "source": [
    "learning_rate = float(input(\"Enter the initial learning rate: \"))\n",
    "epoch = int(input(\"Enter the maximum number of epochs: \"))\n",
    "batch_size = int(input(\"Enter batch size: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter name of the characteristics folder: vgg19_1\n"
     ]
    }
   ],
   "source": [
    "char_name = str(input(\"Enter name of the characteristics folder: \"))\n",
    "\n",
    "char = os.path.join(classify_train_dir, char_name)\n",
    "\n",
    "if not os.path.exists(char):\n",
    "    os.mkdir(char)\n",
    "else:\n",
    "    replace = str(input(\"Folder already exists ! Do you want to replace it ?(Y/N) \"))\n",
    "    if replace.upper() == 'Y':      \n",
    "        shutil.rmtree(char)\n",
    "        os.mkdir(char)\n",
    "    elif replace.upper() == 'N':\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    return learning_rate * (0.1 ** int(epoch / 10))\n",
    "    \n",
    "best_model_address = os.path.join(char, 'best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 1 to monitor Validation Accuracy\n",
      "Press 2 to monitor Validation Loss\n",
      "Press 3 to monitor Training Accuracy\n",
      "Press 4 to monitor Training Loss\n",
      "4\n",
      "Enter number of epochs that will produce monitored quantity with no improvement after which training will be stopped: 100\n",
      "\n",
      "MONITORING TRAINING LOSS..........\n",
      "\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "Training will stop if Validation Accuracy doesn't show any improvements for 100 epcohs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "monitor = int(input(\"Press 1 to monitor Validation Accuracy\\nPress 2 to monitor Validation Loss\\nPress 3 to monitor Training Accuracy\\nPress 4 to monitor Training Loss\\n\"))\n",
    "patience = int(input('Enter number of epochs that will produce monitored quantity with no improvement after which training will be stopped: '))\n",
    "\n",
    "\n",
    "if monitor == 1:\n",
    "    metric = 'val_accuracy'\n",
    "    mode = 'max'\n",
    "    print(\"\\nMONITORING VALIDATION ACCURACY..........\\n\")\n",
    "\n",
    "elif monitor == 2:\n",
    "    metric = 'val_loss'\n",
    "    mode = 'min'\n",
    "    print(\"\\nMONITORING VALIDATION LOSS..........\\n\")\n",
    "\n",
    "elif monitor == 3:\n",
    "    metric = 'accuracy'\n",
    "    mode = 'max'\n",
    "    print(\"\\nMONITORING TRAINING ACCURACY..........\\n\")\n",
    "\n",
    "elif monitor == 4:\n",
    "    metric = 'loss'\n",
    "    mode = 'min'\n",
    "    print(\"\\nMONITORING TRAINING LOSS..........\\n\")\n",
    "\n",
    "callback = [keras.callbacks.LearningRateScheduler(lr_schedule, verbose = 1),\n",
    "            keras.callbacks.EarlyStopping(monitor = metric, min_delta = 0.001, patience = patience, verbose=1, mode = mode, restore_best_weights = True),\n",
    "            keras.callbacks.ModelCheckpoint(best_model_address, monitor = metric, verbose=1, save_best_only=True, save_weights_only=False, mode = mode , period=1)]\n",
    "\n",
    "print(\"\\nTraining will stop if Validation Accuracy doesn't show any improvements for \" + str(patience) + \" epcohs\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg19():\n",
    "    print(\"\\nTRAINING ON VGG19 MODEL:-\")\n",
    "\n",
    "    base_model = keras.applications.vgg19.VGG19(input_shape = dim, weights = 'imagenet', include_top = False)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(dense)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    predictions = Dense(output_layer, activation = output_activation)(x)\n",
    "\n",
    "    model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "    train_base_model = str(input(\"Do you want to train the base model of vgg19?(Y/N) \"))\n",
    "    if train_base_model.upper() == 'Y':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    elif train_base_model.upper() == 'N':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Binary Classification\n"
     ]
    }
   ],
   "source": [
    "class_no = len(os.listdir(TRAINING_DIR))\n",
    "\n",
    "if class_no > 2:\n",
    "    print(\"This is a \" + str(class_no) + \"-Class Classification\")\n",
    "    output_activation = 'softmax'\n",
    "    losses = 'categorical_crossentropy'\n",
    "    class_mode = 'categorical'\n",
    "    output_layer = class_no\n",
    "else:\n",
    "    print(\"This is a Binary Classification\")\n",
    "    output_activation = 'sigmoid'\n",
    "    losses = 'binary_crossentropy'\n",
    "    class_mode = 'binary'\n",
    "    output_layer = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_selection():\n",
    "    print(\"\\nSelect a optimizer which will reduce the loss of the model.\\n\")\n",
    "\n",
    "    optimizer_select = int(input(\"Press 1 to select Stochastic Gradient Descent\\nPress 2 to select RMSprop\\nPress 3 to select Adagrad\\nPress 4 to select Adadelta\\nPress 5 to select Adam\\nPress 6 to select Adamax\\nPress 7 to select Nadam\\n\"))\n",
    "\n",
    "    if optimizer_select == 1:\n",
    "        optimizer = SGD(lr = learning_rate, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "\n",
    "    elif optimizer_select == 2:\n",
    "        optimizer = RMSprop(learning_rate, rho = 0.9)\n",
    "\n",
    "    elif optimizer_select == 3:\n",
    "        optimizer = Adagrad(learning_rate)\n",
    "\n",
    "    elif optimizer_select == 4:\n",
    "        optimizer = Adadelta(learning_rate, rho = 0.95)\n",
    "\n",
    "    elif optimizer_select == 5:\n",
    "        optimizer = Adam(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\n",
    "\n",
    "    elif optimizer_select == 6:\n",
    "        optimizer = Adamax(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999)\n",
    "\n",
    "    elif optimizer_select == 7:\n",
    "        optimizer = Nadam(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999)\n",
    "   \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Dimension(H or W): 64\n"
     ]
    }
   ],
   "source": [
    "h = int(input(\"Image Dimension(H or W): \"))\n",
    "w = h\n",
    "dim = [h,w,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 485 images belonging to 2 classes.\n",
      "Found 56 images belonging to 2 classes.\n",
      "Found 60 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    class_mode = class_mode,\n",
    "                                                    target_size = (h,w),\n",
    "                                                    shuffle=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                              batch_size = batch_size,\n",
    "                                                              class_mode = class_mode,\n",
    "                                                              target_size = (h,w),\n",
    "                                                              shuffle=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "test_generator = test_datagen.flow_from_directory(TESTING_DIR,\n",
    "                                                  batch_size = batch_size,\n",
    "                                                  class_mode = class_mode,\n",
    "                                                  target_size = (h,w),\n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the no. of neurons in dense layer: 256\n",
      "Enter the activation function: relu\n",
      "Enter the dropout percentage: 40\n",
      "\n",
      "Select a optimizer which will reduce the loss of the model.\n",
      "\n",
      "Press 1 to select Stochastic Gradient Descent\n",
      "Press 2 to select RMSprop\n",
      "Press 3 to select Adagrad\n",
      "Press 4 to select Adadelta\n",
      "Press 5 to select Adam\n",
      "Press 6 to select Adamax\n",
      "Press 7 to select Nadam\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "dense = int(input(\"Enter the no. of neurons in dense layer: \"))\n",
    "activation = str(input(\"Enter the activation function: \"))\n",
    "dropout = float(input(\"Enter the dropout percentage: \"))\n",
    "dropout = dropout/100\n",
    "\n",
    "optimizer = optimizer_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING ON VGG19 MODEL:-\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 12s 0us/step\n",
      "Do you want to train the base model of vgg19?(Y/N) y\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 20,156,993\n",
      "Trainable params: 20,156,481\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= vgg19()\n",
    "model.compile(optimizer = optimizer, loss = losses, metrics = ['accuracy', \n",
    "                                                               tf.keras.metrics.Precision(), \n",
    "                                                               tf.keras.metrics.Recall(), \n",
    "                                                               tf.keras.metrics.TruePositives(), \n",
    "                                                               tf.keras.metrics.TrueNegatives(), \n",
    "                                                               tf.keras.metrics.FalsePositives(),\n",
    "                                                               tf.keras.metrics.FalseNegatives()])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-12757c0110cb>:3: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 1/100\n",
      " 1/97 [..............................] - ETA: 0s - loss: 0.6575 - accuracy: 0.4000 - precision: 0.5000 - recall: 0.3333 - true_positives: 1.0000 - true_negatives: 1.0000 - false_positives: 1.0000 - false_negatives: 2.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0108s vs `on_train_batch_end` time: 0.0164s). Check your callbacks.\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.7588 - accuracy: 0.5237 - precision: 0.7450 - recall: 0.5282 - true_positives: 187.0000 - true_negatives: 67.0000 - false_positives: 64.0000 - false_negatives: 167.0000\n",
      "Epoch 00001: loss improved from inf to 0.75877, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/vgg19_1/best_model.h5\n",
      "97/97 [==============================] - 4s 41ms/step - loss: 0.7588 - accuracy: 0.5237 - precision: 0.7450 - recall: 0.5282 - true_positives: 187.0000 - true_negatives: 67.0000 - false_positives: 64.0000 - false_negatives: 167.0000 - val_loss: 0.7257 - val_accuracy: 0.3571 - val_precision: 1.0000 - val_recall: 0.1818 - val_true_positives: 8.0000 - val_true_negatives: 12.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 36.0000\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.7213 - accuracy: 0.5711 - precision: 0.7433 - recall: 0.6299 - true_positives: 223.0000 - true_negatives: 54.0000 - false_positives: 77.0000 - false_negatives: 131.0000\n",
      "Epoch 00002: loss improved from 0.75877 to 0.72132, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/vgg19_1/best_model.h5\n",
      "97/97 [==============================] - 4s 41ms/step - loss: 0.7213 - accuracy: 0.5711 - precision: 0.7433 - recall: 0.6299 - true_positives: 223.0000 - true_negatives: 54.0000 - false_positives: 77.0000 - false_negatives: 131.0000 - val_loss: 0.9814 - val_accuracy: 0.2143 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_true_positives: 0.0000e+00 - val_true_negatives: 12.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 44.0000\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.7154 - accuracy: 0.5938 - precision: 0.7524 - recall: 0.6610 - true_positives: 234.0000 - true_negatives: 54.0000 - false_positives: 77.0000 - false_negatives: 120.0000\n",
      "Epoch 00003: loss improved from 0.72132 to 0.71539, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/vgg19_1/best_model.h5\n",
      "97/97 [==============================] - 7s 70ms/step - loss: 0.7154 - accuracy: 0.5938 - precision: 0.7524 - recall: 0.6610 - true_positives: 234.0000 - true_negatives: 54.0000 - false_positives: 77.0000 - false_negatives: 120.0000 - val_loss: 1.0322 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.7192 - accuracy: 0.5649 - precision: 0.7227 - recall: 0.6554 - true_positives: 232.0000 - true_negatives: 42.0000 - false_positives: 89.0000 - false_negatives: 122.0000\n",
      "Epoch 00004: loss did not improve from 0.71539\n",
      "97/97 [==============================] - 3s 32ms/step - loss: 0.7192 - accuracy: 0.5649 - precision: 0.7227 - recall: 0.6554 - true_positives: 232.0000 - true_negatives: 42.0000 - false_positives: 89.0000 - false_negatives: 122.0000 - val_loss: 0.6068 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.7311 - accuracy: 0.5856 - precision: 0.7131 - recall: 0.7232 - true_positives: 256.0000 - true_negatives: 28.0000 - false_positives: 103.0000 - false_negatives: 98.0000\n",
      "Epoch 00005: loss did not improve from 0.71539\n",
      "97/97 [==============================] - 3s 31ms/step - loss: 0.7311 - accuracy: 0.5856 - precision: 0.7131 - recall: 0.7232 - true_positives: 256.0000 - true_negatives: 28.0000 - false_positives: 103.0000 - false_negatives: 98.0000 - val_loss: 0.6071 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6821 - accuracy: 0.6247 - precision: 0.7251 - recall: 0.7825 - true_positives: 277.0000 - true_negatives: 26.0000 - false_positives: 105.0000 - false_negatives: 77.0000\n",
      "Epoch 00006: loss improved from 0.71539 to 0.68207, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/vgg19_1/best_model.h5\n",
      "97/97 [==============================] - 4s 41ms/step - loss: 0.6821 - accuracy: 0.6247 - precision: 0.7251 - recall: 0.7825 - true_positives: 277.0000 - true_negatives: 26.0000 - false_positives: 105.0000 - false_negatives: 77.0000 - val_loss: 0.7343 - val_accuracy: 0.5536 - val_precision: 0.8065 - val_recall: 0.5682 - val_true_positives: 25.0000 - val_true_negatives: 6.0000 - val_false_positives: 6.0000 - val_false_negatives: 19.0000\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.7062 - accuracy: 0.6144 - precision: 0.7158 - recall: 0.7825 - true_positives: 277.0000 - true_negatives: 21.0000 - false_positives: 110.0000 - false_negatives: 77.0000\n",
      "Epoch 00007: loss did not improve from 0.68207\n",
      "97/97 [==============================] - 3s 31ms/step - loss: 0.7062 - accuracy: 0.6144 - precision: 0.7158 - recall: 0.7825 - true_positives: 277.0000 - true_negatives: 21.0000 - false_positives: 110.0000 - false_negatives: 77.0000 - val_loss: 0.6082 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6980 - accuracy: 0.6103 - precision: 0.7188 - recall: 0.7655 - true_positives: 271.0000 - true_negatives: 25.0000 - false_positives: 106.0000 - false_negatives: 83.0000\n",
      "Epoch 00008: loss did not improve from 0.68207\n",
      "97/97 [==============================] - 3s 31ms/step - loss: 0.6980 - accuracy: 0.6103 - precision: 0.7188 - recall: 0.7655 - true_positives: 271.0000 - true_negatives: 25.0000 - false_positives: 106.0000 - false_negatives: 83.0000 - val_loss: 0.5257 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6631 - accuracy: 0.6186 - precision: 0.7230 - recall: 0.7740 - true_positives: 274.0000 - true_negatives: 26.0000 - false_positives: 105.0000 - false_negatives: 80.0000\n",
      "Epoch 00009: loss improved from 0.68207 to 0.66305, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/vgg19_1/best_model.h5\n",
      "97/97 [==============================] - 4s 39ms/step - loss: 0.6631 - accuracy: 0.6186 - precision: 0.7230 - recall: 0.7740 - true_positives: 274.0000 - true_negatives: 26.0000 - false_positives: 105.0000 - false_negatives: 80.0000 - val_loss: 0.5267 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.7085 - accuracy: 0.6680 - precision: 0.7406 - recall: 0.8390 - true_positives: 297.0000 - true_negatives: 27.0000 - false_positives: 104.0000 - false_negatives: 57.0000\n",
      "Epoch 00010: loss did not improve from 0.66305\n",
      "97/97 [==============================] - 3s 31ms/step - loss: 0.7085 - accuracy: 0.6680 - precision: 0.7406 - recall: 0.8390 - true_positives: 297.0000 - true_negatives: 27.0000 - false_positives: 104.0000 - false_negatives: 57.0000 - val_loss: 0.5450 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6816 - accuracy: 0.6804 - precision: 0.7445 - recall: 0.8559 - true_positives: 303.0000 - true_negatives: 27.0000 - false_positives: 104.0000 - false_negatives: 51.0000\n",
      "Epoch 00011: loss did not improve from 0.66305\n",
      "97/97 [==============================] - 3s 31ms/step - loss: 0.6816 - accuracy: 0.6804 - precision: 0.7445 - recall: 0.8559 - true_positives: 303.0000 - true_negatives: 27.0000 - false_positives: 104.0000 - false_negatives: 51.0000 - val_loss: 0.5359 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6837 - accuracy: 0.6557 - precision: 0.7320 - recall: 0.8333 - true_positives: 295.0000 - true_negatives: 23.0000 - false_positives: 108.0000 - false_negatives: 59.0000\n",
      "Epoch 00012: loss did not improve from 0.66305\n",
      "97/97 [==============================] - 3s 31ms/step - loss: 0.6837 - accuracy: 0.6557 - precision: 0.7320 - recall: 0.8333 - true_positives: 295.0000 - true_negatives: 23.0000 - false_positives: 108.0000 - false_negatives: 59.0000 - val_loss: 0.5377 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6964 - accuracy: 0.6495 - precision: 0.7233 - recall: 0.8418 - true_positives: 298.0000 - true_negatives: 17.0000 - false_positives: 114.0000 - false_negatives: 56.0000\n",
      "Epoch 00013: loss did not improve from 0.66305\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6964 - accuracy: 0.6495 - precision: 0.7233 - recall: 0.8418 - true_positives: 298.0000 - true_negatives: 17.0000 - false_positives: 114.0000 - false_negatives: 56.0000 - val_loss: 0.5305 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6887 - accuracy: 0.6515 - precision: 0.7342 - recall: 0.8192 - true_positives: 290.0000 - true_negatives: 26.0000 - false_positives: 105.0000 - false_negatives: 64.0000\n",
      "Epoch 00014: loss did not improve from 0.66305\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6887 - accuracy: 0.6515 - precision: 0.7342 - recall: 0.8192 - true_positives: 290.0000 - true_negatives: 26.0000 - false_positives: 105.0000 - false_negatives: 64.0000 - val_loss: 0.5342 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6450 - accuracy: 0.6784 - precision: 0.7426 - recall: 0.8559 - true_positives: 303.0000 - true_negatives: 26.0000 - false_positives: 105.0000 - false_negatives: 51.0000\n",
      "Epoch 00015: loss improved from 0.66305 to 0.64499, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/vgg19_1/best_model.h5\n",
      "97/97 [==============================] - 4s 40ms/step - loss: 0.6450 - accuracy: 0.6784 - precision: 0.7426 - recall: 0.8559 - true_positives: 303.0000 - true_negatives: 26.0000 - false_positives: 105.0000 - false_negatives: 51.0000 - val_loss: 0.5297 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6909 - accuracy: 0.6515 - precision: 0.7273 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 58.0000\n",
      "Epoch 00016: loss did not improve from 0.64499\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6909 - accuracy: 0.6515 - precision: 0.7273 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 58.0000 - val_loss: 0.5327 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.6474 - precision: 0.7226 - recall: 0.8390 - true_positives: 297.0000 - true_negatives: 17.0000 - false_positives: 114.0000 - false_negatives: 57.0000\n",
      "Epoch 00017: loss did not improve from 0.64499\n",
      "97/97 [==============================] - 3s 31ms/step - loss: 0.6794 - accuracy: 0.6474 - precision: 0.7226 - recall: 0.8390 - true_positives: 297.0000 - true_negatives: 17.0000 - false_positives: 114.0000 - false_negatives: 57.0000 - val_loss: 0.5358 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6549 - accuracy: 0.6784 - precision: 0.7438 - recall: 0.8531 - true_positives: 302.0000 - true_negatives: 27.0000 - false_positives: 104.0000 - false_negatives: 52.0000\n",
      "Epoch 00018: loss did not improve from 0.64499\n",
      "97/97 [==============================] - 3s 31ms/step - loss: 0.6549 - accuracy: 0.6784 - precision: 0.7438 - recall: 0.8531 - true_positives: 302.0000 - true_negatives: 27.0000 - false_positives: 104.0000 - false_negatives: 52.0000 - val_loss: 0.5302 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6547 - accuracy: 0.6639 - precision: 0.7370 - recall: 0.8390 - true_positives: 297.0000 - true_negatives: 25.0000 - false_positives: 106.0000 - false_negatives: 57.0000\n",
      "Epoch 00019: loss did not improve from 0.64499\n",
      "97/97 [==============================] - 3s 31ms/step - loss: 0.6547 - accuracy: 0.6639 - precision: 0.7370 - recall: 0.8390 - true_positives: 297.0000 - true_negatives: 25.0000 - false_positives: 106.0000 - false_negatives: 57.0000 - val_loss: 0.5430 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - ETA: 0s - loss: 0.6956 - accuracy: 0.6619 - precision: 0.7306 - recall: 0.8503 - true_positives: 301.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 53.0000\n",
      "Epoch 00020: loss did not improve from 0.64499\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6956 - accuracy: 0.6619 - precision: 0.7306 - recall: 0.8503 - true_positives: 301.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 53.0000 - val_loss: 0.5312 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6539 - accuracy: 0.6351 - precision: 0.7218 - recall: 0.8136 - true_positives: 288.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 66.0000\n",
      "Epoch 00021: loss did not improve from 0.64499\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6539 - accuracy: 0.6351 - precision: 0.7218 - recall: 0.8136 - true_positives: 288.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 66.0000 - val_loss: 0.5253 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6617 - accuracy: 0.6577 - precision: 0.7338 - recall: 0.8333 - true_positives: 295.0000 - true_negatives: 24.0000 - false_positives: 107.0000 - false_negatives: 59.0000\n",
      "Epoch 00022: loss did not improve from 0.64499\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6617 - accuracy: 0.6577 - precision: 0.7338 - recall: 0.8333 - true_positives: 295.0000 - true_negatives: 24.0000 - false_positives: 107.0000 - false_negatives: 59.0000 - val_loss: 0.5245 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6430 - accuracy: 0.6619 - precision: 0.7375 - recall: 0.8333 - true_positives: 295.0000 - true_negatives: 26.0000 - false_positives: 105.0000 - false_negatives: 59.0000\n",
      "Epoch 00023: loss improved from 0.64499 to 0.64299, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/vgg19_1/best_model.h5\n",
      "97/97 [==============================] - 4s 39ms/step - loss: 0.6430 - accuracy: 0.6619 - precision: 0.7375 - recall: 0.8333 - true_positives: 295.0000 - true_negatives: 26.0000 - false_positives: 105.0000 - false_negatives: 59.0000 - val_loss: 0.5244 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.7051 - accuracy: 0.6371 - precision: 0.7181 - recall: 0.8277 - true_positives: 293.0000 - true_negatives: 16.0000 - false_positives: 115.0000 - false_negatives: 61.0000\n",
      "Epoch 00024: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.7051 - accuracy: 0.6371 - precision: 0.7181 - recall: 0.8277 - true_positives: 293.0000 - true_negatives: 16.0000 - false_positives: 115.0000 - false_negatives: 61.0000 - val_loss: 0.5244 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6889 - accuracy: 0.6454 - precision: 0.7241 - recall: 0.8305 - true_positives: 294.0000 - true_negatives: 19.0000 - false_positives: 112.0000 - false_negatives: 60.0000\n",
      "Epoch 00025: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6889 - accuracy: 0.6454 - precision: 0.7241 - recall: 0.8305 - true_positives: 294.0000 - true_negatives: 19.0000 - false_positives: 112.0000 - false_negatives: 60.0000 - val_loss: 0.5243 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.6412 - precision: 0.7195 - recall: 0.8333 - true_positives: 295.0000 - true_negatives: 16.0000 - false_positives: 115.0000 - false_negatives: 59.0000\n",
      "Epoch 00026: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6936 - accuracy: 0.6412 - precision: 0.7195 - recall: 0.8333 - true_positives: 295.0000 - true_negatives: 16.0000 - false_positives: 115.0000 - false_negatives: 59.0000 - val_loss: 0.5283 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6412 - precision: 0.7184 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 15.0000 - false_positives: 116.0000 - false_negatives: 58.0000\n",
      "Epoch 00027: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6848 - accuracy: 0.6412 - precision: 0.7184 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 15.0000 - false_positives: 116.0000 - false_negatives: 58.0000 - val_loss: 0.5313 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6802 - accuracy: 0.6557 - precision: 0.7264 - recall: 0.8475 - true_positives: 300.0000 - true_negatives: 18.0000 - false_positives: 113.0000 - false_negatives: 54.0000\n",
      "Epoch 00028: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6802 - accuracy: 0.6557 - precision: 0.7264 - recall: 0.8475 - true_positives: 300.0000 - true_negatives: 18.0000 - false_positives: 113.0000 - false_negatives: 54.0000 - val_loss: 0.5372 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6702 - accuracy: 0.6825 - precision: 0.7415 - recall: 0.8672 - true_positives: 307.0000 - true_negatives: 24.0000 - false_positives: 107.0000 - false_negatives: 47.0000\n",
      "Epoch 00029: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6702 - accuracy: 0.6825 - precision: 0.7415 - recall: 0.8672 - true_positives: 307.0000 - true_negatives: 24.0000 - false_positives: 107.0000 - false_negatives: 47.0000 - val_loss: 0.5263 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6991 - accuracy: 0.6557 - precision: 0.7286 - recall: 0.8418 - true_positives: 298.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 56.0000\n",
      "Epoch 00030: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6991 - accuracy: 0.6557 - precision: 0.7286 - recall: 0.8418 - true_positives: 298.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 56.0000 - val_loss: 0.5240 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6779 - accuracy: 0.6660 - precision: 0.7376 - recall: 0.8418 - true_positives: 298.0000 - true_negatives: 25.0000 - false_positives: 106.0000 - false_negatives: 56.0000\n",
      "Epoch 00031: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6779 - accuracy: 0.6660 - precision: 0.7376 - recall: 0.8418 - true_positives: 298.0000 - true_negatives: 25.0000 - false_positives: 106.0000 - false_negatives: 56.0000 - val_loss: 0.5248 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 32/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6748 - accuracy: 0.6577 - precision: 0.7271 - recall: 0.8503 - true_positives: 301.0000 - true_negatives: 18.0000 - false_positives: 113.0000 - false_negatives: 53.0000\n",
      "Epoch 00032: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6748 - accuracy: 0.6577 - precision: 0.7271 - recall: 0.8503 - true_positives: 301.0000 - true_negatives: 18.0000 - false_positives: 113.0000 - false_negatives: 53.0000 - val_loss: 0.5261 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 33/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6809 - accuracy: 0.6392 - precision: 0.7266 - recall: 0.8107 - true_positives: 287.0000 - true_negatives: 23.0000 - false_positives: 108.0000 - false_negatives: 67.0000\n",
      "Epoch 00033: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6809 - accuracy: 0.6392 - precision: 0.7266 - recall: 0.8107 - true_positives: 287.0000 - true_negatives: 23.0000 - false_positives: 108.0000 - false_negatives: 67.0000 - val_loss: 0.5298 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 34/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6990 - accuracy: 0.6495 - precision: 0.7289 - recall: 0.8277 - true_positives: 293.0000 - true_negatives: 22.0000 - false_positives: 109.0000 - false_negatives: 61.0000\n",
      "Epoch 00034: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6990 - accuracy: 0.6495 - precision: 0.7289 - recall: 0.8277 - true_positives: 293.0000 - true_negatives: 22.0000 - false_positives: 109.0000 - false_negatives: 61.0000 - val_loss: 0.5277 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 35/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6656 - accuracy: 0.6536 - precision: 0.7291 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 21.0000 - false_positives: 110.0000 - false_negatives: 58.0000\n",
      "Epoch 00035: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6656 - accuracy: 0.6536 - precision: 0.7291 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 21.0000 - false_positives: 110.0000 - false_negatives: 58.0000 - val_loss: 0.5297 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 36/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6482 - accuracy: 0.6866 - precision: 0.7451 - recall: 0.8672 - true_positives: 307.0000 - true_negatives: 26.0000 - false_positives: 105.0000 - false_negatives: 47.0000\n",
      "Epoch 00036: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6482 - accuracy: 0.6866 - precision: 0.7451 - recall: 0.8672 - true_positives: 307.0000 - true_negatives: 26.0000 - false_positives: 105.0000 - false_negatives: 47.0000 - val_loss: 0.5316 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 37/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6991 - accuracy: 0.6515 - precision: 0.7318 - recall: 0.8249 - true_positives: 292.0000 - true_negatives: 24.0000 - false_positives: 107.0000 - false_negatives: 62.0000\n",
      "Epoch 00037: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6991 - accuracy: 0.6515 - precision: 0.7318 - recall: 0.8249 - true_positives: 292.0000 - true_negatives: 24.0000 - false_positives: 107.0000 - false_negatives: 62.0000 - val_loss: 0.5324 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 38/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6678 - accuracy: 0.6639 - precision: 0.7382 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 26.0000 - false_positives: 105.0000 - false_negatives: 58.0000\n",
      "Epoch 00038: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6678 - accuracy: 0.6639 - precision: 0.7382 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 26.0000 - false_positives: 105.0000 - false_negatives: 58.0000 - val_loss: 0.5319 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 39/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6706 - accuracy: 0.6536 - precision: 0.7291 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 21.0000 - false_positives: 110.0000 - false_negatives: 58.0000\n",
      "Epoch 00039: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6706 - accuracy: 0.6536 - precision: 0.7291 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 21.0000 - false_positives: 110.0000 - false_negatives: 58.0000 - val_loss: 0.5288 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 40/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6619 - accuracy: 0.6701 - precision: 0.7343 - recall: 0.8588 - true_positives: 304.0000 - true_negatives: 21.0000 - false_positives: 110.0000 - false_negatives: 50.0000\n",
      "Epoch 00040: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6619 - accuracy: 0.6701 - precision: 0.7343 - recall: 0.8588 - true_positives: 304.0000 - true_negatives: 21.0000 - false_positives: 110.0000 - false_negatives: 50.0000 - val_loss: 0.5279 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 41/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6601 - accuracy: 0.6742 - precision: 0.7402 - recall: 0.8531 - true_positives: 302.0000 - true_negatives: 25.0000 - false_positives: 106.0000 - false_negatives: 52.0000\n",
      "Epoch 00041: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6601 - accuracy: 0.6742 - precision: 0.7402 - recall: 0.8531 - true_positives: 302.0000 - true_negatives: 25.0000 - false_positives: 106.0000 - false_negatives: 52.0000 - val_loss: 0.5288 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 42/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6563 - accuracy: 0.6825 - precision: 0.7488 - recall: 0.8503 - true_positives: 301.0000 - true_negatives: 30.0000 - false_positives: 101.0000 - false_negatives: 53.0000\n",
      "Epoch 00042: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6563 - accuracy: 0.6825 - precision: 0.7488 - recall: 0.8503 - true_positives: 301.0000 - true_negatives: 30.0000 - false_positives: 101.0000 - false_negatives: 53.0000 - val_loss: 0.5298 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 43/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6570 - accuracy: 0.6557 - precision: 0.7264 - recall: 0.8475 - true_positives: 300.0000 - true_negatives: 18.0000 - false_positives: 113.0000 - false_negatives: 54.0000\n",
      "Epoch 00043: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6570 - accuracy: 0.6557 - precision: 0.7264 - recall: 0.8475 - true_positives: 300.0000 - true_negatives: 18.0000 - false_positives: 113.0000 - false_negatives: 54.0000 - val_loss: 0.5287 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 44/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6929 - accuracy: 0.6392 - precision: 0.7178 - recall: 0.8333 - true_positives: 295.0000 - true_negatives: 15.0000 - false_positives: 116.0000 - false_negatives: 59.0000\n",
      "Epoch 00044: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6929 - accuracy: 0.6392 - precision: 0.7178 - recall: 0.8333 - true_positives: 295.0000 - true_negatives: 15.0000 - false_positives: 116.0000 - false_negatives: 59.0000 - val_loss: 0.5270 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 45/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6807 - accuracy: 0.6495 - precision: 0.7255 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 19.0000 - false_positives: 112.0000 - false_negatives: 58.0000\n",
      "Epoch 00045: loss did not improve from 0.64299\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6807 - accuracy: 0.6495 - precision: 0.7255 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 19.0000 - false_positives: 112.0000 - false_negatives: 58.0000 - val_loss: 0.5272 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 46/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6423 - accuracy: 0.6907 - precision: 0.7452 - recall: 0.8757 - true_positives: 310.0000 - true_negatives: 25.0000 - false_positives: 106.0000 - false_negatives: 44.0000\n",
      "Epoch 00046: loss improved from 0.64299 to 0.64228, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/vgg19_1/best_model.h5\n",
      "97/97 [==============================] - 4s 40ms/step - loss: 0.6423 - accuracy: 0.6907 - precision: 0.7452 - recall: 0.8757 - true_positives: 310.0000 - true_negatives: 25.0000 - false_positives: 106.0000 - false_negatives: 44.0000 - val_loss: 0.5313 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 47/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6901 - accuracy: 0.6206 - precision: 0.7125 - recall: 0.8051 - true_positives: 285.0000 - true_negatives: 16.0000 - false_positives: 115.0000 - false_negatives: 69.0000\n",
      "Epoch 00047: loss did not improve from 0.64228\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6901 - accuracy: 0.6206 - precision: 0.7125 - recall: 0.8051 - true_positives: 285.0000 - true_negatives: 16.0000 - false_positives: 115.0000 - false_negatives: 69.0000 - val_loss: 0.5255 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 48/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6663 - accuracy: 0.6433 - precision: 0.7246 - recall: 0.8249 - true_positives: 292.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 62.0000\n",
      "Epoch 00048: loss did not improve from 0.64228\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6663 - accuracy: 0.6433 - precision: 0.7246 - recall: 0.8249 - true_positives: 292.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 62.0000 - val_loss: 0.5280 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 49/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6577 - accuracy: 0.6557 - precision: 0.7210 - recall: 0.8616 - true_positives: 305.0000 - true_negatives: 13.0000 - false_positives: 118.0000 - false_negatives: 49.0000\n",
      "Epoch 00049: loss did not improve from 0.64228\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6577 - accuracy: 0.6557 - precision: 0.7210 - recall: 0.8616 - true_positives: 305.0000 - true_negatives: 13.0000 - false_positives: 118.0000 - false_negatives: 49.0000 - val_loss: 0.5323 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 50/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6637 - accuracy: 0.6536 - precision: 0.7279 - recall: 0.8390 - true_positives: 297.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 57.0000\n",
      "Epoch 00050: loss did not improve from 0.64228\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6637 - accuracy: 0.6536 - precision: 0.7279 - recall: 0.8390 - true_positives: 297.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 57.0000 - val_loss: 0.5277 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 51/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6554 - accuracy: 0.6804 - precision: 0.7433 - recall: 0.8588 - true_positives: 304.0000 - true_negatives: 26.0000 - false_positives: 105.0000 - false_negatives: 50.0000\n",
      "Epoch 00051: loss did not improve from 0.64228\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6554 - accuracy: 0.6804 - precision: 0.7433 - recall: 0.8588 - true_positives: 304.0000 - true_negatives: 26.0000 - false_positives: 105.0000 - false_negatives: 50.0000 - val_loss: 0.5244 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 52/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.6289 - precision: 0.7143 - recall: 0.8192 - true_positives: 290.0000 - true_negatives: 15.0000 - false_positives: 116.0000 - false_negatives: 64.0000\n",
      "Epoch 00052: loss did not improve from 0.64228\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6939 - accuracy: 0.6289 - precision: 0.7143 - recall: 0.8192 - true_positives: 290.0000 - true_negatives: 15.0000 - false_positives: 116.0000 - false_negatives: 64.0000 - val_loss: 0.5243 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 53/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6884 - accuracy: 0.6577 - precision: 0.7327 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 23.0000 - false_positives: 108.0000 - false_negatives: 58.0000\n",
      "Epoch 00053: loss did not improve from 0.64228\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6884 - accuracy: 0.6577 - precision: 0.7327 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 23.0000 - false_positives: 108.0000 - false_negatives: 58.0000 - val_loss: 0.5255 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 54/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.7034 - accuracy: 0.6495 - precision: 0.7190 - recall: 0.8531 - true_positives: 302.0000 - true_negatives: 13.0000 - false_positives: 118.0000 - false_negatives: 52.0000\n",
      "Epoch 00054: loss did not improve from 0.64228\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.7034 - accuracy: 0.6495 - precision: 0.7190 - recall: 0.8531 - true_positives: 302.0000 - true_negatives: 13.0000 - false_positives: 118.0000 - false_negatives: 52.0000 - val_loss: 0.5275 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 55/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6842 - accuracy: 0.6474 - precision: 0.7205 - recall: 0.8446 - true_positives: 299.0000 - true_negatives: 15.0000 - false_positives: 116.0000 - false_negatives: 55.0000\n",
      "Epoch 00055: loss did not improve from 0.64228\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6842 - accuracy: 0.6474 - precision: 0.7205 - recall: 0.8446 - true_positives: 299.0000 - true_negatives: 15.0000 - false_positives: 116.0000 - false_negatives: 55.0000 - val_loss: 0.5313 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 56/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6539 - accuracy: 0.6577 - precision: 0.7293 - recall: 0.8446 - true_positives: 299.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 55.0000\n",
      "Epoch 00056: loss did not improve from 0.64228\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6539 - accuracy: 0.6577 - precision: 0.7293 - recall: 0.8446 - true_positives: 299.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 55.0000 - val_loss: 0.5305 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 57/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6824 - accuracy: 0.6412 - precision: 0.7206 - recall: 0.8305 - true_positives: 294.0000 - true_negatives: 17.0000 - false_positives: 114.0000 - false_negatives: 60.0000\n",
      "Epoch 00057: loss did not improve from 0.64228\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6824 - accuracy: 0.6412 - precision: 0.7206 - recall: 0.8305 - true_positives: 294.0000 - true_negatives: 17.0000 - false_positives: 114.0000 - false_negatives: 60.0000 - val_loss: 0.5305 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 58/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6834 - accuracy: 0.6515 - precision: 0.7251 - recall: 0.8418 - true_positives: 298.0000 - true_negatives: 18.0000 - false_positives: 113.0000 - false_negatives: 56.0000\n",
      "Epoch 00058: loss did not improve from 0.64228\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6834 - accuracy: 0.6515 - precision: 0.7251 - recall: 0.8418 - true_positives: 298.0000 - true_negatives: 18.0000 - false_positives: 113.0000 - false_negatives: 56.0000 - val_loss: 0.5273 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 59/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6583 - accuracy: 0.6619 - precision: 0.7317 - recall: 0.8475 - true_positives: 300.0000 - true_negatives: 21.0000 - false_positives: 110.0000 - false_negatives: 54.0000\n",
      "Epoch 00059: loss did not improve from 0.64228\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6583 - accuracy: 0.6619 - precision: 0.7317 - recall: 0.8475 - true_positives: 300.0000 - true_negatives: 21.0000 - false_positives: 110.0000 - false_negatives: 54.0000 - val_loss: 0.5296 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 60/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6770 - accuracy: 0.6577 - precision: 0.7350 - recall: 0.8305 - true_positives: 294.0000 - true_negatives: 25.0000 - false_positives: 106.0000 - false_negatives: 60.0000\n",
      "Epoch 00060: loss did not improve from 0.64228\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6770 - accuracy: 0.6577 - precision: 0.7350 - recall: 0.8305 - true_positives: 294.0000 - true_negatives: 25.0000 - false_positives: 106.0000 - false_negatives: 60.0000 - val_loss: 0.5256 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 61/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6607 - accuracy: 0.6412 - precision: 0.7153 - recall: 0.8446 - true_positives: 299.0000 - true_negatives: 12.0000 - false_positives: 119.0000 - false_negatives: 55.0000\n",
      "Epoch 00061: loss did not improve from 0.64228\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6607 - accuracy: 0.6412 - precision: 0.7153 - recall: 0.8446 - true_positives: 299.0000 - true_negatives: 12.0000 - false_positives: 119.0000 - false_negatives: 55.0000 - val_loss: 0.5260 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 62/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6723 - accuracy: 0.6454 - precision: 0.7198 - recall: 0.8418 - true_positives: 298.0000 - true_negatives: 15.0000 - false_positives: 116.0000 - false_negatives: 56.0000\n",
      "Epoch 00062: loss did not improve from 0.64228\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6723 - accuracy: 0.6454 - precision: 0.7198 - recall: 0.8418 - true_positives: 298.0000 - true_negatives: 15.0000 - false_positives: 116.0000 - false_negatives: 56.0000 - val_loss: 0.5268 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 63/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6742 - accuracy: 0.6433 - precision: 0.7181 - recall: 0.8418 - true_positives: 298.0000 - true_negatives: 14.0000 - false_positives: 117.0000 - false_negatives: 56.0000\n",
      "Epoch 00063: loss did not improve from 0.64228\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6742 - accuracy: 0.6433 - precision: 0.7181 - recall: 0.8418 - true_positives: 298.0000 - true_negatives: 14.0000 - false_positives: 117.0000 - false_negatives: 56.0000 - val_loss: 0.5285 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 64/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6378 - accuracy: 0.6701 - precision: 0.7401 - recall: 0.8446 - true_positives: 299.0000 - true_negatives: 26.0000 - false_positives: 105.0000 - false_negatives: 55.0000\n",
      "Epoch 00064: loss improved from 0.64228 to 0.63783, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/vgg19_1/best_model.h5\n",
      "97/97 [==============================] - 4s 38ms/step - loss: 0.6378 - accuracy: 0.6701 - precision: 0.7401 - recall: 0.8446 - true_positives: 299.0000 - true_negatives: 26.0000 - false_positives: 105.0000 - false_negatives: 55.0000 - val_loss: 0.5266 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 65/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6859 - accuracy: 0.6186 - precision: 0.7107 - recall: 0.8051 - true_positives: 285.0000 - true_negatives: 15.0000 - false_positives: 116.0000 - false_negatives: 69.0000\n",
      "Epoch 00065: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6859 - accuracy: 0.6186 - precision: 0.7107 - recall: 0.8051 - true_positives: 285.0000 - true_negatives: 15.0000 - false_positives: 116.0000 - false_negatives: 69.0000 - val_loss: 0.5257 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 66/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6698 - accuracy: 0.6598 - precision: 0.7345 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 24.0000 - false_positives: 107.0000 - false_negatives: 58.0000\n",
      "Epoch 00066: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6698 - accuracy: 0.6598 - precision: 0.7345 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 24.0000 - false_positives: 107.0000 - false_negatives: 58.0000 - val_loss: 0.5251 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 67/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6664 - accuracy: 0.6371 - precision: 0.7214 - recall: 0.8192 - true_positives: 290.0000 - true_negatives: 19.0000 - false_positives: 112.0000 - false_negatives: 64.0000\n",
      "Epoch 00067: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6664 - accuracy: 0.6371 - precision: 0.7214 - recall: 0.8192 - true_positives: 290.0000 - true_negatives: 19.0000 - false_positives: 112.0000 - false_negatives: 64.0000 - val_loss: 0.5266 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 68/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6776 - accuracy: 0.6639 - precision: 0.7258 - recall: 0.8672 - true_positives: 307.0000 - true_negatives: 15.0000 - false_positives: 116.0000 - false_negatives: 47.0000\n",
      "Epoch 00068: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6776 - accuracy: 0.6639 - precision: 0.7258 - recall: 0.8672 - true_positives: 307.0000 - true_negatives: 15.0000 - false_positives: 116.0000 - false_negatives: 47.0000 - val_loss: 0.5278 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 69/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6910 - accuracy: 0.6412 - precision: 0.7228 - recall: 0.8249 - true_positives: 292.0000 - true_negatives: 19.0000 - false_positives: 112.0000 - false_negatives: 62.0000\n",
      "Epoch 00069: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6910 - accuracy: 0.6412 - precision: 0.7228 - recall: 0.8249 - true_positives: 292.0000 - true_negatives: 19.0000 - false_positives: 112.0000 - false_negatives: 62.0000 - val_loss: 0.5301 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 70/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6562 - accuracy: 0.6474 - precision: 0.7282 - recall: 0.8249 - true_positives: 292.0000 - true_negatives: 22.0000 - false_positives: 109.0000 - false_negatives: 62.0000\n",
      "Epoch 00070: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6562 - accuracy: 0.6474 - precision: 0.7282 - recall: 0.8249 - true_positives: 292.0000 - true_negatives: 22.0000 - false_positives: 109.0000 - false_negatives: 62.0000 - val_loss: 0.5287 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 71/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6619 - accuracy: 0.6639 - precision: 0.7324 - recall: 0.8503 - true_positives: 301.0000 - true_negatives: 21.0000 - false_positives: 110.0000 - false_negatives: 53.0000\n",
      "Epoch 00071: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6619 - accuracy: 0.6639 - precision: 0.7324 - recall: 0.8503 - true_positives: 301.0000 - true_negatives: 21.0000 - false_positives: 110.0000 - false_negatives: 53.0000 - val_loss: 0.5259 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 72/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6824 - accuracy: 0.6495 - precision: 0.7244 - recall: 0.8390 - true_positives: 297.0000 - true_negatives: 18.0000 - false_positives: 113.0000 - false_negatives: 57.0000\n",
      "Epoch 00072: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6824 - accuracy: 0.6495 - precision: 0.7244 - recall: 0.8390 - true_positives: 297.0000 - true_negatives: 18.0000 - false_positives: 113.0000 - false_negatives: 57.0000 - val_loss: 0.5272 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 73/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.7266 - accuracy: 0.6268 - precision: 0.7179 - recall: 0.8051 - true_positives: 285.0000 - true_negatives: 19.0000 - false_positives: 112.0000 - false_negatives: 69.0000\n",
      "Epoch 00073: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.7266 - accuracy: 0.6268 - precision: 0.7179 - recall: 0.8051 - true_positives: 285.0000 - true_negatives: 19.0000 - false_positives: 112.0000 - false_negatives: 69.0000 - val_loss: 0.5279 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 74/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.7017 - accuracy: 0.6454 - precision: 0.7198 - recall: 0.8418 - true_positives: 298.0000 - true_negatives: 15.0000 - false_positives: 116.0000 - false_negatives: 56.0000\n",
      "Epoch 00074: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.7017 - accuracy: 0.6454 - precision: 0.7198 - recall: 0.8418 - true_positives: 298.0000 - true_negatives: 15.0000 - false_positives: 116.0000 - false_negatives: 56.0000 - val_loss: 0.5261 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 75/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.6557 - precision: 0.7253 - recall: 0.8503 - true_positives: 301.0000 - true_negatives: 17.0000 - false_positives: 114.0000 - false_negatives: 53.0000\n",
      "Epoch 00075: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6914 - accuracy: 0.6557 - precision: 0.7253 - recall: 0.8503 - true_positives: 301.0000 - true_negatives: 17.0000 - false_positives: 114.0000 - false_negatives: 53.0000 - val_loss: 0.5241 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 76/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6735 - accuracy: 0.6619 - precision: 0.7306 - recall: 0.8503 - true_positives: 301.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 53.0000\n",
      "Epoch 00076: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6735 - accuracy: 0.6619 - precision: 0.7306 - recall: 0.8503 - true_positives: 301.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 53.0000 - val_loss: 0.5270 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 77/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6781 - accuracy: 0.6680 - precision: 0.7359 - recall: 0.8503 - true_positives: 301.0000 - true_negatives: 23.0000 - false_positives: 108.0000 - false_negatives: 53.0000\n",
      "Epoch 00077: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6781 - accuracy: 0.6680 - precision: 0.7359 - recall: 0.8503 - true_positives: 301.0000 - true_negatives: 23.0000 - false_positives: 108.0000 - false_negatives: 53.0000 - val_loss: 0.5248 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 78/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6763 - accuracy: 0.6536 - precision: 0.7302 - recall: 0.8333 - true_positives: 295.0000 - true_negatives: 22.0000 - false_positives: 109.0000 - false_negatives: 59.0000\n",
      "Epoch 00078: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6763 - accuracy: 0.6536 - precision: 0.7302 - recall: 0.8333 - true_positives: 295.0000 - true_negatives: 22.0000 - false_positives: 109.0000 - false_negatives: 59.0000 - val_loss: 0.5260 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 79/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6436 - accuracy: 0.6598 - precision: 0.7299 - recall: 0.8475 - true_positives: 300.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 54.0000\n",
      "Epoch 00079: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6436 - accuracy: 0.6598 - precision: 0.7299 - recall: 0.8475 - true_positives: 300.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 54.0000 - val_loss: 0.5273 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 80/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6523 - accuracy: 0.6804 - precision: 0.7481 - recall: 0.8475 - true_positives: 300.0000 - true_negatives: 30.0000 - false_positives: 101.0000 - false_negatives: 54.0000\n",
      "Epoch 00080: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6523 - accuracy: 0.6804 - precision: 0.7481 - recall: 0.8475 - true_positives: 300.0000 - true_negatives: 30.0000 - false_positives: 101.0000 - false_negatives: 54.0000 - val_loss: 0.5288 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 81/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6827 - accuracy: 0.6784 - precision: 0.7438 - recall: 0.8531 - true_positives: 302.0000 - true_negatives: 27.0000 - false_positives: 104.0000 - false_negatives: 52.0000\n",
      "Epoch 00081: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6827 - accuracy: 0.6784 - precision: 0.7438 - recall: 0.8531 - true_positives: 302.0000 - true_negatives: 27.0000 - false_positives: 104.0000 - false_negatives: 52.0000 - val_loss: 0.5300 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 82/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6700 - accuracy: 0.6536 - precision: 0.7257 - recall: 0.8446 - true_positives: 299.0000 - true_negatives: 18.0000 - false_positives: 113.0000 - false_negatives: 55.0000\n",
      "Epoch 00082: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6700 - accuracy: 0.6536 - precision: 0.7257 - recall: 0.8446 - true_positives: 299.0000 - true_negatives: 18.0000 - false_positives: 113.0000 - false_negatives: 55.0000 - val_loss: 0.5306 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 83/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6781 - accuracy: 0.6660 - precision: 0.7308 - recall: 0.8588 - true_positives: 304.0000 - true_negatives: 19.0000 - false_positives: 112.0000 - false_negatives: 50.0000\n",
      "Epoch 00083: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6781 - accuracy: 0.6660 - precision: 0.7308 - recall: 0.8588 - true_positives: 304.0000 - true_negatives: 19.0000 - false_positives: 112.0000 - false_negatives: 50.0000 - val_loss: 0.5279 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 84/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6639 - accuracy: 0.6742 - precision: 0.7390 - recall: 0.8559 - true_positives: 303.0000 - true_negatives: 24.0000 - false_positives: 107.0000 - false_negatives: 51.0000\n",
      "Epoch 00084: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6639 - accuracy: 0.6742 - precision: 0.7390 - recall: 0.8559 - true_positives: 303.0000 - true_negatives: 24.0000 - false_positives: 107.0000 - false_negatives: 51.0000 - val_loss: 0.5284 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 85/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6980 - accuracy: 0.6289 - precision: 0.7153 - recall: 0.8164 - true_positives: 289.0000 - true_negatives: 16.0000 - false_positives: 115.0000 - false_negatives: 65.0000\n",
      "Epoch 00085: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6980 - accuracy: 0.6289 - precision: 0.7153 - recall: 0.8164 - true_positives: 289.0000 - true_negatives: 16.0000 - false_positives: 115.0000 - false_negatives: 65.0000 - val_loss: 0.5298 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 86/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6489 - accuracy: 0.6680 - precision: 0.7419 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 28.0000 - false_positives: 103.0000 - false_negatives: 58.0000\n",
      "Epoch 00086: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6489 - accuracy: 0.6680 - precision: 0.7419 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 28.0000 - false_positives: 103.0000 - false_negatives: 58.0000 - val_loss: 0.5278 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 87/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6431 - accuracy: 0.6804 - precision: 0.7398 - recall: 0.8672 - true_positives: 307.0000 - true_negatives: 23.0000 - false_positives: 108.0000 - false_negatives: 47.0000\n",
      "Epoch 00087: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6431 - accuracy: 0.6804 - precision: 0.7398 - recall: 0.8672 - true_positives: 307.0000 - true_negatives: 23.0000 - false_positives: 108.0000 - false_negatives: 47.0000 - val_loss: 0.5288 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 88/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6980 - accuracy: 0.6371 - precision: 0.7192 - recall: 0.8249 - true_positives: 292.0000 - true_negatives: 17.0000 - false_positives: 114.0000 - false_negatives: 62.0000\n",
      "Epoch 00088: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6980 - accuracy: 0.6371 - precision: 0.7192 - recall: 0.8249 - true_positives: 292.0000 - true_negatives: 17.0000 - false_positives: 114.0000 - false_negatives: 62.0000 - val_loss: 0.5270 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 89/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6745 - accuracy: 0.6722 - precision: 0.7372 - recall: 0.8559 - true_positives: 303.0000 - true_negatives: 23.0000 - false_positives: 108.0000 - false_negatives: 51.0000\n",
      "Epoch 00089: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6745 - accuracy: 0.6722 - precision: 0.7372 - recall: 0.8559 - true_positives: 303.0000 - true_negatives: 23.0000 - false_positives: 108.0000 - false_negatives: 51.0000 - val_loss: 0.5276 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 90/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6812 - accuracy: 0.6495 - precision: 0.7300 - recall: 0.8249 - true_positives: 292.0000 - true_negatives: 23.0000 - false_positives: 108.0000 - false_negatives: 62.0000\n",
      "Epoch 00090: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6812 - accuracy: 0.6495 - precision: 0.7300 - recall: 0.8249 - true_positives: 292.0000 - true_negatives: 23.0000 - false_positives: 108.0000 - false_negatives: 62.0000 - val_loss: 0.5304 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 91/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6963 - accuracy: 0.6515 - precision: 0.7284 - recall: 0.8333 - true_positives: 295.0000 - true_negatives: 21.0000 - false_positives: 110.0000 - false_negatives: 59.0000\n",
      "Epoch 00091: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6963 - accuracy: 0.6515 - precision: 0.7284 - recall: 0.8333 - true_positives: 295.0000 - true_negatives: 21.0000 - false_positives: 110.0000 - false_negatives: 59.0000 - val_loss: 0.5293 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 92/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6885 - accuracy: 0.6639 - precision: 0.7312 - recall: 0.8531 - true_positives: 302.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 52.0000\n",
      "Epoch 00092: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6885 - accuracy: 0.6639 - precision: 0.7312 - recall: 0.8531 - true_positives: 302.0000 - true_negatives: 20.0000 - false_positives: 111.0000 - false_negatives: 52.0000 - val_loss: 0.5266 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 93/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6690 - accuracy: 0.6680 - precision: 0.7359 - recall: 0.8503 - true_positives: 301.0000 - true_negatives: 23.0000 - false_positives: 108.0000 - false_negatives: 53.0000\n",
      "Epoch 00093: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6690 - accuracy: 0.6680 - precision: 0.7359 - recall: 0.8503 - true_positives: 301.0000 - true_negatives: 23.0000 - false_positives: 108.0000 - false_negatives: 53.0000 - val_loss: 0.5257 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 94/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6666 - accuracy: 0.6763 - precision: 0.7432 - recall: 0.8503 - true_positives: 301.0000 - true_negatives: 27.0000 - false_positives: 104.0000 - false_negatives: 53.0000\n",
      "Epoch 00094: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6666 - accuracy: 0.6763 - precision: 0.7432 - recall: 0.8503 - true_positives: 301.0000 - true_negatives: 27.0000 - false_positives: 104.0000 - false_negatives: 53.0000 - val_loss: 0.5262 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 95/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6750 - accuracy: 0.6557 - precision: 0.7264 - recall: 0.8475 - true_positives: 300.0000 - true_negatives: 18.0000 - false_positives: 113.0000 - false_negatives: 54.0000\n",
      "Epoch 00095: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6750 - accuracy: 0.6557 - precision: 0.7264 - recall: 0.8475 - true_positives: 300.0000 - true_negatives: 18.0000 - false_positives: 113.0000 - false_negatives: 54.0000 - val_loss: 0.5324 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 96/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.7172 - accuracy: 0.6247 - precision: 0.7150 - recall: 0.8079 - true_positives: 286.0000 - true_negatives: 17.0000 - false_positives: 114.0000 - false_negatives: 68.0000\n",
      "Epoch 00096: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.7172 - accuracy: 0.6247 - precision: 0.7150 - recall: 0.8079 - true_positives: 286.0000 - true_negatives: 17.0000 - false_positives: 114.0000 - false_negatives: 68.0000 - val_loss: 0.5317 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 97/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.7353 - accuracy: 0.6474 - precision: 0.7237 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 18.0000 - false_positives: 113.0000 - false_negatives: 58.0000\n",
      "Epoch 00097: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.7353 - accuracy: 0.6474 - precision: 0.7237 - recall: 0.8362 - true_positives: 296.0000 - true_negatives: 18.0000 - false_positives: 113.0000 - false_negatives: 58.0000 - val_loss: 0.5321 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 98/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6489 - accuracy: 0.6701 - precision: 0.7321 - recall: 0.8644 - true_positives: 306.0000 - true_negatives: 19.0000 - false_positives: 112.0000 - false_negatives: 48.0000\n",
      "Epoch 00098: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6489 - accuracy: 0.6701 - precision: 0.7321 - recall: 0.8644 - true_positives: 306.0000 - true_negatives: 19.0000 - false_positives: 112.0000 - false_negatives: 48.0000 - val_loss: 0.5312 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 99/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6496 - accuracy: 0.6722 - precision: 0.7372 - recall: 0.8559 - true_positives: 303.0000 - true_negatives: 23.0000 - false_positives: 108.0000 - false_negatives: 51.0000\n",
      "Epoch 00099: loss did not improve from 0.63783\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.6496 - accuracy: 0.6722 - precision: 0.7372 - recall: 0.8559 - true_positives: 303.0000 - true_negatives: 23.0000 - false_positives: 108.0000 - false_negatives: 51.0000 - val_loss: 0.5304 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 100/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6324 - accuracy: 0.6742 - precision: 0.7426 - recall: 0.8475 - true_positives: 300.0000 - true_negatives: 27.0000 - false_positives: 104.0000 - false_negatives: 54.0000\n",
      "Epoch 00100: loss improved from 0.63783 to 0.63237, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/vgg19_1/best_model.h5\n",
      "97/97 [==============================] - 4s 39ms/step - loss: 0.6324 - accuracy: 0.6742 - precision: 0.7426 - recall: 0.8475 - true_positives: 300.0000 - true_negatives: 27.0000 - false_positives: 104.0000 - false_negatives: 54.0000 - val_loss: 0.5315 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 0.5831 - accuracy: 0.7299 - precision: 0.7299 - recall: 1.0000 - true_positives: 354.0000 - true_negatives: 0.0000e+00 - false_positives: 131.0000 - false_negatives: 0.0000e+00\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5315 - accuracy: 0.7857 - precision: 0.7857 - recall: 1.0000 - true_positives: 44.0000 - true_negatives: 0.0000e+00 - false_positives: 12.0000 - false_negatives: 0.0000e+00\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5948 - accuracy: 0.7167 - precision: 0.7167 - recall: 1.0000 - true_positives: 43.0000 - true_negatives: 0.0000e+00 - false_positives: 17.0000 - false_negatives: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    start = time.time()\n",
    "    history = model.fit(train_generator,\n",
    "                        epochs = epoch,\n",
    "                        verbose = 1,\n",
    "                        callbacks = callback,\n",
    "                        validation_data = validation_generator,\n",
    "                        shuffle=True)\n",
    "\n",
    "    end = time.time()\n",
    "    duration = end-start\n",
    "\n",
    "train_score = model.evaluate(train_generator)\n",
    "val_score = model.evaluate(validation_generator)\n",
    "test_score = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 311.49369716644287 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Execution Time: {} seconds\".format(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "epochs=range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title('Training and validation accuracy vs Epochs')\n",
    "plt.legend()\n",
    "accuracy_fig_name = \"accuracy.eps\"\n",
    "plt.savefig(os.path.join(char, accuracy_fig_name))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title('Training and validation loss vs Epochs')\n",
    "plt.legend()\n",
    "loss_fig_name = \"loss.eps\"\n",
    "\n",
    "plt.savefig(os.path.join(char, loss_fig_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: 72.98969030380249 %\n",
      "The validation accuracy is: 78.57142686843872 %\n",
      "The test accuracy is: 71.66666388511658 %\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = train_score[1]*100\n",
    "validation_accuracy = val_score[1]*100\n",
    "test_accuracy = test_score[1]*100\n",
    "\n",
    "print(\"The training accuracy is: \" + str(training_accuracy) + ' %')\n",
    "print(\"The validation accuracy is: \" + str(validation_accuracy) + ' %')\n",
    "print(\"The test accuracy is: \" + str(test_accuracy) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = test_score[1]*100\n",
    "test_precision = test_score[2]*100\n",
    "test_recall = test_score[3]*100\n",
    "tp = int(test_score[4])\n",
    "tn = int(test_score[5])\n",
    "fp = int(test_score[6])\n",
    "fn = int(test_score[7])\n",
    "\n",
    "f1 = 2*((test_precision*test_recall)/(test_precision+test_recall))\n",
    "sensitivity = (tp/(tp+fn))*100\n",
    "specificity = (tn/(tn+fp))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.66666388511658\n",
      "Test Precision: 71.66666388511658\n",
      "Test Recall: 100.0\n",
      "True Positive: 43\n",
      "Test Negetive: 0\n",
      "False Positive: 17\n",
      "False Negetive: 0\n",
      "Sensitivity: 100.0\n",
      "Specificity: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy: {}\".format(test_accuracy))\n",
    "print(\"Test Precision: {}\".format(test_precision))\n",
    "print(\"Test Recall: {}\".format(test_recall))\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "print(\"Test Negetive: {}\".format(tn))\n",
    "print(\"False Positive: {}\".format(fp))\n",
    "print(\"False Negetive: {}\".format(fn))\n",
    "print(\"Sensitivity: {}\".format(sensitivity))\n",
    "print(\"Specificity: {}\".format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please read the text file named readme.txt for detailed information of the model.\n"
     ]
    }
   ],
   "source": [
    "from contextlib import redirect_stdout\n",
    "\n",
    "readme_name_text = \"readme.txt\"\n",
    "print(\"Please read the text file named \" + readme_name_text + \" for detailed information of the model.\")\n",
    "\n",
    "completeName_txt = os.path.join(char, readme_name_text) \n",
    "\n",
    "readme = open(completeName_txt, \"w\")\n",
    "\n",
    "if len(os.listdir(TRAINING_DIR)) > 2:\n",
    "    readme.write(\"This is a MULTICLASS CLASSIFICATION\")\n",
    "else:\n",
    "    readme.write(\"This is a BINARY CLASSIFICATION\")\n",
    "\n",
    "\n",
    "readme.write(\"\\n\\n--HYPERPARAMETERS--\\n\")\n",
    "readme.write(str(augmentation))\n",
    "readme.write(\"\\nInitial Learning Rate = \" + str(learning_rate))\n",
    "readme.write(\"\\nNo. of epochs = \" + str(len(acc)))\n",
    "readme.write(\"\\nBatch Size = \" + str(batch_size))\n",
    "\n",
    "\n",
    "readme.write(\"\\n\\n--MODEL-PARAMETERS--\")\n",
    "readme.write(\"\\nActivation Function = relu\")\n",
    "readme.write(\"\\nDropout = \" + str(int(dropout*100)) + \"%\")\n",
    "readme.write(\"\\nActivation function of the output layer = \" + str(output_activation))\n",
    "readme.write(\"\\nCost function of the model = \" + str(losses))\n",
    "readme.write(\"\\nOptimizer = \" + str(optimizer) + \"\\n\\n\")\n",
    "\n",
    "\n",
    "readme.write(\"Trained on a VGG19 Model\\n\")\n",
    "with redirect_stdout(readme):\n",
    "    model.summary()\n",
    "        \n",
    "    \n",
    "readme.write(\"\\n\\n--MODEL-PERFORMANCE--\")\n",
    "readme.write(\"\\nTest Accuracy = \" + str(test_accuracy) + \" %\")\n",
    "readme.write(\"\\nTest Precision = \" + str(test_precision) + \" %\")\n",
    "readme.write(\"\\nTest Recall = \" + str(test_recall) + \" %\")\n",
    "readme.write(\"\\nTrue Positive = \" + str(tp))\n",
    "readme.write(\"\\nTrue Negetive = \" + str(tn))\n",
    "readme.write(\"\\nFalse Positive = \" + str(fp))\n",
    "readme.write(\"\\nFalse Negetive = \" + str(fn))\n",
    "readme.write(\"\\nSensitivity = \" + str(sensitivity))\n",
    "readme.write(\"\\nSpecificity = \" + str(specificity) + \" \\n\\n\\n\")\n",
    "\n",
    "\n",
    "readme.write(\"\\n\\n--MODEL-CHARACTERISTICS--\")\n",
    "readme.write(\"\\nacc = \" + str(acc))\n",
    "readme.write(\"\\n\\nval_acc = \" + str(val_acc))\n",
    "readme.write(\"\\n\\nloss = \" + str(loss))\n",
    "readme.write(\"\\n\\nval_loss = \" + str(val_loss))\n",
    "\n",
    "\n",
    "\n",
    "readme.write(\"\\nExecution Time: {} seconds\".format(duration))\n",
    "\n",
    "readme.write(\"\\n\\nCreated using Self-Regulated Image Classifier using Convolution Neural Network\")\n",
    "\n",
    "readme.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
