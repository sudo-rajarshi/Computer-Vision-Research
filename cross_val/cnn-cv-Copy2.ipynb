{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import matplotlib\n",
    "import glob\n",
    "import operator\n",
    "import psutil\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, GlobalMaxPooling2D, BatchNormalization, Conv2D, MaxPooling2D, Flatten\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify Train Dir: /home/rajarshi/Documents/DATASETS/Health/COVID/covid-chestxray-dataset-master (copy)/DATASET\n",
      "/home/rajarshi/Documents/DATASETS/Health/COVID/covid-chestxray-dataset-master (copy)/DATASET/classify train/training\n",
      "/home/rajarshi/Documents/DATASETS/Health/COVID/covid-chestxray-dataset-master (copy)/DATASET/classify train/validation\n",
      "/home/rajarshi/Documents/DATASETS/Health/COVID/covid-chestxray-dataset-master (copy)/DATASET/classify train/testing\n"
     ]
    }
   ],
   "source": [
    "classify_train_dir = str(input(\"Classify Train Dir: \"))\n",
    "classify_train = os.path.join(classify_train_dir, 'classify train')\n",
    "classify_train_lis = []\n",
    "for file in os.listdir(classify_train):\n",
    "    print(os.path.join(classify_train, file))\n",
    "    classify_train_lis.append(os.path.join(classify_train, file))\n",
    "\n",
    "TRAINING_DIR = classify_train_lis[0]\n",
    "VALIDATION_DIR = classify_train_lis[1]\n",
    "TESTING_DIR = classify_train_lis[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = []\n",
    "\n",
    "trainY = []\n",
    "\n",
    "i,j = 0,0\n",
    "for i in os.listdir(TRAINING_DIR):\n",
    "    for j in os.listdir(os.path.join(TRAINING_DIR, i)):\n",
    "        img = os.path.join(os.path.join(TRAINING_DIR, i), j)\n",
    "        x = cv2.imread(img)\n",
    "        trainX.append(x)\n",
    "\n",
    "        \n",
    "i,j = 0,0\n",
    "for i in range(1064):\n",
    "    trainY.append(0)\n",
    "for j in range(1064):\n",
    "    trainY.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.array(trainX)\n",
    "trainY = np.array(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2128, 224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2128,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_norm = trainX.astype('float32')\n",
    "\n",
    "trainX_norm = trainX_norm / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2128, 224, 224, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((trainX_norm, testX_norm), axis=0)\n",
    "y = np.concatenate((trainY, testY), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = float(input(\"Enter the initial learning rate: \"))\n",
    "epoch = int(input(\"Enter the maximum number of epochs: \"))\n",
    "batch_size = int(input(\"Enter batch size: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_name = str(input(\"Enter name of the characteristics folder: \"))\n",
    "\n",
    "char = os.path.join('/home/rajarshi/Documents/DATASETS/Health/COVID/covid-chestxray-dataset-master/DATASET', char_name)\n",
    "\n",
    "if not os.path.exists(char):\n",
    "    os.mkdir(char)\n",
    "else:\n",
    "    shutil.rmtree(char)\n",
    "    os.mkdir(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    return learning_rate * (0.1 ** int(epoch / 10))\n",
    "    \n",
    "best_model_address = os.path.join(char, 'best_model.h5')\n",
    "\n",
    "callback = [keras.callbacks.LearningRateScheduler(lr_schedule, verbose = 0),\n",
    "            keras.callbacks.EarlyStopping(monitor = 'loss', min_delta = 0.001, patience = 10, verbose=0, mode = 'min', restore_best_weights = True),\n",
    "            keras.callbacks.ModelCheckpoint(best_model_address, monitor = 'loss', verbose=0, save_best_only=True, save_weights_only=False, mode = 'min' , period=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = int(input(\"Press 1 to monitor Validation Accuracy\\nPress 2 to monitor Validation Loss\\nPress 3 to monitor Training Accuracy\\nPress 4 to monitor Training Loss\\n\"))\n",
    "patience = int(input('Enter number of epochs that will produce monitored quantity with no improvement after which training will be stopped: '))\n",
    "\n",
    "\n",
    "if monitor == 1:\n",
    "    metric = 'val_accuracy'\n",
    "    mode = 'max'\n",
    "    print(\"\\nMONITORING VALIDATION ACCURACY..........\\n\")\n",
    "\n",
    "elif monitor == 2:\n",
    "    metric = 'val_loss'\n",
    "    mode = 'min'\n",
    "    print(\"\\nMONITORING VALIDATION LOSS..........\\n\")\n",
    "\n",
    "elif monitor == 3:\n",
    "    metric = 'accuracy'\n",
    "    mode = 'max'\n",
    "    print(\"\\nMONITORING TRAINING ACCURACY..........\\n\")\n",
    "\n",
    "elif monitor == 4:\n",
    "    metric = 'loss'\n",
    "    mode = 'min'\n",
    "    print(\"\\nMONITORING TRAINING LOSS..........\\n\")\n",
    "\n",
    "callback = [keras.callbacks.LearningRateScheduler(lr_schedule, verbose = 0),\n",
    "            keras.callbacks.EarlyStopping(monitor = metric, min_delta = 0.001, patience = patience, verbose=0, mode = mode, restore_best_weights = True),\n",
    "            keras.callbacks.ModelCheckpoint(best_model_address, monitor = metric, verbose=0, save_best_only=True, save_weights_only=False, mode = mode , period=1)]\n",
    "\n",
    "print(\"\\nTraining will stop if Validation Accuracy doesn't show any improvements for \" + str(patience) + \" epcohs\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    print(\"\\nTRAINING ON A COMPLEX CUSTOM MODEL:-\")\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    for l in range(layer):\n",
    "        l += 1\n",
    "        m = (2**l)//2\n",
    "        for c in range(conv_layer):\n",
    "            model.add(Conv2D(conv*m, (conv_size, conv_size), padding = 'same', input_shape = dim, activation = activation))\n",
    "        model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense, activation=activation))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(output_layer, activation=output_activation))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(os.listdir(TRAINING_DIR)) > 2:\n",
    "    print(\"This is a \" + str(class_no) + \"-Class Classification\")\n",
    "    output_activation = 'softmax'\n",
    "    losses = 'categorical_crossentropy'\n",
    "    output_layer = class_no\n",
    "else:\n",
    "    print(\"This is a Binary Classification\")\n",
    "    output_activation = 'sigmoid'\n",
    "    losses = 'binary_crossentropy'\n",
    "    output_layer = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = int(input(\"Enter the no. of neurons in dense layer: \"))\n",
    "activation = str(input(\"Enter the activation function: \"))\n",
    "dropout = float(input(\"Enter the dropout percentage: \"))\n",
    "dropout = dropout/100\n",
    "\n",
    "layer = int(input(\"Enter number of layers you want to apply: \"))\n",
    "conv_layer = int(input(\"Enter number of convolution layers you want to apply: \"))\n",
    "conv = int(input(\"Enter the no. of filters in the 1st convolution layer: \"))\n",
    "conv_size = int(input(\"Enter the size of filters: \"))\n",
    "h = int(input(\"Image Dimension(H or W): \"))\n",
    "w = h\n",
    "dim = [h,w,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "train_scores, val_scores, histories = list(), list(), list()\n",
    "\n",
    "kfold = KFold(10, shuffle=True, random_state=1)\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "for train, test in kfold.split(x, y):\n",
    "    model = create_model()\n",
    "    model.compile(optimizer = optimizer, loss = losses, metrics = ['accuracy', \n",
    "                                                               tf.keras.metrics.Precision(), \n",
    "                                                               tf.keras.metrics.Recall(), \n",
    "                                                               tf.keras.metrics.TruePositives(), \n",
    "                                                               tf.keras.metrics.TrueNegatives(), \n",
    "                                                               tf.keras.metrics.FalsePositives(),\n",
    "                                                               tf.keras.metrics.FalseNegatives()])\n",
    "    \n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Training for fold {}...'.format(fold_no))\n",
    "    \n",
    "    history = model.fit(x[train], y[train], epochs=epoch, batch_size=batch_size, validation_data=(x[test], y[test]), callbacks = callback, verbose=0)\n",
    "    \n",
    "    train_score = model.evaluate(x[train], y[train], verbose=0)\n",
    "    val_score = model.evaluate(x[test], y[test], verbose=0)\n",
    "    \n",
    "    print(\"\\nTraining Acc: {}, Validation Acc: {}\".format(train_score[1],val_score[1]))\n",
    "    \n",
    "    train_scores.append(train_score)\n",
    "    val_scores.append(val_score)\n",
    "    histories.append(history)\n",
    "    \n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "val_acc = []\n",
    "tr_acc = []\n",
    "\n",
    "for i in range(len(val_scores)):\n",
    "    val_acc.append(val_scores[i][1])\n",
    "    tr_acc.append(train_scores[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(val_acc), np.std(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(tr_acc), np.std(tr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "for i in range(len(histories)):\n",
    "    plt.title('Training Loss')\n",
    "    plt.plot(histories[i].history['loss'], color='blue')\n",
    "\n",
    "plt.savefig(os.path.join(char, 'tr_loss.eps'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "for i in range(len(histories)):\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(histories[i].history['val_loss'], color='orange')\n",
    "    \n",
    "plt.savefig(os.path.join(char, 'val_loss.eps'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(histories)):\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.plot(histories[i].history['accuracy'], color='blue')\n",
    "\n",
    "plt.savefig(os.path.join(char, 'tr_acc.eps'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(histories)):\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.plot(histories[i].history['val_accuracy'], color='orange')\n",
    "\n",
    "plt.savefig(os.path.join(char, 'val_acc.eps'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_class_list = []\n",
    "for test_name in os.listdir(TESTING_DIR):\n",
    "    test = os.path.join(TESTING_DIR,test_name)\n",
    "    test_class_list.append(test)\n",
    "test_class_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pred(pred):\n",
    "    pred_categorical = keras.utils.to_categorical(pred)\n",
    "    if 1 > 2:\n",
    "        pred_max = np.argmax(pred)\n",
    "    else:\n",
    "        pred_max = np.argmax(pred_categorical)\n",
    "    return pred_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = testY\n",
    "labels = {'covid': 0, 'normal': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "model = tf.keras.models.load_model(os.path.join(char, 'best_model.h5'))\n",
    "\n",
    "y_pred = []\n",
    "for i in range(len(os.listdir(TRAINING_DIR))):\n",
    "    for filename in os.listdir(test_class_list[i]):\n",
    "        file = os.path.join(test_class_list[i], filename)\n",
    "        img = image.load_img(file, target_size=(224,224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "\n",
    "        images = np.vstack([x])\n",
    "\n",
    "        pred = model.predict(images, batch_size = 10)\n",
    "        pred_max = max_pred(pred)\n",
    "        \n",
    "        y_pred.append(pred_max)\n",
    " \n",
    "print(\"Calculating CLASSIFICATION REPORT..........:\")\n",
    "classification_report = classification_report(y_true, y_pred, target_names=labels)\n",
    "print(classification_report)\n",
    "\n",
    "print(\"\\nCalculating SENSITIVITY & SPECIFICITY..........:\")\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "total = sum(sum(cm))\n",
    "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "\n",
    "print(\"sensitivity = {:.4f}\".format(sensitivity))\n",
    "print(\"specificity = {:.4f}\".format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_confusion_matrix(conf_mat=cm,\n",
    "                                colorbar=True,\n",
    "                                show_absolute=True,\n",
    "                                show_normed=True)\n",
    "\n",
    "plt.savefig(os.path.join(char, 'cm.eps'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
