{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import matplotlib\n",
    "import glob\n",
    "import operator\n",
    "import psutil\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify Train Dir: /mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr\n"
     ]
    }
   ],
   "source": [
    "classify_train_dir = str(input(\"Classify Train Dir: \"))\n",
    "classify_train = os.path.join(classify_train_dir, 'classify train')\n",
    "\n",
    "    \n",
    "TRAINING_DIR = os.path.join(classify_train, 'training')\n",
    "VALIDATION_DIR = os.path.join(classify_train, 'validation')\n",
    "TESTING_DIR = os.path.join(classify_train, 'testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/classify train/training',\n",
       " '/mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/classify train/validation',\n",
       " '/mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/classify train/testing')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_DIR, VALIDATION_DIR, TESTING_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the initial learning rate: 0.001\n",
      "Enter the maximum number of epochs: 100\n",
      "Enter batch size: 8\n"
     ]
    }
   ],
   "source": [
    "learning_rate = float(input(\"Enter the initial learning rate: \"))\n",
    "epoch = int(input(\"Enter the maximum number of epochs: \"))\n",
    "batch_size = int(input(\"Enter batch size: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter name of the characteristics folder: xception\n"
     ]
    }
   ],
   "source": [
    "char_name = str(input(\"Enter name of the characteristics folder: \"))\n",
    "\n",
    "char = os.path.join(classify_train_dir, char_name)\n",
    "\n",
    "if not os.path.exists(char):\n",
    "    os.mkdir(char)\n",
    "else:\n",
    "    replace = str(input(\"Folder already exists ! Do you want to replace it ?(Y/N) \"))\n",
    "    if replace.upper() == 'Y':      \n",
    "        shutil.rmtree(char)\n",
    "        os.mkdir(char)\n",
    "    elif replace.upper() == 'N':\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    return learning_rate * (0.1 ** int(epoch / 10))\n",
    "    \n",
    "best_model_address = os.path.join(char, 'best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 1 to monitor Validation Accuracy\n",
      "Press 2 to monitor Validation Loss\n",
      "Press 3 to monitor Training Accuracy\n",
      "Press 4 to monitor Training Loss\n",
      "4\n",
      "Enter number of epochs that will produce monitored quantity with no improvement after which training will be stopped: 10\n",
      "\n",
      "MONITORING TRAINING LOSS..........\n",
      "\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "Training will stop if Validation Accuracy doesn't show any improvements for 10 epcohs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "monitor = int(input(\"Press 1 to monitor Validation Accuracy\\nPress 2 to monitor Validation Loss\\nPress 3 to monitor Training Accuracy\\nPress 4 to monitor Training Loss\\n\"))\n",
    "patience = int(input('Enter number of epochs that will produce monitored quantity with no improvement after which training will be stopped: '))\n",
    "\n",
    "\n",
    "if monitor == 1:\n",
    "    metric = 'val_accuracy'\n",
    "    mode = 'max'\n",
    "    print(\"\\nMONITORING VALIDATION ACCURACY..........\\n\")\n",
    "\n",
    "elif monitor == 2:\n",
    "    metric = 'val_loss'\n",
    "    mode = 'min'\n",
    "    print(\"\\nMONITORING VALIDATION LOSS..........\\n\")\n",
    "\n",
    "elif monitor == 3:\n",
    "    metric = 'accuracy'\n",
    "    mode = 'max'\n",
    "    print(\"\\nMONITORING TRAINING ACCURACY..........\\n\")\n",
    "\n",
    "elif monitor == 4:\n",
    "    metric = 'loss'\n",
    "    mode = 'min'\n",
    "    print(\"\\nMONITORING TRAINING LOSS..........\\n\")\n",
    "\n",
    "callback = [keras.callbacks.LearningRateScheduler(lr_schedule, verbose = 1),\n",
    "            keras.callbacks.EarlyStopping(monitor = metric, min_delta = 0.001, patience = patience, verbose=1, mode = mode, restore_best_weights = True),\n",
    "            keras.callbacks.ModelCheckpoint(best_model_address, monitor = metric, verbose=1, save_best_only=True, save_weights_only=False, mode = mode , period=1)]\n",
    "\n",
    "print(\"\\nTraining will stop if Validation Accuracy doesn't show any improvements for \" + str(patience) + \" epcohs\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xception():\n",
    "    print(\"\\nTRAINING ON Xception MODEL:-\")\n",
    "\n",
    "    base_model = keras.applications.Xception(input_shape = dim, weights = 'imagenet', include_top = False)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(dense)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    predictions = Dense(output_layer, activation = output_activation)(x)\n",
    "\n",
    "    model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "    train_base_model = str(input(\"Do you want to train the base model of Xception?(Y/N) \"))\n",
    "    if train_base_model.upper() == 'Y':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    elif train_base_model.upper() == 'N':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a 3-Class Classification\n"
     ]
    }
   ],
   "source": [
    "class_no = len(os.listdir(TRAINING_DIR))\n",
    "\n",
    "if class_no > 2:\n",
    "    print(\"This is a \" + str(class_no) + \"-Class Classification\")\n",
    "    output_activation = 'softmax'\n",
    "    losses = 'categorical_crossentropy'\n",
    "    class_mode = 'categorical'\n",
    "    output_layer = class_no\n",
    "else:\n",
    "    print(\"This is a Binary Classification\")\n",
    "    output_activation = 'sigmoid'\n",
    "    losses = 'binary_crossentropy'\n",
    "    class_mode = 'binary'\n",
    "    output_layer = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_selection():\n",
    "    print(\"\\nSelect a optimizer which will reduce the loss of the model.\\n\")\n",
    "\n",
    "    optimizer_select = int(input(\"Press 1 to select Stochastic Gradient Descent\\nPress 2 to select RMSprop\\nPress 3 to select Adagrad\\nPress 4 to select Adadelta\\nPress 5 to select Adam\\nPress 6 to select Adamax\\nPress 7 to select Nadam\\n\"))\n",
    "\n",
    "    if optimizer_select == 1:\n",
    "        optimizer = SGD(lr = learning_rate, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "\n",
    "    elif optimizer_select == 2:\n",
    "        optimizer = RMSprop(learning_rate, rho = 0.9)\n",
    "\n",
    "    elif optimizer_select == 3:\n",
    "        optimizer = Adagrad(learning_rate)\n",
    "\n",
    "    elif optimizer_select == 4:\n",
    "        optimizer = Adadelta(learning_rate, rho = 0.95)\n",
    "\n",
    "    elif optimizer_select == 5:\n",
    "        optimizer = Adam(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\n",
    "\n",
    "    elif optimizer_select == 6:\n",
    "        optimizer = Adamax(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999)\n",
    "\n",
    "    elif optimizer_select == 7:\n",
    "        optimizer = Nadam(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999)\n",
    "   \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Dimension(H or W): 128\n"
     ]
    }
   ],
   "source": [
    "h = int(input(\"Image Dimension(H or W): \"))\n",
    "w = h\n",
    "dim = [h,w,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8591 images belonging to 3 classes.\n",
      "Found 399 images belonging to 3 classes.\n",
      "Found 1995 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    class_mode = class_mode,\n",
    "                                                    target_size = (h,w),\n",
    "                                                    shuffle=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                              batch_size = batch_size,\n",
    "                                                              class_mode = class_mode,\n",
    "                                                              target_size = (h,w),\n",
    "                                                              shuffle=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "test_generator = test_datagen.flow_from_directory(TESTING_DIR,\n",
    "                                                  batch_size = batch_size,\n",
    "                                                  class_mode = class_mode,\n",
    "                                                  target_size = (h,w),\n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the no. of neurons in dense layer: 128\n",
      "Enter the dropout percentage: 20\n",
      "\n",
      "Select a optimizer which will reduce the loss of the model.\n",
      "\n",
      "Press 1 to select Stochastic Gradient Descent\n",
      "Press 2 to select RMSprop\n",
      "Press 3 to select Adagrad\n",
      "Press 4 to select Adadelta\n",
      "Press 5 to select Adam\n",
      "Press 6 to select Adamax\n",
      "Press 7 to select Nadam\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "dense = int(input(\"Enter the no. of neurons in dense layer: \"))\n",
    "dropout = float(input(\"Enter the dropout percentage: \"))\n",
    "dropout = dropout/100\n",
    "\n",
    "optimizer = optimizer_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING ON Xception MODEL:-\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 12s 0us/step\n",
      "Do you want to train the base model of Xception?(Y/N) y\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 63, 63, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 63, 63, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 63, 63, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 61, 61, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 61, 61, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 61, 61, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 61, 61, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 61, 61, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 61, 61, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 31, 31, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 31, 31, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 31, 31, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 31, 31, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 31, 31, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 31, 31, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 31, 31, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 31, 31, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 16, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 16, 16, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16, 16, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 16, 16, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 16, 16, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 16, 16, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 16, 16, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 8, 8, 728)    186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 8, 8, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 8, 8, 728)    2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 8, 8, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 8, 8, 728)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 8, 8, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 8, 8, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 8, 8, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 8, 8, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 8, 8, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 8, 8, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 8, 8, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 8, 8, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 8, 8, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 8, 8, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 8, 8, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 8, 8, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 8, 8, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 8, 8, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 8, 8, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 8, 8, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 8, 8, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 8, 8, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 8, 8, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 8, 8, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 8, 8, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 8, 8, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 8, 8, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 4, 4, 1024)   745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 4, 4, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 4, 4, 1024)   4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 4, 4, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 4, 4, 1536)   1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 4, 4, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 4, 4, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 4, 4, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 4, 4, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 4, 4, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          262272      global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128)          512         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            387         batch_normalization_4[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 21,124,651\n",
      "Trainable params: 21,069,867\n",
      "Non-trainable params: 54,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Xception()\n",
    "model.compile(optimizer = optimizer, loss = losses, metrics = ['accuracy', \n",
    "                                                               tf.keras.metrics.Precision(), \n",
    "                                                               tf.keras.metrics.Recall(), \n",
    "                                                               tf.keras.metrics.TruePositives(), \n",
    "                                                               tf.keras.metrics.TrueNegatives(), \n",
    "                                                               tf.keras.metrics.FalsePositives(),\n",
    "                                                               tf.keras.metrics.FalseNegatives()])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n",
      "1074/1074 [==============================] - 73s 61ms/step - loss: 0.4705 - accuracy: 0.8346 - precision: 0.8460 - recall: 0.8187 - true_positives: 3677.4158 - true_negatives: 8088.7060 - false_positives: 518.3767 - false_negatives: 626.1256 - val_loss: 0.0654 - val_accuracy: 0.9774 - val_precision: 0.9799 - val_recall: 0.9774 - val_true_positives: 390.0000 - val_true_negatives: 790.0000 - val_false_positives: 8.0000 - val_false_negatives: 9.0000\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.31867, saving model to /mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/xception/best_model.h5\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n",
      "1074/1074 [==============================] - 64s 60ms/step - loss: 0.1447 - accuracy: 0.9561 - precision: 0.9592 - recall: 0.9556 - true_positives: 4109.9609 - true_negatives: 8429.6214 - false_positives: 178.3302 - false_negatives: 194.0149 - val_loss: 0.1139 - val_accuracy: 0.9749 - val_precision: 0.9749 - val_recall: 0.9749 - val_true_positives: 389.0000 - val_true_negatives: 788.0000 - val_false_positives: 10.0000 - val_false_negatives: 10.0000\n",
      "\n",
      "Epoch 00002: loss improved from 0.31867 to 0.14517, saving model to /mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/xception/best_model.h5\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n",
      "1074/1074 [==============================] - 65s 60ms/step - loss: 0.1254 - accuracy: 0.9624 - precision: 0.9635 - recall: 0.9602 - true_positives: 4132.0670 - true_negatives: 8449.3191 - false_positives: 158.0428 - false_negatives: 171.6140 - val_loss: 0.1094 - val_accuracy: 0.9674 - val_precision: 0.9698 - val_recall: 0.9649 - val_true_positives: 385.0000 - val_true_negatives: 786.0000 - val_false_positives: 12.0000 - val_false_negatives: 14.0000\n",
      "\n",
      "Epoch 00003: loss improved from 0.14517 to 0.12197, saving model to /mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/xception/best_model.h5\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n",
      "1074/1074 [==============================] - 65s 61ms/step - loss: 0.0957 - accuracy: 0.9696 - precision: 0.9701 - recall: 0.9685 - true_positives: 4173.4642 - true_negatives: 8483.7042 - false_positives: 123.6484 - false_negatives: 130.2121 - val_loss: 0.0404 - val_accuracy: 0.9875 - val_precision: 0.9899 - val_recall: 0.9850 - val_true_positives: 393.0000 - val_true_negatives: 794.0000 - val_false_positives: 4.0000 - val_false_negatives: 6.0000\n",
      "\n",
      "Epoch 00004: loss improved from 0.12197 to 0.09165, saving model to /mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/xception/best_model.h5\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n",
      "1074/1074 [==============================] - 65s 60ms/step - loss: 0.0945 - accuracy: 0.9698 - precision: 0.9702 - recall: 0.9692 - true_positives: 4186.7656 - true_negatives: 8494.2558 - false_positives: 112.2763 - false_negatives: 116.5005 - val_loss: 0.1157 - val_accuracy: 0.9699 - val_precision: 0.9699 - val_recall: 0.9699 - val_true_positives: 387.0000 - val_true_negatives: 786.0000 - val_false_positives: 12.0000 - val_false_negatives: 12.0000\n",
      "\n",
      "Epoch 00005: loss improved from 0.09165 to 0.08614, saving model to /mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/xception/best_model.h5\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n",
      "1074/1074 [==============================] - 67s 62ms/step - loss: 0.0747 - accuracy: 0.9772 - precision: 0.9777 - recall: 0.9771 - true_positives: 4209.1535 - true_negatives: 8514.0967 - false_positives: 91.9777 - false_negatives: 93.8837 - val_loss: 0.8340 - val_accuracy: 0.7669 - val_precision: 0.7688 - val_recall: 0.7669 - val_true_positives: 306.0000 - val_true_negatives: 706.0000 - val_false_positives: 92.0000 - val_false_negatives: 93.0000\n",
      "\n",
      "Epoch 00006: loss improved from 0.08614 to 0.07515, saving model to /mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/xception/best_model.h5\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n",
      "1074/1074 [==============================] - 68s 63ms/step - loss: 0.0531 - accuracy: 0.9849 - precision: 0.9850 - recall: 0.9843 - true_positives: 4231.3191 - true_negatives: 8537.3674 - false_positives: 69.3042 - false_negatives: 72.0167 - val_loss: 0.0336 - val_accuracy: 0.9875 - val_precision: 0.9875 - val_recall: 0.9875 - val_true_positives: 394.0000 - val_true_negatives: 793.0000 - val_false_positives: 5.0000 - val_false_negatives: 5.0000\n",
      "\n",
      "Epoch 00007: loss improved from 0.07515 to 0.06295, saving model to /mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/xception/best_model.h5\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n",
      "1074/1074 [==============================] - 66s 62ms/step - loss: 0.0319 - accuracy: 0.9898 - precision: 0.9905 - recall: 0.9898 - true_positives: 4255.0726 - true_negatives: 8561.0251 - false_positives: 45.2260 - false_negatives: 48.0530 - val_loss: 0.3985 - val_accuracy: 0.8947 - val_precision: 0.9013 - val_recall: 0.8922 - val_true_positives: 356.0000 - val_true_negatives: 759.0000 - val_false_positives: 39.0000 - val_false_negatives: 43.0000\n",
      "\n",
      "Epoch 00008: loss improved from 0.06295 to 0.04842, saving model to /mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/xception/best_model.h5\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n",
      "1074/1074 [==============================] - 62s 58ms/step - loss: 0.0557 - accuracy: 0.9838 - precision: 0.9846 - recall: 0.9832 - true_positives: 4237.6772 - true_negatives: 8546.5898 - false_positives: 59.7860 - false_negatives: 65.5107 - val_loss: 0.0486 - val_accuracy: 0.9825 - val_precision: 0.9825 - val_recall: 0.9825 - val_true_positives: 392.0000 - val_true_negatives: 791.0000 - val_false_positives: 7.0000 - val_false_negatives: 7.0000\n",
      "\n",
      "Epoch 00009: loss improved from 0.04842 to 0.04799, saving model to /mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/xception/best_model.h5\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n",
      "1074/1074 [==============================] - 62s 58ms/step - loss: 0.0238 - accuracy: 0.9934 - precision: 0.9934 - recall: 0.9929 - true_positives: 4268.5144 - true_negatives: 8573.1851 - false_positives: 33.8512 - false_negatives: 35.0037 - val_loss: 0.0337 - val_accuracy: 0.9825 - val_precision: 0.9825 - val_recall: 0.9825 - val_true_positives: 392.0000 - val_true_negatives: 791.0000 - val_false_positives: 7.0000 - val_false_negatives: 7.0000\n",
      "\n",
      "Epoch 00010: loss improved from 0.04799 to 0.03133, saving model to /mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/xception/best_model.h5\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "1074/1074 [==============================] - 62s 58ms/step - loss: 0.0125 - accuracy: 0.9964 - precision: 0.9966 - recall: 0.9964 - true_positives: 4286.0660 - true_negatives: 8590.0298 - false_positives: 16.4744 - false_negatives: 17.1860 - val_loss: 0.0198 - val_accuracy: 0.9925 - val_precision: 0.9925 - val_recall: 0.9925 - val_true_positives: 396.0000 - val_true_negatives: 795.0000 - val_false_positives: 3.0000 - val_false_negatives: 3.0000\n",
      "\n",
      "Epoch 00011: loss improved from 0.03133 to 0.01219, saving model to /mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/xception/best_model.h5\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "1074/1074 [==============================] - 62s 57ms/step - loss: 0.0048 - accuracy: 0.9986 - precision: 0.9987 - recall: 0.9986 - true_positives: 4297.6763 - true_negatives: 8601.9972 - false_positives: 5.2940 - false_negatives: 5.9693 - val_loss: 0.0197 - val_accuracy: 0.9925 - val_precision: 0.9925 - val_recall: 0.9925 - val_true_positives: 396.0000 - val_true_negatives: 795.0000 - val_false_positives: 3.0000 - val_false_negatives: 3.0000\n",
      "\n",
      "Epoch 00012: loss improved from 0.01219 to 0.00541, saving model to /mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/xception/best_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "1074/1074 [==============================] - 62s 58ms/step - loss: 0.0085 - accuracy: 0.9988 - precision: 0.9988 - recall: 0.9988 - true_positives: 4298.1014 - true_negatives: 8601.1786 - false_positives: 4.9758 - false_negatives: 4.9758 - val_loss: 0.0198 - val_accuracy: 0.9925 - val_precision: 0.9925 - val_recall: 0.9925 - val_true_positives: 396.0000 - val_true_negatives: 795.0000 - val_false_positives: 3.0000 - val_false_negatives: 3.0000\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00541\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "1074/1074 [==============================] - 62s 57ms/step - loss: 0.0018 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999 - true_positives: 4302.9795 - true_negatives: 8606.6995 - false_positives: 0.5172 - false_negatives: 0.6288 - val_loss: 0.0184 - val_accuracy: 0.9925 - val_precision: 0.9925 - val_recall: 0.9925 - val_true_positives: 396.0000 - val_true_negatives: 795.0000 - val_false_positives: 3.0000 - val_false_negatives: 3.0000\n",
      "\n",
      "Epoch 00014: loss improved from 0.00541 to 0.00535, saving model to /mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/xception/best_model.h5\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "1074/1074 [==============================] - 62s 57ms/step - loss: 0.0014 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - true_positives: 4303.0577 - true_negatives: 8606.2270 - false_positives: 0.1116 - false_negatives: 0.1116 - val_loss: 0.0218 - val_accuracy: 0.9925 - val_precision: 0.9925 - val_recall: 0.9925 - val_true_positives: 396.0000 - val_true_negatives: 795.0000 - val_false_positives: 3.0000 - val_false_negatives: 3.0000\n",
      "\n",
      "Epoch 00015: loss improved from 0.00535 to 0.00153, saving model to /mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/xception/best_model.h5\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "1074/1074 [==============================] - 62s 58ms/step - loss: 0.0017 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - true_positives: 4303.2298 - true_negatives: 8606.6093 - false_positives: 0.1498 - false_negatives: 0.1498 - val_loss: 0.0112 - val_accuracy: 0.9950 - val_precision: 0.9950 - val_recall: 0.9950 - val_true_positives: 397.0000 - val_true_negatives: 796.0000 - val_false_positives: 2.0000 - val_false_negatives: 2.0000\n",
      "\n",
      "Epoch 00016: loss improved from 0.00153 to 0.00133, saving model to /mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/xception/best_model.h5\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "1074/1074 [==============================] - 62s 57ms/step - loss: 0.0020 - accuracy: 0.9997 - precision: 0.9997 - recall: 0.9997 - true_positives: 4302.4502 - true_negatives: 8606.0893 - false_positives: 1.1888 - false_negatives: 1.1888 - val_loss: 0.0095 - val_accuracy: 0.9925 - val_precision: 0.9925 - val_recall: 0.9925 - val_true_positives: 396.0000 - val_true_negatives: 795.0000 - val_false_positives: 3.0000 - val_false_negatives: 3.0000\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00133\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "1074/1074 [==============================] - 63s 59ms/step - loss: 0.0159 - accuracy: 0.9977 - precision: 0.9977 - recall: 0.9977 - true_positives: 4295.2791 - true_negatives: 8598.4902 - false_positives: 7.9321 - false_negatives: 7.9321 - val_loss: 0.0092 - val_accuracy: 0.9950 - val_precision: 0.9950 - val_recall: 0.9950 - val_true_positives: 397.0000 - val_true_negatives: 796.0000 - val_false_positives: 2.0000 - val_false_negatives: 2.0000\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00133\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "1074/1074 [==============================] - 63s 58ms/step - loss: 0.0234 - accuracy: 0.9980 - precision: 0.9980 - recall: 0.9980 - true_positives: 4298.3395 - true_negatives: 8601.4047 - false_positives: 4.7256 - false_negatives: 4.7256 - val_loss: 0.0104 - val_accuracy: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975 - val_true_positives: 398.0000 - val_true_negatives: 797.0000 - val_false_positives: 1.0000 - val_false_negatives: 1.0000\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00133\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "1074/1074 [==============================] - 62s 58ms/step - loss: 0.0025 - accuracy: 0.9997 - precision: 0.9997 - recall: 0.9997 - true_positives: 4303.0902 - true_negatives: 8607.0707 - false_positives: 0.8902 - false_negatives: 0.8902 - val_loss: 0.0091 - val_accuracy: 0.9950 - val_precision: 0.9950 - val_recall: 0.9950 - val_true_positives: 397.0000 - val_true_negatives: 796.0000 - val_false_positives: 2.0000 - val_false_negatives: 2.0000\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00133\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 1.0000000000000003e-05.\n",
      "1074/1074 [==============================] - 62s 58ms/step - loss: 6.8359e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - true_positives: 4303.1237 - true_negatives: 8606.2474 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.9950 - val_precision: 0.9950 - val_recall: 0.9950 - val_true_positives: 397.0000 - val_true_negatives: 796.0000 - val_false_positives: 2.0000 - val_false_negatives: 2.0000\n",
      "\n",
      "Epoch 00021: loss improved from 0.00133 to 0.00091, saving model to /mnt/335fff25-d210-4fe2-8249-4ba8b4a17ce4/DATASETS/Shrabana/cov-cxr/xception/best_model.h5\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 1.0000000000000003e-05.\n",
      "1074/1074 [==============================] - 67s 63ms/step - loss: 0.0190 - accuracy: 0.9983 - precision: 0.9983 - recall: 0.9983 - true_positives: 4297.9767 - true_negatives: 8601.6316 - false_positives: 5.6781 - false_negatives: 5.6781 - val_loss: 0.0093 - val_accuracy: 0.9950 - val_precision: 0.9950 - val_recall: 0.9950 - val_true_positives: 397.0000 - val_true_negatives: 796.0000 - val_false_positives: 2.0000 - val_false_negatives: 2.0000\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00091\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 1.0000000000000003e-05.\n",
      "1074/1074 [==============================] - 67s 63ms/step - loss: 0.0059 - accuracy: 0.9998 - precision: 0.9998 - recall: 0.9997 - true_positives: 4302.0474 - true_negatives: 8606.3972 - false_positives: 0.7674 - false_negatives: 1.5349 - val_loss: 0.0096 - val_accuracy: 0.9950 - val_precision: 0.9950 - val_recall: 0.9950 - val_true_positives: 397.0000 - val_true_negatives: 796.0000 - val_false_positives: 2.0000 - val_false_negatives: 2.0000\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00091\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 1.0000000000000003e-05.\n",
      "1074/1074 [==============================] - 67s 63ms/step - loss: 0.0083 - accuracy: 0.9996 - precision: 0.9996 - recall: 0.9996 - true_positives: 4300.9488 - true_negatives: 8604.3386 - false_positives: 2.4409 - false_negatives: 2.4409 - val_loss: 0.0086 - val_accuracy: 0.9950 - val_precision: 0.9950 - val_recall: 0.9950 - val_true_positives: 397.0000 - val_true_negatives: 796.0000 - val_false_positives: 2.0000 - val_false_negatives: 2.0000\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00091\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1.0000000000000003e-05.\n",
      "1074/1074 [==============================] - 67s 63ms/step - loss: 0.0035 - accuracy: 0.9997 - precision: 0.9997 - recall: 0.9997 - true_positives: 4301.9740 - true_negatives: 8605.5805 - false_positives: 1.6326 - false_negatives: 1.6326 - val_loss: 0.0097 - val_accuracy: 0.9950 - val_precision: 0.9950 - val_recall: 0.9950 - val_true_positives: 397.0000 - val_true_negatives: 796.0000 - val_false_positives: 2.0000 - val_false_negatives: 2.0000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00091\n",
      "Epoch 00025: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1074/1074 [==============================] - 20s 19ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - true_positives: 8591.0000 - true_negatives: 17182.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 0.0218 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - true_positives: 396.0000 - true_negatives: 795.0000 - false_positives: 3.0000 - false_negatives: 3.0000\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 0.1084 - accuracy: 0.9704 - precision: 0.9704 - recall: 0.9689 - true_positives: 1933.0000 - true_negatives: 3931.0000 - false_positives: 59.0000 - false_negatives: 62.0000\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    start = time.time()\n",
    "    history = model.fit(train_generator,\n",
    "                        epochs = epoch,\n",
    "                        verbose = 1,\n",
    "                        callbacks = callback,\n",
    "                        validation_data = validation_generator,\n",
    "                        shuffle=True)\n",
    "\n",
    "    end = time.time()\n",
    "    duration = end-start\n",
    "\n",
    "train_score = model.evaluate(train_generator)\n",
    "val_score = model.evaluate(validation_generator)\n",
    "test_score = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 1661.0059010982513 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Execution Time: {} seconds\".format(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "epochs=range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title('Training and validation accuracy vs Epochs')\n",
    "plt.legend()\n",
    "accuracy_fig_name = \"accuracy.eps\"\n",
    "plt.savefig(os.path.join(char, accuracy_fig_name))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title('Training and validation loss vs Epochs')\n",
    "plt.legend()\n",
    "loss_fig_name = \"loss.eps\"\n",
    "\n",
    "plt.savefig(os.path.join(char, loss_fig_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: 100.0 %\n",
      "The validation accuracy is: 99.24812316894531 %\n",
      "The test accuracy is: 97.0426082611084 %\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = train_score[1]*100\n",
    "validation_accuracy = val_score[1]*100\n",
    "test_accuracy = test_score[1]*100\n",
    "\n",
    "print(\"The training accuracy is: \" + str(training_accuracy) + ' %')\n",
    "print(\"The validation accuracy is: \" + str(validation_accuracy) + ' %')\n",
    "print(\"The test accuracy is: \" + str(test_accuracy) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = test_score[1]*100\n",
    "test_precision = test_score[2]*100\n",
    "test_recall = test_score[3]*100\n",
    "tp = int(test_score[4])\n",
    "tn = int(test_score[5])\n",
    "fp = int(test_score[6])\n",
    "fn = int(test_score[7])\n",
    "\n",
    "f1 = 2*((test_precision*test_recall)/(test_precision+test_recall))\n",
    "sensitivity = (tp/(tp+fn))*100\n",
    "specificity = (tn/(tn+fp))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.0426082611084\n",
      "Test Precision: 97.0381498336792\n",
      "Test Recall: 96.89223170280457\n",
      "True Positive: 1933\n",
      "Test Negetive: 3931\n",
      "False Positive: 59\n",
      "False Negetive: 62\n",
      "Sensitivity: 96.89223057644111\n",
      "Specificity: 98.52130325814537\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy: {}\".format(test_accuracy))\n",
    "print(\"Test Precision: {}\".format(test_precision))\n",
    "print(\"Test Recall: {}\".format(test_recall))\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "print(\"Test Negetive: {}\".format(tn))\n",
    "print(\"False Positive: {}\".format(fp))\n",
    "print(\"False Negetive: {}\".format(fn))\n",
    "print(\"Sensitivity: {}\".format(sensitivity))\n",
    "print(\"Specificity: {}\".format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please read the text file named readme.txt for detailed information of the model.\n"
     ]
    }
   ],
   "source": [
    "from contextlib import redirect_stdout\n",
    "\n",
    "readme_name_text = \"readme.txt\"\n",
    "print(\"Please read the text file named \" + readme_name_text + \" for detailed information of the model.\")\n",
    "\n",
    "completeName_txt = os.path.join(char, readme_name_text) \n",
    "\n",
    "readme = open(completeName_txt, \"w\")\n",
    "\n",
    "if len(os.listdir(TRAINING_DIR)) > 2:\n",
    "    readme.write(\"This is a MULTICLASS CLASSIFICATION\")\n",
    "else:\n",
    "    readme.write(\"This is a BINARY CLASSIFICATION\")\n",
    "\n",
    "\n",
    "readme.write(\"\\n\\n--HYPERPARAMETERS--\\n\")\n",
    "readme.write(\"\\nInitial Learning Rate = \" + str(learning_rate))\n",
    "readme.write(\"\\nNo. of epochs = \" + str(len(acc)))\n",
    "readme.write(\"\\nBatch Size = \" + str(batch_size))\n",
    "\n",
    "\n",
    "readme.write(\"\\n\\n--MODEL-PARAMETERS--\")\n",
    "readme.write(\"\\nActivation Function = relu\")\n",
    "readme.write(\"\\nDropout = \" + str(int(dropout*100)) + \"%\")\n",
    "readme.write(\"\\nActivation function of the output layer = \" + str(output_activation))\n",
    "readme.write(\"\\nCost function of the model = \" + str(losses))\n",
    "readme.write(\"\\nOptimizer = \" + str(optimizer) + \"\\n\\n\")\n",
    "\n",
    "\n",
    "readme.write(\"Trained on a Resnet50 Model\\n\")\n",
    "with redirect_stdout(readme):\n",
    "    model.summary()\n",
    "        \n",
    "    \n",
    "readme.write(\"\\n\\n--MODEL-PERFORMANCE--\")\n",
    "readme.write(\"\\nTest Accuracy = \" + str(test_accuracy) + \" %\")\n",
    "readme.write(\"\\nTest Precision = \" + str(test_precision) + \" %\")\n",
    "readme.write(\"\\nTest Recall = \" + str(test_recall) + \" %\")\n",
    "readme.write(\"\\nTrue Positive = \" + str(tp))\n",
    "readme.write(\"\\nTrue Negetive = \" + str(tn))\n",
    "readme.write(\"\\nFalse Positive = \" + str(fp))\n",
    "readme.write(\"\\nFalse Negetive = \" + str(fn))\n",
    "readme.write(\"\\nSensitivity = \" + str(sensitivity))\n",
    "readme.write(\"\\nSpecificity = \" + str(specificity) + \" \\n\\n\\n\")\n",
    "\n",
    "\n",
    "readme.write(\"\\n\\n--MODEL-CHARACTERISTICS--\")\n",
    "readme.write(\"\\nacc = \" + str(acc))\n",
    "readme.write(\"\\n\\nval_acc = \" + str(val_acc))\n",
    "readme.write(\"\\n\\nloss = \" + str(loss))\n",
    "readme.write(\"\\n\\nval_loss = \" + str(val_loss))\n",
    "\n",
    "\n",
    "readme.write(\"\\nExecution Time: {} seconds\".format(duration))\n",
    "\n",
    "readme.write(\"\\n\\nCreated using Self-Regulated Image Classifier using Convolution Neural Network\")\n",
    "\n",
    "readme.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
