{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import matplotlib\n",
    "import glob\n",
    "import operator\n",
    "import psutil\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, GlobalMaxPooling2D, BatchNormalization, Conv2D, MaxPooling2D, Flatten\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify Train Dir: /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus\n",
      "/home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/classify train/testing\n",
      "/home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/classify train/training\n",
      "/home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/classify train/validation\n"
     ]
    }
   ],
   "source": [
    "classify_train_dir = str(input(\"Classify Train Dir: \"))\n",
    "classify_train = os.path.join(classify_train_dir, 'classify train')\n",
    "\n",
    "    \n",
    "TRAINING_DIR = os.path.join(classify_train, 'training')\n",
    "VALIDATION_DIR = os.path.join(classify_train, 'validation')\n",
    "TESTING_DIR = os.path.join(classify_train, 'testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/classify train/training',\n",
       " '/home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/classify train/validation',\n",
       " '/home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/classify train/testing')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_DIR, VALIDATION_DIR, TESTING_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the initial learning rate: 0.0001\n",
      "Enter the maximum number of epochs: 100\n",
      "Enter batch size: 5\n"
     ]
    }
   ],
   "source": [
    "learning_rate = float(input(\"Enter the initial learning rate: \"))\n",
    "epoch = int(input(\"Enter the maximum number of epochs: \"))\n",
    "batch_size = int(input(\"Enter batch size: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter name of the characteristics folder: resnet50_1\n"
     ]
    }
   ],
   "source": [
    "char_name = str(input(\"Enter name of the characteristics folder: \"))\n",
    "\n",
    "char = os.path.join(classify_train_dir, char_name)\n",
    "\n",
    "if not os.path.exists(char):\n",
    "    os.mkdir(char)\n",
    "else:\n",
    "    replace = str(input(\"Folder already exists ! Do you want to replace it ?(Y/N) \"))\n",
    "    if replace.upper() == 'Y':      \n",
    "        shutil.rmtree(char)\n",
    "        os.mkdir(char)\n",
    "    elif replace.upper() == 'N':\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    return learning_rate * (0.1 ** int(epoch / 10))\n",
    "    \n",
    "best_model_address = os.path.join(char, 'best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 1 to monitor Validation Accuracy\n",
      "Press 2 to monitor Validation Loss\n",
      "Press 3 to monitor Training Accuracy\n",
      "Press 4 to monitor Training Loss\n",
      "4\n",
      "Enter number of epochs that will produce monitored quantity with no improvement after which training will be stopped: 100\n",
      "\n",
      "MONITORING TRAINING LOSS..........\n",
      "\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "Training will stop if Validation Accuracy doesn't show any improvements for 100 epcohs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "monitor = int(input(\"Press 1 to monitor Validation Accuracy\\nPress 2 to monitor Validation Loss\\nPress 3 to monitor Training Accuracy\\nPress 4 to monitor Training Loss\\n\"))\n",
    "patience = int(input('Enter number of epochs that will produce monitored quantity with no improvement after which training will be stopped: '))\n",
    "\n",
    "\n",
    "if monitor == 1:\n",
    "    metric = 'val_accuracy'\n",
    "    mode = 'max'\n",
    "    print(\"\\nMONITORING VALIDATION ACCURACY..........\\n\")\n",
    "\n",
    "elif monitor == 2:\n",
    "    metric = 'val_loss'\n",
    "    mode = 'min'\n",
    "    print(\"\\nMONITORING VALIDATION LOSS..........\\n\")\n",
    "\n",
    "elif monitor == 3:\n",
    "    metric = 'accuracy'\n",
    "    mode = 'max'\n",
    "    print(\"\\nMONITORING TRAINING ACCURACY..........\\n\")\n",
    "\n",
    "elif monitor == 4:\n",
    "    metric = 'loss'\n",
    "    mode = 'min'\n",
    "    print(\"\\nMONITORING TRAINING LOSS..........\\n\")\n",
    "\n",
    "callback = [keras.callbacks.LearningRateScheduler(lr_schedule, verbose = 1),\n",
    "            keras.callbacks.EarlyStopping(monitor = metric, min_delta = 0.001, patience = patience, verbose=1, mode = mode, restore_best_weights = True),\n",
    "            keras.callbacks.ModelCheckpoint(best_model_address, monitor = metric, verbose=1, save_best_only=True, save_weights_only=False, mode = mode , period=1)]\n",
    "\n",
    "print(\"\\nTraining will stop if Validation Accuracy doesn't show any improvements for \" + str(patience) + \" epcohs\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50():\n",
    "    print(\"\\nTRAINING ON ResNet50 MODEL:-\")\n",
    "\n",
    "    base_model = keras.applications.resnet.ResNet50(input_shape = dim, weights = 'imagenet', include_top = False)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(dense)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    predictions = Dense(output_layer, activation = output_activation)(x)\n",
    "\n",
    "    model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "    train_base_model = str(input(\"Do you want to train the base model of ResNet50?(Y/N) \"))\n",
    "    if train_base_model.upper() == 'Y':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    elif train_base_model.upper() == 'N':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Binary Classification\n"
     ]
    }
   ],
   "source": [
    "class_no = len(os.listdir(TRAINING_DIR))\n",
    "\n",
    "if class_no > 2:\n",
    "    print(\"This is a \" + str(class_no) + \"-Class Classification\")\n",
    "    output_activation = 'softmax'\n",
    "    losses = 'categorical_crossentropy'\n",
    "    class_mode = 'categorical'\n",
    "    output_layer = class_no\n",
    "else:\n",
    "    print(\"This is a Binary Classification\")\n",
    "    output_activation = 'sigmoid'\n",
    "    losses = 'binary_crossentropy'\n",
    "    class_mode = 'binary'\n",
    "    output_layer = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_selection():\n",
    "    print(\"\\nSelect a optimizer which will reduce the loss of the model.\\n\")\n",
    "\n",
    "    optimizer_select = int(input(\"Press 1 to select Stochastic Gradient Descent\\nPress 2 to select RMSprop\\nPress 3 to select Adagrad\\nPress 4 to select Adadelta\\nPress 5 to select Adam\\nPress 6 to select Adamax\\nPress 7 to select Nadam\\n\"))\n",
    "\n",
    "    if optimizer_select == 1:\n",
    "        optimizer = SGD(lr = learning_rate, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "\n",
    "    elif optimizer_select == 2:\n",
    "        optimizer = RMSprop(learning_rate, rho = 0.9)\n",
    "\n",
    "    elif optimizer_select == 3:\n",
    "        optimizer = Adagrad(learning_rate)\n",
    "\n",
    "    elif optimizer_select == 4:\n",
    "        optimizer = Adadelta(learning_rate, rho = 0.95)\n",
    "\n",
    "    elif optimizer_select == 5:\n",
    "        optimizer = Adam(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\n",
    "\n",
    "    elif optimizer_select == 6:\n",
    "        optimizer = Adamax(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999)\n",
    "\n",
    "    elif optimizer_select == 7:\n",
    "        optimizer = Nadam(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999)\n",
    "   \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Dimension(H or W): 64\n"
     ]
    }
   ],
   "source": [
    "h = int(input(\"Image Dimension(H or W): \"))\n",
    "w = h\n",
    "dim = [h,w,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 485 images belonging to 2 classes.\n",
      "Found 56 images belonging to 2 classes.\n",
      "Found 60 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    class_mode = class_mode,\n",
    "                                                    target_size = (h,w),\n",
    "                                                    shuffle=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                              batch_size = batch_size,\n",
    "                                                              class_mode = class_mode,\n",
    "                                                              target_size = (h,w),\n",
    "                                                              shuffle=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "test_generator = test_datagen.flow_from_directory(TESTING_DIR,\n",
    "                                                  batch_size = batch_size,\n",
    "                                                  class_mode = class_mode,\n",
    "                                                  target_size = (h,w),\n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the no. of neurons in dense layer: 256\n",
      "Enter the activation function: relu\n",
      "Enter the dropout percentage: 40\n",
      "\n",
      "Select a optimizer which will reduce the loss of the model.\n",
      "\n",
      "Press 1 to select Stochastic Gradient Descent\n",
      "Press 2 to select RMSprop\n",
      "Press 3 to select Adagrad\n",
      "Press 4 to select Adadelta\n",
      "Press 5 to select Adam\n",
      "Press 6 to select Adamax\n",
      "Press 7 to select Nadam\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "dense = int(input(\"Enter the no. of neurons in dense layer: \"))\n",
    "activation = str(input(\"Enter the activation function: \"))\n",
    "dropout = float(input(\"Enter the dropout percentage: \"))\n",
    "dropout = dropout/100\n",
    "\n",
    "optimizer = optimizer_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING ON ResNet50 MODEL:-\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 15s 0us/step\n",
      "Do you want to train the base model of ResNet50?(Y/N) y\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 70, 70, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 32, 32, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 32, 32, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 32, 32, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 34, 34, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 16, 16, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 16, 16, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 16, 16, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 16, 16, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 16, 16, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 16, 16, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 16, 16, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 16, 16, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 16, 16, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 16, 16, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 16, 16, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 16, 16, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 16, 16, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 16, 16, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 16, 16, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 16, 16, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 16, 16, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 8, 8, 128)    32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 8, 8, 128)    0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 8, 8, 128)    0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 8, 8, 512)    131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 8, 8, 512)    0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 8, 8, 512)    0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 8, 8, 128)    0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 8, 8, 128)    0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 8, 8, 512)    0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 8, 8, 512)    0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 8, 8, 128)    0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 8, 8, 128)    0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 8, 8, 512)    0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 8, 8, 512)    0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 8, 8, 128)    0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 8, 8, 128)    0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 8, 8, 512)    0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 8, 8, 512)    0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 4, 4, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 4, 4, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 4, 4, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 4, 4, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 4, 4, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 4, 4, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 4, 4, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 4, 4, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 4, 4, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 4, 4, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 4, 4, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 4, 4, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 4, 4, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 4, 4, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 4, 4, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 4, 4, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 4, 4, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 4, 4, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 4, 4, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 4, 4, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 4, 4, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 4, 4, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 4, 4, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 4, 4, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 4, 4, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 4, 4, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 2, 2, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 2, 2, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 2, 2, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 2, 2, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 2, 2, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 2, 2, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 2, 2, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 2, 2, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 2, 2, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 2, 2, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 2, 2, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 2, 2, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 2, 2, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 2, 2, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 2, 2, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 2, 2, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256)          1024        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            257         batch_normalization[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 24,113,537\n",
      "Trainable params: 24,059,905\n",
      "Non-trainable params: 53,632\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= ResNet50()\n",
    "model.compile(optimizer = optimizer, loss = losses, metrics = ['accuracy', \n",
    "                                                               tf.keras.metrics.Precision(), \n",
    "                                                               tf.keras.metrics.Recall(), \n",
    "                                                               tf.keras.metrics.TruePositives(), \n",
    "                                                               tf.keras.metrics.TrueNegatives(), \n",
    "                                                               tf.keras.metrics.FalsePositives(),\n",
    "                                                               tf.keras.metrics.FalseNegatives()])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-12757c0110cb>:3: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 1/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.8317 - accuracy: 0.5340 - precision: 0.7520 - recall: 0.5395 - true_positives: 191.0000 - true_negatives: 68.0000 - false_positives: 63.0000 - false_negatives: 163.0000\n",
      "Epoch 00001: loss improved from inf to 0.83173, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/resnet50_1/best_model.h5\n",
      "97/97 [==============================] - 5s 57ms/step - loss: 0.8317 - accuracy: 0.5340 - precision: 0.7520 - recall: 0.5395 - true_positives: 191.0000 - true_negatives: 68.0000 - false_positives: 63.0000 - false_negatives: 163.0000 - val_loss: 1.6536 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6802 - accuracy: 0.6536 - precision: 0.8345 - recall: 0.6554 - true_positives: 232.0000 - true_negatives: 85.0000 - false_positives: 46.0000 - false_negatives: 122.0000\n",
      "Epoch 00002: loss improved from 0.83173 to 0.68015, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/resnet50_1/best_model.h5\n",
      "97/97 [==============================] - 5s 51ms/step - loss: 0.6802 - accuracy: 0.6536 - precision: 0.8345 - recall: 0.6554 - true_positives: 232.0000 - true_negatives: 85.0000 - false_positives: 46.0000 - false_negatives: 122.0000 - val_loss: 1.9665 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6217 - accuracy: 0.6701 - precision: 0.8440 - recall: 0.6723 - true_positives: 238.0000 - true_negatives: 87.0000 - false_positives: 44.0000 - false_negatives: 116.0000\n",
      "Epoch 00003: loss improved from 0.68015 to 0.62170, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/resnet50_1/best_model.h5\n",
      "97/97 [==============================] - 5s 53ms/step - loss: 0.6217 - accuracy: 0.6701 - precision: 0.8440 - recall: 0.6723 - true_positives: 238.0000 - true_negatives: 87.0000 - false_positives: 44.0000 - false_negatives: 116.0000 - val_loss: 1.1124 - val_accuracy: 0.7857 - val_precision: 0.7857 - val_recall: 1.0000 - val_true_positives: 44.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 0.0000e+00\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.6165 - accuracy: 0.6680 - precision: 0.8206 - recall: 0.6977 - true_positives: 247.0000 - true_negatives: 77.0000 - false_positives: 54.0000 - false_negatives: 107.0000\n",
      "Epoch 00004: loss improved from 0.62170 to 0.61653, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/resnet50_1/best_model.h5\n",
      "97/97 [==============================] - 7s 77ms/step - loss: 0.6165 - accuracy: 0.6680 - precision: 0.8206 - recall: 0.6977 - true_positives: 247.0000 - true_negatives: 77.0000 - false_positives: 54.0000 - false_negatives: 107.0000 - val_loss: 0.7618 - val_accuracy: 0.7143 - val_precision: 0.7692 - val_recall: 0.9091 - val_true_positives: 40.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 4.0000\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.5453 - accuracy: 0.7340 - precision: 0.8505 - recall: 0.7712 - true_positives: 273.0000 - true_negatives: 83.0000 - false_positives: 48.0000 - false_negatives: 81.0000\n",
      "Epoch 00005: loss improved from 0.61653 to 0.54531, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/resnet50_1/best_model.h5\n",
      "97/97 [==============================] - 8s 78ms/step - loss: 0.5453 - accuracy: 0.7340 - precision: 0.8505 - recall: 0.7712 - true_positives: 273.0000 - true_negatives: 83.0000 - false_positives: 48.0000 - false_negatives: 81.0000 - val_loss: 0.8162 - val_accuracy: 0.5714 - val_precision: 0.7500 - val_recall: 0.6818 - val_true_positives: 30.0000 - val_true_negatives: 2.0000 - val_false_positives: 10.0000 - val_false_negatives: 14.0000\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.5616 - accuracy: 0.7196 - precision: 0.8449 - recall: 0.7542 - true_positives: 267.0000 - true_negatives: 82.0000 - false_positives: 49.0000 - false_negatives: 87.0000\n",
      "Epoch 00006: loss did not improve from 0.54531\n",
      "97/97 [==============================] - 3s 36ms/step - loss: 0.5616 - accuracy: 0.7196 - precision: 0.8449 - recall: 0.7542 - true_positives: 267.0000 - true_negatives: 82.0000 - false_positives: 49.0000 - false_negatives: 87.0000 - val_loss: 1.0280 - val_accuracy: 0.7143 - val_precision: 0.7692 - val_recall: 0.9091 - val_true_positives: 40.0000 - val_true_negatives: 0.0000e+00 - val_false_positives: 12.0000 - val_false_negatives: 4.0000\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.5722 - accuracy: 0.7052 - precision: 0.8149 - recall: 0.7712 - true_positives: 273.0000 - true_negatives: 69.0000 - false_positives: 62.0000 - false_negatives: 81.0000\n",
      "Epoch 00007: loss did not improve from 0.54531\n",
      "97/97 [==============================] - 3s 36ms/step - loss: 0.5722 - accuracy: 0.7052 - precision: 0.8149 - recall: 0.7712 - true_positives: 273.0000 - true_negatives: 69.0000 - false_positives: 62.0000 - false_negatives: 81.0000 - val_loss: 1.1449 - val_accuracy: 0.4464 - val_precision: 0.9333 - val_recall: 0.3182 - val_true_positives: 14.0000 - val_true_negatives: 11.0000 - val_false_positives: 1.0000 - val_false_negatives: 30.0000\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.4428 - accuracy: 0.7835 - precision: 0.8739 - recall: 0.8220 - true_positives: 291.0000 - true_negatives: 89.0000 - false_positives: 42.0000 - false_negatives: 63.0000\n",
      "Epoch 00008: loss improved from 0.54531 to 0.44278, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/resnet50_1/best_model.h5\n",
      "97/97 [==============================] - 5s 51ms/step - loss: 0.4428 - accuracy: 0.7835 - precision: 0.8739 - recall: 0.8220 - true_positives: 291.0000 - true_negatives: 89.0000 - false_positives: 42.0000 - false_negatives: 63.0000 - val_loss: 1.6573 - val_accuracy: 0.2321 - val_precision: 1.0000 - val_recall: 0.0227 - val_true_positives: 1.0000 - val_true_negatives: 12.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 43.0000\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.5023 - accuracy: 0.7567 - precision: 0.8430 - recall: 0.8192 - true_positives: 290.0000 - true_negatives: 77.0000 - false_positives: 54.0000 - false_negatives: 64.0000\n",
      "Epoch 00009: loss did not improve from 0.44278\n",
      "97/97 [==============================] - 4s 36ms/step - loss: 0.5023 - accuracy: 0.7567 - precision: 0.8430 - recall: 0.8192 - true_positives: 290.0000 - true_negatives: 77.0000 - false_positives: 54.0000 - false_negatives: 64.0000 - val_loss: 1.7338 - val_accuracy: 0.2321 - val_precision: 1.0000 - val_recall: 0.0227 - val_true_positives: 1.0000 - val_true_negatives: 12.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 43.0000\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - ETA: 0s - loss: 0.4388 - accuracy: 0.7897 - precision: 0.8818 - recall: 0.8220 - true_positives: 291.0000 - true_negatives: 92.0000 - false_positives: 39.0000 - false_negatives: 63.0000\n",
      "Epoch 00010: loss improved from 0.44278 to 0.43880, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/resnet50_1/best_model.h5\n",
      "97/97 [==============================] - 5s 50ms/step - loss: 0.4388 - accuracy: 0.7897 - precision: 0.8818 - recall: 0.8220 - true_positives: 291.0000 - true_negatives: 92.0000 - false_positives: 39.0000 - false_negatives: 63.0000 - val_loss: 1.6539 - val_accuracy: 0.3214 - val_precision: 0.8750 - val_recall: 0.1591 - val_true_positives: 7.0000 - val_true_negatives: 11.0000 - val_false_positives: 1.0000 - val_false_negatives: 37.0000\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3726 - accuracy: 0.8268 - precision: 0.9042 - recall: 0.8531 - true_positives: 302.0000 - true_negatives: 99.0000 - false_positives: 32.0000 - false_negatives: 52.0000\n",
      "Epoch 00011: loss improved from 0.43880 to 0.37255, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/resnet50_1/best_model.h5\n",
      "97/97 [==============================] - 5s 52ms/step - loss: 0.3726 - accuracy: 0.8268 - precision: 0.9042 - recall: 0.8531 - true_positives: 302.0000 - true_negatives: 99.0000 - false_positives: 32.0000 - false_negatives: 52.0000 - val_loss: 1.3712 - val_accuracy: 0.4107 - val_precision: 0.9231 - val_recall: 0.2727 - val_true_positives: 12.0000 - val_true_negatives: 11.0000 - val_false_positives: 1.0000 - val_false_negatives: 32.0000\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3380 - accuracy: 0.8701 - precision: 0.9292 - recall: 0.8898 - true_positives: 315.0000 - true_negatives: 107.0000 - false_positives: 24.0000 - false_negatives: 39.0000\n",
      "Epoch 00012: loss improved from 0.37255 to 0.33801, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/resnet50_1/best_model.h5\n",
      "97/97 [==============================] - 8s 86ms/step - loss: 0.3380 - accuracy: 0.8701 - precision: 0.9292 - recall: 0.8898 - true_positives: 315.0000 - true_negatives: 107.0000 - false_positives: 24.0000 - false_negatives: 39.0000 - val_loss: 1.2468 - val_accuracy: 0.4464 - val_precision: 0.8824 - val_recall: 0.3409 - val_true_positives: 15.0000 - val_true_negatives: 10.0000 - val_false_positives: 2.0000 - val_false_negatives: 29.0000\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3388 - accuracy: 0.8742 - precision: 0.9296 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 107.0000 - false_positives: 24.0000 - false_negatives: 37.0000\n",
      "Epoch 00013: loss did not improve from 0.33801\n",
      "97/97 [==============================] - 3s 35ms/step - loss: 0.3388 - accuracy: 0.8742 - precision: 0.9296 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 107.0000 - false_positives: 24.0000 - false_negatives: 37.0000 - val_loss: 1.1043 - val_accuracy: 0.5536 - val_precision: 0.9130 - val_recall: 0.4773 - val_true_positives: 21.0000 - val_true_negatives: 10.0000 - val_false_positives: 2.0000 - val_false_negatives: 23.0000\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3557 - accuracy: 0.8412 - precision: 0.9210 - recall: 0.8559 - true_positives: 303.0000 - true_negatives: 105.0000 - false_positives: 26.0000 - false_negatives: 51.0000\n",
      "Epoch 00014: loss did not improve from 0.33801\n",
      "97/97 [==============================] - 3s 35ms/step - loss: 0.3557 - accuracy: 0.8412 - precision: 0.9210 - recall: 0.8559 - true_positives: 303.0000 - true_negatives: 105.0000 - false_positives: 26.0000 - false_negatives: 51.0000 - val_loss: 0.9735 - val_accuracy: 0.5893 - val_precision: 0.9200 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 10.0000 - val_false_positives: 2.0000 - val_false_negatives: 21.0000\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3468 - accuracy: 0.8371 - precision: 0.9104 - recall: 0.8616 - true_positives: 305.0000 - true_negatives: 101.0000 - false_positives: 30.0000 - false_negatives: 49.0000\n",
      "Epoch 00015: loss did not improve from 0.33801\n",
      "97/97 [==============================] - 3s 35ms/step - loss: 0.3468 - accuracy: 0.8371 - precision: 0.9104 - recall: 0.8616 - true_positives: 305.0000 - true_negatives: 101.0000 - false_positives: 30.0000 - false_negatives: 49.0000 - val_loss: 1.0016 - val_accuracy: 0.5714 - val_precision: 0.8571 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 8.0000 - val_false_positives: 4.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3559 - accuracy: 0.8392 - precision: 0.9157 - recall: 0.8588 - true_positives: 304.0000 - true_negatives: 103.0000 - false_positives: 28.0000 - false_negatives: 50.0000\n",
      "Epoch 00016: loss did not improve from 0.33801\n",
      "97/97 [==============================] - 3s 35ms/step - loss: 0.3559 - accuracy: 0.8392 - precision: 0.9157 - recall: 0.8588 - true_positives: 304.0000 - true_negatives: 103.0000 - false_positives: 28.0000 - false_negatives: 50.0000 - val_loss: 0.9445 - val_accuracy: 0.6250 - val_precision: 0.8710 - val_recall: 0.6136 - val_true_positives: 27.0000 - val_true_negatives: 8.0000 - val_false_positives: 4.0000 - val_false_negatives: 17.0000\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3184 - accuracy: 0.8763 - precision: 0.9324 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 108.0000 - false_positives: 23.0000 - false_negatives: 37.0000\n",
      "Epoch 00017: loss improved from 0.33801 to 0.31845, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/resnet50_1/best_model.h5\n",
      "97/97 [==============================] - 5s 52ms/step - loss: 0.3184 - accuracy: 0.8763 - precision: 0.9324 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 108.0000 - false_positives: 23.0000 - false_negatives: 37.0000 - val_loss: 0.9735 - val_accuracy: 0.6250 - val_precision: 0.8710 - val_recall: 0.6136 - val_true_positives: 27.0000 - val_true_negatives: 8.0000 - val_false_positives: 4.0000 - val_false_negatives: 17.0000\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2870 - accuracy: 0.8763 - precision: 0.9298 - recall: 0.8983 - true_positives: 318.0000 - true_negatives: 107.0000 - false_positives: 24.0000 - false_negatives: 36.0000\n",
      "Epoch 00018: loss improved from 0.31845 to 0.28704, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/resnet50_1/best_model.h5\n",
      "97/97 [==============================] - 5s 51ms/step - loss: 0.2870 - accuracy: 0.8763 - precision: 0.9298 - recall: 0.8983 - true_positives: 318.0000 - true_negatives: 107.0000 - false_positives: 24.0000 - false_negatives: 36.0000 - val_loss: 1.0394 - val_accuracy: 0.6250 - val_precision: 0.8966 - val_recall: 0.5909 - val_true_positives: 26.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 18.0000\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2851 - accuracy: 0.8804 - precision: 0.9353 - recall: 0.8983 - true_positives: 318.0000 - true_negatives: 109.0000 - false_positives: 22.0000 - false_negatives: 36.0000\n",
      "Epoch 00019: loss improved from 0.28704 to 0.28514, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/resnet50_1/best_model.h5\n",
      "97/97 [==============================] - 8s 80ms/step - loss: 0.2851 - accuracy: 0.8804 - precision: 0.9353 - recall: 0.8983 - true_positives: 318.0000 - true_negatives: 109.0000 - false_positives: 22.0000 - false_negatives: 36.0000 - val_loss: 1.1000 - val_accuracy: 0.5536 - val_precision: 0.8519 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 8.0000 - val_false_positives: 4.0000 - val_false_negatives: 21.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2962 - accuracy: 0.8866 - precision: 0.9463 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 113.0000 - false_positives: 18.0000 - false_negatives: 37.0000\n",
      "Epoch 00020: loss did not improve from 0.28514\n",
      "97/97 [==============================] - 3s 35ms/step - loss: 0.2962 - accuracy: 0.8866 - precision: 0.9463 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 113.0000 - false_positives: 18.0000 - false_negatives: 37.0000 - val_loss: 1.0763 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3049 - accuracy: 0.8701 - precision: 0.9369 - recall: 0.8814 - true_positives: 312.0000 - true_negatives: 110.0000 - false_positives: 21.0000 - false_negatives: 42.0000\n",
      "Epoch 00021: loss did not improve from 0.28514\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.3049 - accuracy: 0.8701 - precision: 0.9369 - recall: 0.8814 - true_positives: 312.0000 - true_negatives: 110.0000 - false_positives: 21.0000 - false_negatives: 42.0000 - val_loss: 1.1387 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2743 - accuracy: 0.8907 - precision: 0.9466 - recall: 0.9011 - true_positives: 319.0000 - true_negatives: 113.0000 - false_positives: 18.0000 - false_negatives: 35.0000\n",
      "Epoch 00022: loss improved from 0.28514 to 0.27425, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/resnet50_1/best_model.h5\n",
      "97/97 [==============================] - 5s 50ms/step - loss: 0.2743 - accuracy: 0.8907 - precision: 0.9466 - recall: 0.9011 - true_positives: 319.0000 - true_negatives: 113.0000 - false_positives: 18.0000 - false_negatives: 35.0000 - val_loss: 1.1715 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2859 - accuracy: 0.8680 - precision: 0.9503 - recall: 0.8644 - true_positives: 306.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 48.0000\n",
      "Epoch 00023: loss did not improve from 0.27425\n",
      "97/97 [==============================] - 3s 35ms/step - loss: 0.2859 - accuracy: 0.8680 - precision: 0.9503 - recall: 0.8644 - true_positives: 306.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 48.0000 - val_loss: 1.1732 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3449 - accuracy: 0.8495 - precision: 0.9145 - recall: 0.8757 - true_positives: 310.0000 - true_negatives: 102.0000 - false_positives: 29.0000 - false_negatives: 44.0000\n",
      "Epoch 00024: loss did not improve from 0.27425\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.3449 - accuracy: 0.8495 - precision: 0.9145 - recall: 0.8757 - true_positives: 310.0000 - true_negatives: 102.0000 - false_positives: 29.0000 - false_negatives: 44.0000 - val_loss: 1.1718 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2880 - accuracy: 0.8742 - precision: 0.9592 - recall: 0.8644 - true_positives: 306.0000 - true_negatives: 118.0000 - false_positives: 13.0000 - false_negatives: 48.0000\n",
      "Epoch 00025: loss did not improve from 0.27425\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2880 - accuracy: 0.8742 - precision: 0.9592 - recall: 0.8644 - true_positives: 306.0000 - true_negatives: 118.0000 - false_positives: 13.0000 - false_negatives: 48.0000 - val_loss: 1.2363 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2898 - accuracy: 0.8866 - precision: 0.9517 - recall: 0.8898 - true_positives: 315.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 39.0000\n",
      "Epoch 00026: loss did not improve from 0.27425\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2898 - accuracy: 0.8866 - precision: 0.9517 - recall: 0.8898 - true_positives: 315.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 39.0000 - val_loss: 1.1508 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3328 - accuracy: 0.8619 - precision: 0.9335 - recall: 0.8729 - true_positives: 309.0000 - true_negatives: 109.0000 - false_positives: 22.0000 - false_negatives: 45.0000\n",
      "Epoch 00027: loss did not improve from 0.27425\n",
      "97/97 [==============================] - 3s 35ms/step - loss: 0.3328 - accuracy: 0.8619 - precision: 0.9335 - recall: 0.8729 - true_positives: 309.0000 - true_negatives: 109.0000 - false_positives: 22.0000 - false_negatives: 45.0000 - val_loss: 1.1200 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2783 - accuracy: 0.8948 - precision: 0.9605 - recall: 0.8927 - true_positives: 316.0000 - true_negatives: 118.0000 - false_positives: 13.0000 - false_negatives: 38.0000\n",
      "Epoch 00028: loss did not improve from 0.27425\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2783 - accuracy: 0.8948 - precision: 0.9605 - recall: 0.8927 - true_positives: 316.0000 - true_negatives: 118.0000 - false_positives: 13.0000 - false_negatives: 38.0000 - val_loss: 1.1341 - val_accuracy: 0.5536 - val_precision: 0.8800 - val_recall: 0.5000 - val_true_positives: 22.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 22.0000\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2674 - accuracy: 0.8887 - precision: 0.9386 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 110.0000 - false_positives: 21.0000 - false_negatives: 33.0000\n",
      "Epoch 00029: loss improved from 0.27425 to 0.26743, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/resnet50_1/best_model.h5\n",
      "97/97 [==============================] - 5s 50ms/step - loss: 0.2674 - accuracy: 0.8887 - precision: 0.9386 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 110.0000 - false_positives: 21.0000 - false_negatives: 33.0000 - val_loss: 1.1387 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 1.0000000000000002e-06.\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2818 - accuracy: 0.8887 - precision: 0.9545 - recall: 0.8898 - true_positives: 315.0000 - true_negatives: 116.0000 - false_positives: 15.0000 - false_negatives: 39.0000\n",
      "Epoch 00030: loss did not improve from 0.26743\n",
      "97/97 [==============================] - 3s 35ms/step - loss: 0.2818 - accuracy: 0.8887 - precision: 0.9545 - recall: 0.8898 - true_positives: 315.0000 - true_negatives: 116.0000 - false_positives: 15.0000 - false_negatives: 39.0000 - val_loss: 1.2175 - val_accuracy: 0.5536 - val_precision: 0.8800 - val_recall: 0.5000 - val_true_positives: 22.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 22.0000\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2604 - accuracy: 0.8763 - precision: 0.9428 - recall: 0.8842 - true_positives: 313.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 41.0000\n",
      "Epoch 00031: loss improved from 0.26743 to 0.26044, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/resnet50_1/best_model.h5\n",
      "97/97 [==============================] - 5s 50ms/step - loss: 0.2604 - accuracy: 0.8763 - precision: 0.9428 - recall: 0.8842 - true_positives: 313.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 41.0000 - val_loss: 1.1056 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 32/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2450 - accuracy: 0.8948 - precision: 0.9522 - recall: 0.9011 - true_positives: 319.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 35.0000\n",
      "Epoch 00032: loss improved from 0.26044 to 0.24505, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/resnet50_1/best_model.h5\n",
      "97/97 [==============================] - 7s 76ms/step - loss: 0.2450 - accuracy: 0.8948 - precision: 0.9522 - recall: 0.9011 - true_positives: 319.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 35.0000 - val_loss: 1.1029 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 33/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3208 - accuracy: 0.8722 - precision: 0.9371 - recall: 0.8842 - true_positives: 313.0000 - true_negatives: 110.0000 - false_positives: 21.0000 - false_negatives: 41.0000\n",
      "Epoch 00033: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 35ms/step - loss: 0.3208 - accuracy: 0.8722 - precision: 0.9371 - recall: 0.8842 - true_positives: 313.0000 - true_negatives: 110.0000 - false_positives: 21.0000 - false_negatives: 41.0000 - val_loss: 1.0873 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 34/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2702 - accuracy: 0.8825 - precision: 0.9514 - recall: 0.8842 - true_positives: 313.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 41.0000\n",
      "Epoch 00034: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 35ms/step - loss: 0.2702 - accuracy: 0.8825 - precision: 0.9514 - recall: 0.8842 - true_positives: 313.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 41.0000 - val_loss: 1.0805 - val_accuracy: 0.5536 - val_precision: 0.8800 - val_recall: 0.5000 - val_true_positives: 22.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 22.0000\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 35/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2596 - accuracy: 0.8845 - precision: 0.9435 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 37.0000\n",
      "Epoch 00035: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 35ms/step - loss: 0.2596 - accuracy: 0.8845 - precision: 0.9435 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 37.0000 - val_loss: 1.1111 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 36/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3193 - accuracy: 0.8722 - precision: 0.9320 - recall: 0.8898 - true_positives: 315.0000 - true_negatives: 108.0000 - false_positives: 23.0000 - false_negatives: 39.0000\n",
      "Epoch 00036: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 35ms/step - loss: 0.3193 - accuracy: 0.8722 - precision: 0.9320 - recall: 0.8898 - true_positives: 315.0000 - true_negatives: 108.0000 - false_positives: 23.0000 - false_negatives: 39.0000 - val_loss: 1.0929 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 37/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3177 - accuracy: 0.8619 - precision: 0.9309 - recall: 0.8757 - true_positives: 310.0000 - true_negatives: 108.0000 - false_positives: 23.0000 - false_negatives: 44.0000\n",
      "Epoch 00037: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 35ms/step - loss: 0.3177 - accuracy: 0.8619 - precision: 0.9309 - recall: 0.8757 - true_positives: 310.0000 - true_negatives: 108.0000 - false_positives: 23.0000 - false_negatives: 44.0000 - val_loss: 1.1135 - val_accuracy: 0.5536 - val_precision: 0.8800 - val_recall: 0.5000 - val_true_positives: 22.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 22.0000\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 38/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2828 - accuracy: 0.8948 - precision: 0.9469 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 113.0000 - false_positives: 18.0000 - false_negatives: 33.0000\n",
      "Epoch 00038: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 35ms/step - loss: 0.2828 - accuracy: 0.8948 - precision: 0.9469 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 113.0000 - false_positives: 18.0000 - false_negatives: 33.0000 - val_loss: 1.1272 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 39/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2696 - accuracy: 0.8990 - precision: 0.9580 - recall: 0.9011 - true_positives: 319.0000 - true_negatives: 117.0000 - false_positives: 14.0000 - false_negatives: 35.0000\n",
      "Epoch 00039: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 35ms/step - loss: 0.2696 - accuracy: 0.8990 - precision: 0.9580 - recall: 0.9011 - true_positives: 319.0000 - true_negatives: 117.0000 - false_positives: 14.0000 - false_negatives: 35.0000 - val_loss: 1.1628 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 1.0000000000000002e-07.\n",
      "Epoch 40/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2790 - accuracy: 0.8825 - precision: 0.9381 - recall: 0.8983 - true_positives: 318.0000 - true_negatives: 110.0000 - false_positives: 21.0000 - false_negatives: 36.0000\n",
      "Epoch 00040: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2790 - accuracy: 0.8825 - precision: 0.9381 - recall: 0.8983 - true_positives: 318.0000 - true_negatives: 110.0000 - false_positives: 21.0000 - false_negatives: 36.0000 - val_loss: 1.1117 - val_accuracy: 0.5536 - val_precision: 0.8800 - val_recall: 0.5000 - val_true_positives: 22.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 22.0000\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 41/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2717 - accuracy: 0.8907 - precision: 0.9574 - recall: 0.8898 - true_positives: 315.0000 - true_negatives: 117.0000 - false_positives: 14.0000 - false_negatives: 39.0000\n",
      "Epoch 00041: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2717 - accuracy: 0.8907 - precision: 0.9574 - recall: 0.8898 - true_positives: 315.0000 - true_negatives: 117.0000 - false_positives: 14.0000 - false_negatives: 39.0000 - val_loss: 1.1479 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 42/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2626 - accuracy: 0.9052 - precision: 0.9695 - recall: 0.8983 - true_positives: 318.0000 - true_negatives: 121.0000 - false_positives: 10.0000 - false_negatives: 36.0000\n",
      "Epoch 00042: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2626 - accuracy: 0.9052 - precision: 0.9695 - recall: 0.8983 - true_positives: 318.0000 - true_negatives: 121.0000 - false_positives: 10.0000 - false_negatives: 36.0000 - val_loss: 1.1038 - val_accuracy: 0.6071 - val_precision: 0.8929 - val_recall: 0.5682 - val_true_positives: 25.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 19.0000\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 43/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2556 - accuracy: 0.8845 - precision: 0.9488 - recall: 0.8898 - true_positives: 315.0000 - true_negatives: 114.0000 - false_positives: 17.0000 - false_negatives: 39.0000\n",
      "Epoch 00043: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2556 - accuracy: 0.8845 - precision: 0.9488 - recall: 0.8898 - true_positives: 315.0000 - true_negatives: 114.0000 - false_positives: 17.0000 - false_negatives: 39.0000 - val_loss: 1.0480 - val_accuracy: 0.6429 - val_precision: 0.9000 - val_recall: 0.6136 - val_true_positives: 27.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 17.0000\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 44/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2710 - accuracy: 0.8928 - precision: 0.9548 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 116.0000 - false_positives: 15.0000 - false_negatives: 37.0000\n",
      "Epoch 00044: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2710 - accuracy: 0.8928 - precision: 0.9548 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 116.0000 - false_positives: 15.0000 - false_negatives: 37.0000 - val_loss: 1.0757 - val_accuracy: 0.6071 - val_precision: 0.8929 - val_recall: 0.5682 - val_true_positives: 25.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 19.0000\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 45/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2911 - accuracy: 0.8742 - precision: 0.9480 - recall: 0.8757 - true_positives: 310.0000 - true_negatives: 114.0000 - false_positives: 17.0000 - false_negatives: 44.0000\n",
      "Epoch 00045: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2911 - accuracy: 0.8742 - precision: 0.9480 - recall: 0.8757 - true_positives: 310.0000 - true_negatives: 114.0000 - false_positives: 17.0000 - false_negatives: 44.0000 - val_loss: 1.1626 - val_accuracy: 0.5536 - val_precision: 0.8800 - val_recall: 0.5000 - val_true_positives: 22.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 22.0000\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 46/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3068 - accuracy: 0.8619 - precision: 0.9309 - recall: 0.8757 - true_positives: 310.0000 - true_negatives: 108.0000 - false_positives: 23.0000 - false_negatives: 44.0000\n",
      "Epoch 00046: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.3068 - accuracy: 0.8619 - precision: 0.9309 - recall: 0.8757 - true_positives: 310.0000 - true_negatives: 108.0000 - false_positives: 23.0000 - false_negatives: 44.0000 - val_loss: 1.1419 - val_accuracy: 0.5357 - val_precision: 0.8750 - val_recall: 0.4773 - val_true_positives: 21.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 23.0000\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 47/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2769 - accuracy: 0.8928 - precision: 0.9548 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 116.0000 - false_positives: 15.0000 - false_negatives: 37.0000\n",
      "Epoch 00047: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2769 - accuracy: 0.8928 - precision: 0.9548 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 116.0000 - false_positives: 15.0000 - false_negatives: 37.0000 - val_loss: 1.1024 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 48/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2660 - accuracy: 0.8804 - precision: 0.9405 - recall: 0.8927 - true_positives: 316.0000 - true_negatives: 111.0000 - false_positives: 20.0000 - false_negatives: 38.0000\n",
      "Epoch 00048: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2660 - accuracy: 0.8804 - precision: 0.9405 - recall: 0.8927 - true_positives: 316.0000 - true_negatives: 111.0000 - false_positives: 20.0000 - false_negatives: 38.0000 - val_loss: 1.0979 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 49/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2730 - accuracy: 0.8969 - precision: 0.9551 - recall: 0.9011 - true_positives: 319.0000 - true_negatives: 116.0000 - false_positives: 15.0000 - false_negatives: 35.0000\n",
      "Epoch 00049: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2730 - accuracy: 0.8969 - precision: 0.9551 - recall: 0.9011 - true_positives: 319.0000 - true_negatives: 116.0000 - false_positives: 15.0000 - false_negatives: 35.0000 - val_loss: 1.1332 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 1.0000000000000002e-08.\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - ETA: 0s - loss: 0.2577 - accuracy: 0.8948 - precision: 0.9605 - recall: 0.8927 - true_positives: 316.0000 - true_negatives: 118.0000 - false_positives: 13.0000 - false_negatives: 38.0000\n",
      "Epoch 00050: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2577 - accuracy: 0.8948 - precision: 0.9605 - recall: 0.8927 - true_positives: 316.0000 - true_negatives: 118.0000 - false_positives: 13.0000 - false_negatives: 38.0000 - val_loss: 1.1924 - val_accuracy: 0.5357 - val_precision: 0.8750 - val_recall: 0.4773 - val_true_positives: 21.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 23.0000\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 51/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2541 - accuracy: 0.9031 - precision: 0.9528 - recall: 0.9124 - true_positives: 323.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 31.0000\n",
      "Epoch 00051: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2541 - accuracy: 0.9031 - precision: 0.9528 - recall: 0.9124 - true_positives: 323.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 31.0000 - val_loss: 1.1657 - val_accuracy: 0.5536 - val_precision: 0.8800 - val_recall: 0.5000 - val_true_positives: 22.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 22.0000\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 52/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2628 - accuracy: 0.9093 - precision: 0.9532 - recall: 0.9209 - true_positives: 326.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 28.0000\n",
      "Epoch 00052: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2628 - accuracy: 0.9093 - precision: 0.9532 - recall: 0.9209 - true_positives: 326.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 28.0000 - val_loss: 1.1635 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 53/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3031 - accuracy: 0.8866 - precision: 0.9463 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 113.0000 - false_positives: 18.0000 - false_negatives: 37.0000\n",
      "Epoch 00053: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.3031 - accuracy: 0.8866 - precision: 0.9463 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 113.0000 - false_positives: 18.0000 - false_negatives: 37.0000 - val_loss: 1.1855 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 54/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2787 - accuracy: 0.8866 - precision: 0.9436 - recall: 0.8983 - true_positives: 318.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 36.0000\n",
      "Epoch 00054: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2787 - accuracy: 0.8866 - precision: 0.9436 - recall: 0.8983 - true_positives: 318.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 36.0000 - val_loss: 1.1659 - val_accuracy: 0.5357 - val_precision: 0.8750 - val_recall: 0.4773 - val_true_positives: 21.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 23.0000\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 55/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2689 - accuracy: 0.8866 - precision: 0.9384 - recall: 0.9040 - true_positives: 320.0000 - true_negatives: 110.0000 - false_positives: 21.0000 - false_negatives: 34.0000\n",
      "Epoch 00055: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2689 - accuracy: 0.8866 - precision: 0.9384 - recall: 0.9040 - true_positives: 320.0000 - true_negatives: 110.0000 - false_positives: 21.0000 - false_negatives: 34.0000 - val_loss: 1.0308 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 56/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2913 - accuracy: 0.8866 - precision: 0.9517 - recall: 0.8898 - true_positives: 315.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 39.0000\n",
      "Epoch 00056: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2913 - accuracy: 0.8866 - precision: 0.9517 - recall: 0.8898 - true_positives: 315.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 39.0000 - val_loss: 1.1010 - val_accuracy: 0.5357 - val_precision: 0.8750 - val_recall: 0.4773 - val_true_positives: 21.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 23.0000\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 57/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3416 - accuracy: 0.8680 - precision: 0.9240 - recall: 0.8927 - true_positives: 316.0000 - true_negatives: 105.0000 - false_positives: 26.0000 - false_negatives: 38.0000\n",
      "Epoch 00057: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.3416 - accuracy: 0.8680 - precision: 0.9240 - recall: 0.8927 - true_positives: 316.0000 - true_negatives: 105.0000 - false_positives: 26.0000 - false_negatives: 38.0000 - val_loss: 1.1926 - val_accuracy: 0.5536 - val_precision: 0.8800 - val_recall: 0.5000 - val_true_positives: 22.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 22.0000\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 58/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2743 - accuracy: 0.9031 - precision: 0.9610 - recall: 0.9040 - true_positives: 320.0000 - true_negatives: 118.0000 - false_positives: 13.0000 - false_negatives: 34.0000\n",
      "Epoch 00058: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2743 - accuracy: 0.9031 - precision: 0.9610 - recall: 0.9040 - true_positives: 320.0000 - true_negatives: 118.0000 - false_positives: 13.0000 - false_negatives: 34.0000 - val_loss: 1.1586 - val_accuracy: 0.5536 - val_precision: 0.8800 - val_recall: 0.5000 - val_true_positives: 22.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 22.0000\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 59/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2493 - accuracy: 0.9072 - precision: 0.9585 - recall: 0.9124 - true_positives: 323.0000 - true_negatives: 117.0000 - false_positives: 14.0000 - false_negatives: 31.0000\n",
      "Epoch 00059: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2493 - accuracy: 0.9072 - precision: 0.9585 - recall: 0.9124 - true_positives: 323.0000 - true_negatives: 117.0000 - false_positives: 14.0000 - false_negatives: 31.0000 - val_loss: 1.1478 - val_accuracy: 0.6071 - val_precision: 0.8929 - val_recall: 0.5682 - val_true_positives: 25.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 19.0000\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 1.0000000000000003e-09.\n",
      "Epoch 60/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3011 - accuracy: 0.8742 - precision: 0.9373 - recall: 0.8870 - true_positives: 314.0000 - true_negatives: 110.0000 - false_positives: 21.0000 - false_negatives: 40.0000\n",
      "Epoch 00060: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.3011 - accuracy: 0.8742 - precision: 0.9373 - recall: 0.8870 - true_positives: 314.0000 - true_negatives: 110.0000 - false_positives: 21.0000 - false_negatives: 40.0000 - val_loss: 1.1736 - val_accuracy: 0.6071 - val_precision: 0.8929 - val_recall: 0.5682 - val_true_positives: 25.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 19.0000\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 61/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2986 - accuracy: 0.8804 - precision: 0.9379 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 110.0000 - false_positives: 21.0000 - false_negatives: 37.0000\n",
      "Epoch 00061: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2986 - accuracy: 0.8804 - precision: 0.9379 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 110.0000 - false_positives: 21.0000 - false_negatives: 37.0000 - val_loss: 1.1008 - val_accuracy: 0.6071 - val_precision: 0.8929 - val_recall: 0.5682 - val_true_positives: 25.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 19.0000\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 62/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2738 - accuracy: 0.8928 - precision: 0.9441 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 33.0000\n",
      "Epoch 00062: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2738 - accuracy: 0.8928 - precision: 0.9441 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 33.0000 - val_loss: 1.2085 - val_accuracy: 0.5357 - val_precision: 0.8750 - val_recall: 0.4773 - val_true_positives: 21.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 23.0000\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 63/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 0.8784 - precision: 0.9351 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 109.0000 - false_positives: 22.0000 - false_negatives: 37.0000\n",
      "Epoch 00063: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2878 - accuracy: 0.8784 - precision: 0.9351 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 109.0000 - false_positives: 22.0000 - false_negatives: 37.0000 - val_loss: 1.1097 - val_accuracy: 0.5536 - val_precision: 0.8800 - val_recall: 0.5000 - val_true_positives: 22.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 22.0000\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 64/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2751 - accuracy: 0.8969 - precision: 0.9497 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 114.0000 - false_positives: 17.0000 - false_negatives: 33.0000\n",
      "Epoch 00064: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2751 - accuracy: 0.8969 - precision: 0.9497 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 114.0000 - false_positives: 17.0000 - false_negatives: 33.0000 - val_loss: 1.1357 - val_accuracy: 0.5357 - val_precision: 0.8750 - val_recall: 0.4773 - val_true_positives: 21.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 23.0000\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 65/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3064 - accuracy: 0.8660 - precision: 0.9313 - recall: 0.8814 - true_positives: 312.0000 - true_negatives: 108.0000 - false_positives: 23.0000 - false_negatives: 42.0000\n",
      "Epoch 00065: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.3064 - accuracy: 0.8660 - precision: 0.9313 - recall: 0.8814 - true_positives: 312.0000 - true_negatives: 108.0000 - false_positives: 23.0000 - false_negatives: 42.0000 - val_loss: 1.1029 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 66/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2599 - accuracy: 0.8969 - precision: 0.9524 - recall: 0.9040 - true_positives: 320.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 34.0000\n",
      "Epoch 00066: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2599 - accuracy: 0.8969 - precision: 0.9524 - recall: 0.9040 - true_positives: 320.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 34.0000 - val_loss: 1.1694 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 67/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.9010 - precision: 0.9527 - recall: 0.9096 - true_positives: 322.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 32.0000\n",
      "Epoch 00067: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2611 - accuracy: 0.9010 - precision: 0.9527 - recall: 0.9096 - true_positives: 322.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 32.0000 - val_loss: 1.1427 - val_accuracy: 0.5536 - val_precision: 0.8800 - val_recall: 0.5000 - val_true_positives: 22.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 22.0000\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 68/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.3195 - accuracy: 0.8763 - precision: 0.9349 - recall: 0.8927 - true_positives: 316.0000 - true_negatives: 109.0000 - false_positives: 22.0000 - false_negatives: 38.0000\n",
      "Epoch 00068: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.3195 - accuracy: 0.8763 - precision: 0.9349 - recall: 0.8927 - true_positives: 316.0000 - true_negatives: 109.0000 - false_positives: 22.0000 - false_negatives: 38.0000 - val_loss: 1.0788 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 69/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2674 - accuracy: 0.9113 - precision: 0.9534 - recall: 0.9237 - true_positives: 327.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 27.0000\n",
      "Epoch 00069: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2674 - accuracy: 0.9113 - precision: 0.9534 - recall: 0.9237 - true_positives: 327.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 27.0000 - val_loss: 1.1304 - val_accuracy: 0.5536 - val_precision: 0.8800 - val_recall: 0.5000 - val_true_positives: 22.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 22.0000\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to 1.0000000000000004e-10.\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - ETA: 0s - loss: 0.2694 - accuracy: 0.8887 - precision: 0.9438 - recall: 0.9011 - true_positives: 319.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 35.0000\n",
      "Epoch 00070: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2694 - accuracy: 0.8887 - precision: 0.9438 - recall: 0.9011 - true_positives: 319.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 35.0000 - val_loss: 1.0790 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 71/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2755 - accuracy: 0.9031 - precision: 0.9582 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 117.0000 - false_positives: 14.0000 - false_negatives: 33.0000\n",
      "Epoch 00071: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2755 - accuracy: 0.9031 - precision: 0.9582 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 117.0000 - false_positives: 14.0000 - false_negatives: 33.0000 - val_loss: 1.0977 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 72/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2925 - accuracy: 0.8742 - precision: 0.9508 - recall: 0.8729 - true_positives: 309.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 45.0000\n",
      "Epoch 00072: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2925 - accuracy: 0.8742 - precision: 0.9508 - recall: 0.8729 - true_positives: 309.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 45.0000 - val_loss: 1.1412 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 73/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2820 - accuracy: 0.8804 - precision: 0.9512 - recall: 0.8814 - true_positives: 312.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 42.0000\n",
      "Epoch 00073: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2820 - accuracy: 0.8804 - precision: 0.9512 - recall: 0.8814 - true_positives: 312.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 42.0000 - val_loss: 1.1577 - val_accuracy: 0.5536 - val_precision: 0.8800 - val_recall: 0.5000 - val_true_positives: 22.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 22.0000\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 74/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2475 - accuracy: 0.9134 - precision: 0.9643 - recall: 0.9153 - true_positives: 324.0000 - true_negatives: 119.0000 - false_positives: 12.0000 - false_negatives: 30.0000\n",
      "Epoch 00074: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2475 - accuracy: 0.9134 - precision: 0.9643 - recall: 0.9153 - true_positives: 324.0000 - true_negatives: 119.0000 - false_positives: 12.0000 - false_negatives: 30.0000 - val_loss: 1.1805 - val_accuracy: 0.5536 - val_precision: 0.8800 - val_recall: 0.5000 - val_true_positives: 22.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 22.0000\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 75/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2757 - accuracy: 0.8928 - precision: 0.9632 - recall: 0.8870 - true_positives: 314.0000 - true_negatives: 119.0000 - false_positives: 12.0000 - false_negatives: 40.0000\n",
      "Epoch 00075: loss did not improve from 0.24505\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2757 - accuracy: 0.8928 - precision: 0.9632 - recall: 0.8870 - true_positives: 314.0000 - true_negatives: 119.0000 - false_positives: 12.0000 - false_negatives: 40.0000 - val_loss: 1.2095 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 76/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2385 - accuracy: 0.9072 - precision: 0.9640 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 119.0000 - false_positives: 12.0000 - false_negatives: 33.0000\n",
      "Epoch 00076: loss improved from 0.24505 to 0.23848, saving model to /home/rajarshi/Documents/Datasets/Health/Leukomia/big_images/train/nucleus/resnet50_1/best_model.h5\n",
      "97/97 [==============================] - 5s 49ms/step - loss: 0.2385 - accuracy: 0.9072 - precision: 0.9640 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 119.0000 - false_positives: 12.0000 - false_negatives: 33.0000 - val_loss: 1.1263 - val_accuracy: 0.5357 - val_precision: 0.8750 - val_recall: 0.4773 - val_true_positives: 21.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 23.0000\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 77/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2747 - accuracy: 0.8887 - precision: 0.9412 - recall: 0.9040 - true_positives: 320.0000 - true_negatives: 111.0000 - false_positives: 20.0000 - false_negatives: 34.0000\n",
      "Epoch 00077: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 35ms/step - loss: 0.2747 - accuracy: 0.8887 - precision: 0.9412 - recall: 0.9040 - true_positives: 320.0000 - true_negatives: 111.0000 - false_positives: 20.0000 - false_negatives: 34.0000 - val_loss: 1.1358 - val_accuracy: 0.5536 - val_precision: 0.8800 - val_recall: 0.5000 - val_true_positives: 22.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 22.0000\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 78/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2771 - accuracy: 0.8887 - precision: 0.9386 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 110.0000 - false_positives: 21.0000 - false_negatives: 33.0000\n",
      "Epoch 00078: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2771 - accuracy: 0.8887 - precision: 0.9386 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 110.0000 - false_positives: 21.0000 - false_negatives: 33.0000 - val_loss: 1.1237 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 79/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2562 - accuracy: 0.8948 - precision: 0.9496 - recall: 0.9040 - true_positives: 320.0000 - true_negatives: 114.0000 - false_positives: 17.0000 - false_negatives: 34.0000\n",
      "Epoch 00079: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2562 - accuracy: 0.8948 - precision: 0.9496 - recall: 0.9040 - true_positives: 320.0000 - true_negatives: 114.0000 - false_positives: 17.0000 - false_negatives: 34.0000 - val_loss: 1.1053 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to 1.0000000000000004e-11.\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - ETA: 0s - loss: 0.2593 - accuracy: 0.9010 - precision: 0.9554 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 116.0000 - false_positives: 15.0000 - false_negatives: 33.0000\n",
      "Epoch 00080: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2593 - accuracy: 0.9010 - precision: 0.9554 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 116.0000 - false_positives: 15.0000 - false_negatives: 33.0000 - val_loss: 1.1918 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 81/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2763 - accuracy: 0.8928 - precision: 0.9441 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 33.0000\n",
      "Epoch 00081: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2763 - accuracy: 0.8928 - precision: 0.9441 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 33.0000 - val_loss: 1.1576 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 82/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2772 - accuracy: 0.8907 - precision: 0.9547 - recall: 0.8927 - true_positives: 316.0000 - true_negatives: 116.0000 - false_positives: 15.0000 - false_negatives: 38.0000\n",
      "Epoch 00082: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2772 - accuracy: 0.8907 - precision: 0.9547 - recall: 0.8927 - true_positives: 316.0000 - true_negatives: 116.0000 - false_positives: 15.0000 - false_negatives: 38.0000 - val_loss: 1.2013 - val_accuracy: 0.6071 - val_precision: 0.8929 - val_recall: 0.5682 - val_true_positives: 25.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 19.0000\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 83/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2620 - accuracy: 0.9031 - precision: 0.9475 - recall: 0.9181 - true_positives: 325.0000 - true_negatives: 113.0000 - false_positives: 18.0000 - false_negatives: 29.0000\n",
      "Epoch 00083: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2620 - accuracy: 0.9031 - precision: 0.9475 - recall: 0.9181 - true_positives: 325.0000 - true_negatives: 113.0000 - false_positives: 18.0000 - false_negatives: 29.0000 - val_loss: 1.2033 - val_accuracy: 0.6071 - val_precision: 0.8929 - val_recall: 0.5682 - val_true_positives: 25.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 19.0000\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 84/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2853 - accuracy: 0.8825 - precision: 0.9355 - recall: 0.9011 - true_positives: 319.0000 - true_negatives: 109.0000 - false_positives: 22.0000 - false_negatives: 35.0000\n",
      "Epoch 00084: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2853 - accuracy: 0.8825 - precision: 0.9355 - recall: 0.9011 - true_positives: 319.0000 - true_negatives: 109.0000 - false_positives: 22.0000 - false_negatives: 35.0000 - val_loss: 1.2497 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 85/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2565 - accuracy: 0.8887 - precision: 0.9491 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 114.0000 - false_positives: 17.0000 - false_negatives: 37.0000\n",
      "Epoch 00085: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2565 - accuracy: 0.8887 - precision: 0.9491 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 114.0000 - false_positives: 17.0000 - false_negatives: 37.0000 - val_loss: 1.1580 - val_accuracy: 0.5536 - val_precision: 0.8800 - val_recall: 0.5000 - val_true_positives: 22.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 22.0000\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 86/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2650 - accuracy: 0.8907 - precision: 0.9413 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 111.0000 - false_positives: 20.0000 - false_negatives: 33.0000\n",
      "Epoch 00086: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2650 - accuracy: 0.8907 - precision: 0.9413 - recall: 0.9068 - true_positives: 321.0000 - true_negatives: 111.0000 - false_positives: 20.0000 - false_negatives: 33.0000 - val_loss: 1.1116 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 87/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2600 - accuracy: 0.8845 - precision: 0.9461 - recall: 0.8927 - true_positives: 316.0000 - true_negatives: 113.0000 - false_positives: 18.0000 - false_negatives: 38.0000\n",
      "Epoch 00087: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2600 - accuracy: 0.8845 - precision: 0.9461 - recall: 0.8927 - true_positives: 316.0000 - true_negatives: 113.0000 - false_positives: 18.0000 - false_negatives: 38.0000 - val_loss: 1.1347 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 88/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2606 - accuracy: 0.8948 - precision: 0.9443 - recall: 0.9096 - true_positives: 322.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 32.0000\n",
      "Epoch 00088: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2606 - accuracy: 0.8948 - precision: 0.9443 - recall: 0.9096 - true_positives: 322.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 32.0000 - val_loss: 1.1883 - val_accuracy: 0.5357 - val_precision: 0.8750 - val_recall: 0.4773 - val_true_positives: 21.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 23.0000\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 89/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2936 - accuracy: 0.8907 - precision: 0.9440 - recall: 0.9040 - true_positives: 320.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 34.0000\n",
      "Epoch 00089: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2936 - accuracy: 0.8907 - precision: 0.9440 - recall: 0.9040 - true_positives: 320.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 34.0000 - val_loss: 1.1906 - val_accuracy: 0.5179 - val_precision: 0.8696 - val_recall: 0.4545 - val_true_positives: 20.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 24.0000\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to 1.0000000000000006e-12.\n",
      "Epoch 90/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2742 - accuracy: 0.9010 - precision: 0.9581 - recall: 0.9040 - true_positives: 320.0000 - true_negatives: 117.0000 - false_positives: 14.0000 - false_negatives: 34.0000\n",
      "Epoch 00090: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 35ms/step - loss: 0.2742 - accuracy: 0.9010 - precision: 0.9581 - recall: 0.9040 - true_positives: 320.0000 - true_negatives: 117.0000 - false_positives: 14.0000 - false_negatives: 34.0000 - val_loss: 1.1314 - val_accuracy: 0.5357 - val_precision: 0.8750 - val_recall: 0.4773 - val_true_positives: 21.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 23.0000\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 91/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2778 - accuracy: 0.8948 - precision: 0.9577 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 117.0000 - false_positives: 14.0000 - false_negatives: 37.0000\n",
      "Epoch 00091: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2778 - accuracy: 0.8948 - precision: 0.9577 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 117.0000 - false_positives: 14.0000 - false_negatives: 37.0000 - val_loss: 1.1718 - val_accuracy: 0.5536 - val_precision: 0.8800 - val_recall: 0.5000 - val_true_positives: 22.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 22.0000\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 92/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2605 - accuracy: 0.8928 - precision: 0.9521 - recall: 0.8983 - true_positives: 318.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 36.0000\n",
      "Epoch 00092: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2605 - accuracy: 0.8928 - precision: 0.9521 - recall: 0.8983 - true_positives: 318.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 36.0000 - val_loss: 1.1219 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 93/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2990 - accuracy: 0.8680 - precision: 0.9315 - recall: 0.8842 - true_positives: 313.0000 - true_negatives: 108.0000 - false_positives: 23.0000 - false_negatives: 41.0000\n",
      "Epoch 00093: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 35ms/step - loss: 0.2990 - accuracy: 0.8680 - precision: 0.9315 - recall: 0.8842 - true_positives: 313.0000 - true_negatives: 108.0000 - false_positives: 23.0000 - false_negatives: 41.0000 - val_loss: 1.0899 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 94/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2738 - accuracy: 0.8990 - precision: 0.9499 - recall: 0.9096 - true_positives: 322.0000 - true_negatives: 114.0000 - false_positives: 17.0000 - false_negatives: 32.0000\n",
      "Epoch 00094: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2738 - accuracy: 0.8990 - precision: 0.9499 - recall: 0.9096 - true_positives: 322.0000 - true_negatives: 114.0000 - false_positives: 17.0000 - false_negatives: 32.0000 - val_loss: 1.1061 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 95/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2911 - accuracy: 0.8804 - precision: 0.9431 - recall: 0.8898 - true_positives: 315.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 39.0000\n",
      "Epoch 00095: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2911 - accuracy: 0.8804 - precision: 0.9431 - recall: 0.8898 - true_positives: 315.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 39.0000 - val_loss: 1.1284 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 96/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2686 - accuracy: 0.9052 - precision: 0.9503 - recall: 0.9181 - true_positives: 325.0000 - true_negatives: 114.0000 - false_positives: 17.0000 - false_negatives: 29.0000\n",
      "Epoch 00096: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2686 - accuracy: 0.9052 - precision: 0.9503 - recall: 0.9181 - true_positives: 325.0000 - true_negatives: 114.0000 - false_positives: 17.0000 - false_negatives: 29.0000 - val_loss: 1.0730 - val_accuracy: 0.6071 - val_precision: 0.8929 - val_recall: 0.5682 - val_true_positives: 25.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 19.0000\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 97/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2813 - accuracy: 0.8948 - precision: 0.9577 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 117.0000 - false_positives: 14.0000 - false_negatives: 37.0000\n",
      "Epoch 00097: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2813 - accuracy: 0.8948 - precision: 0.9577 - recall: 0.8955 - true_positives: 317.0000 - true_negatives: 117.0000 - false_positives: 14.0000 - false_negatives: 37.0000 - val_loss: 1.0758 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 98/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2671 - accuracy: 0.8928 - precision: 0.9521 - recall: 0.8983 - true_positives: 318.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 36.0000\n",
      "Epoch 00098: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2671 - accuracy: 0.8928 - precision: 0.9521 - recall: 0.8983 - true_positives: 318.0000 - true_negatives: 115.0000 - false_positives: 16.0000 - false_negatives: 36.0000 - val_loss: 1.1686 - val_accuracy: 0.6071 - val_precision: 0.8929 - val_recall: 0.5682 - val_true_positives: 25.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 19.0000\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 99/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.2882 - accuracy: 0.8845 - precision: 0.9543 - recall: 0.8842 - true_positives: 313.0000 - true_negatives: 116.0000 - false_positives: 15.0000 - false_negatives: 41.0000\n",
      "Epoch 00099: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2882 - accuracy: 0.8845 - precision: 0.9543 - recall: 0.8842 - true_positives: 313.0000 - true_negatives: 116.0000 - false_positives: 15.0000 - false_negatives: 41.0000 - val_loss: 1.1718 - val_accuracy: 0.5893 - val_precision: 0.8889 - val_recall: 0.5455 - val_true_positives: 24.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 20.0000\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to 1.0000000000000005e-13.\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - ETA: 0s - loss: 0.2839 - accuracy: 0.8866 - precision: 0.9436 - recall: 0.8983 - true_positives: 318.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 36.0000\n",
      "Epoch 00100: loss did not improve from 0.23848\n",
      "97/97 [==============================] - 3s 34ms/step - loss: 0.2839 - accuracy: 0.8866 - precision: 0.9436 - recall: 0.8983 - true_positives: 318.0000 - true_negatives: 112.0000 - false_positives: 19.0000 - false_negatives: 36.0000 - val_loss: 1.2018 - val_accuracy: 0.5714 - val_precision: 0.8846 - val_recall: 0.5227 - val_true_positives: 23.0000 - val_true_negatives: 9.0000 - val_false_positives: 3.0000 - val_false_negatives: 21.0000\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.2632 - accuracy: 0.9155 - precision: 1.0000 - recall: 0.8842 - true_positives: 313.0000 - true_negatives: 131.0000 - false_positives: 0.0000e+00 - false_negatives: 41.0000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.2018 - accuracy: 0.5714 - precision: 0.8846 - recall: 0.5227 - true_positives: 23.0000 - true_negatives: 9.0000 - false_positives: 3.0000 - false_negatives: 21.0000\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.0200 - accuracy: 0.6167 - precision: 0.8571 - recall: 0.5581 - true_positives: 24.0000 - true_negatives: 13.0000 - false_positives: 4.0000 - false_negatives: 19.0000\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    start = time.time()\n",
    "    history = model.fit(train_generator,\n",
    "                        epochs = epoch,\n",
    "                        verbose = 1,\n",
    "                        callbacks = callback,\n",
    "                        validation_data = validation_generator,\n",
    "                        shuffle=True)\n",
    "\n",
    "    end = time.time()\n",
    "    duration = end-start\n",
    "\n",
    "train_score = model.evaluate(train_generator)\n",
    "val_score = model.evaluate(validation_generator)\n",
    "test_score = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 388.5651707649231 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Execution Time: {} seconds\".format(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "epochs=range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title('Training and validation accuracy vs Epochs')\n",
    "plt.legend()\n",
    "accuracy_fig_name = \"accuracy.eps\"\n",
    "plt.savefig(os.path.join(char, accuracy_fig_name))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title('Training and validation loss vs Epochs')\n",
    "plt.legend()\n",
    "loss_fig_name = \"loss.eps\"\n",
    "\n",
    "plt.savefig(os.path.join(char, loss_fig_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: 91.5463924407959 %\n",
      "The validation accuracy is: 57.14285969734192 %\n",
      "The test accuracy is: 61.666667461395264 %\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = train_score[1]*100\n",
    "validation_accuracy = val_score[1]*100\n",
    "test_accuracy = test_score[1]*100\n",
    "\n",
    "print(\"The training accuracy is: \" + str(training_accuracy) + ' %')\n",
    "print(\"The validation accuracy is: \" + str(validation_accuracy) + ' %')\n",
    "print(\"The test accuracy is: \" + str(test_accuracy) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = test_score[1]*100\n",
    "test_precision = test_score[2]*100\n",
    "test_recall = test_score[3]*100\n",
    "tp = int(test_score[4])\n",
    "tn = int(test_score[5])\n",
    "fp = int(test_score[6])\n",
    "fn = int(test_score[7])\n",
    "\n",
    "f1 = 2*((test_precision*test_recall)/(test_precision+test_recall))\n",
    "sensitivity = (tp/(tp+fn))*100\n",
    "specificity = (tn/(tn+fp))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 61.666667461395264\n",
      "Test Precision: 85.71428656578064\n",
      "Test Recall: 55.81395626068115\n",
      "True Positive: 24\n",
      "Test Negetive: 13\n",
      "False Positive: 4\n",
      "False Negetive: 19\n",
      "Sensitivity: 55.81395348837209\n",
      "Specificity: 76.47058823529412\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy: {}\".format(test_accuracy))\n",
    "print(\"Test Precision: {}\".format(test_precision))\n",
    "print(\"Test Recall: {}\".format(test_recall))\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "print(\"Test Negetive: {}\".format(tn))\n",
    "print(\"False Positive: {}\".format(fp))\n",
    "print(\"False Negetive: {}\".format(fn))\n",
    "print(\"Sensitivity: {}\".format(sensitivity))\n",
    "print(\"Specificity: {}\".format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please read the text file named readme.txt for detailed information of the model.\n"
     ]
    }
   ],
   "source": [
    "from contextlib import redirect_stdout\n",
    "\n",
    "readme_name_text = \"readme.txt\"\n",
    "print(\"Please read the text file named \" + readme_name_text + \" for detailed information of the model.\")\n",
    "\n",
    "completeName_txt = os.path.join(char, readme_name_text) \n",
    "\n",
    "readme = open(completeName_txt, \"w\")\n",
    "\n",
    "if len(os.listdir(TRAINING_DIR)) > 2:\n",
    "    readme.write(\"This is a MULTICLASS CLASSIFICATION\")\n",
    "else:\n",
    "    readme.write(\"This is a BINARY CLASSIFICATION\")\n",
    "\n",
    "\n",
    "readme.write(\"\\n\\n--HYPERPARAMETERS--\\n\")\n",
    "readme.write(str(augmentation))\n",
    "readme.write(\"\\nInitial Learning Rate = \" + str(learning_rate))\n",
    "readme.write(\"\\nNo. of epochs = \" + str(len(acc)))\n",
    "readme.write(\"\\nBatch Size = \" + str(batch_size))\n",
    "\n",
    "\n",
    "readme.write(\"\\n\\n--MODEL-PARAMETERS--\")\n",
    "readme.write(\"\\nActivation Function = relu\")\n",
    "readme.write(\"\\nDropout = \" + str(int(dropout*100)) + \"%\")\n",
    "readme.write(\"\\nActivation function of the output layer = \" + str(output_activation))\n",
    "readme.write(\"\\nCost function of the model = \" + str(losses))\n",
    "readme.write(\"\\nOptimizer = \" + str(optimizer) + \"\\n\\n\")\n",
    "\n",
    "\n",
    "readme.write(\"Trained on a Resnet50 Model\\n\")\n",
    "with redirect_stdout(readme):\n",
    "    model.summary()\n",
    "        \n",
    "    \n",
    "readme.write(\"\\n\\n--MODEL-PERFORMANCE--\")\n",
    "readme.write(\"\\nTest Accuracy = \" + str(test_accuracy) + \" %\")\n",
    "readme.write(\"\\nTest Precision = \" + str(test_precision) + \" %\")\n",
    "readme.write(\"\\nTest Recall = \" + str(test_recall) + \" %\")\n",
    "readme.write(\"\\nTrue Positive = \" + str(tp))\n",
    "readme.write(\"\\nTrue Negetive = \" + str(tn))\n",
    "readme.write(\"\\nFalse Positive = \" + str(fp))\n",
    "readme.write(\"\\nFalse Negetive = \" + str(fn))\n",
    "readme.write(\"\\nSensitivity = \" + str(sensitivity))\n",
    "readme.write(\"\\nSpecificity = \" + str(specificity) + \" \\n\\n\\n\")\n",
    "\n",
    "\n",
    "readme.write(\"\\n\\n--MODEL-CHARACTERISTICS--\")\n",
    "readme.write(\"\\nacc = \" + str(acc))\n",
    "readme.write(\"\\n\\nval_acc = \" + str(val_acc))\n",
    "readme.write(\"\\n\\nloss = \" + str(loss))\n",
    "readme.write(\"\\n\\nval_loss = \" + str(val_loss))\n",
    "\n",
    "\n",
    "readme.write(\"\\nExecution Time: {} seconds\".format(duration))\n",
    "\n",
    "readme.write(\"\\n\\nCreated using Self-Regulated Image Classifier using Convolution Neural Network\")\n",
    "\n",
    "readme.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
