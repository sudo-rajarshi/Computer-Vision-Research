{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import matplotlib\n",
    "import glob\n",
    "import operator\n",
    "import psutil\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if physical_devices != []:\n",
    "    print(\"Using GPU\")\n",
    "    for i in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(i, True)\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path where 'classify train' directory belongs: /mnt/036b1314-13ad-429f-b9f9-07467946c5d7/Datasets/Health/OCT2017\n"
     ]
    }
   ],
   "source": [
    "root_dir = str(input(\"Path where 'classify train' directory belongs: \"))\n",
    "classify_train = os.path.join(root_dir, 'classify train')\n",
    "\n",
    "train_directory = os.path.join(classify_train, 'training')\n",
    "validation_directory = os.path.join(classify_train, 'validation')\n",
    "test_directory = os.path.join(classify_train, 'testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/mnt/036b1314-13ad-429f-b9f9-07467946c5d7/Datasets/Health/OCT2017/classify train/training',\n",
       " '/mnt/036b1314-13ad-429f-b9f9-07467946c5d7/Datasets/Health/OCT2017/classify train/validation',\n",
       " '/mnt/036b1314-13ad-429f-b9f9-07467946c5d7/Datasets/Health/OCT2017/classify train/testing')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_directory, validation_directory, test_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the initial learning rate: 0.001\n",
      "Enter the maximum number of epochs: 100\n",
      "Enter batch size: 8\n"
     ]
    }
   ],
   "source": [
    "learning_rate = float(input(\"Enter the initial learning rate: \"))\n",
    "epoch = int(input(\"Enter the maximum number of epochs: \"))\n",
    "batch_size = int(input(\"Enter batch size: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter name of the characteristics folder: vgg16\n"
     ]
    }
   ],
   "source": [
    "char_name = str(input(\"Enter name of the characteristics folder: \"))\n",
    "\n",
    "char = os.path.join(root_dir, char_name)\n",
    "\n",
    "if not os.path.exists(char):\n",
    "    os.mkdir(char)\n",
    "else:\n",
    "    replace = str(input(\"Folder already exists ! Do you want to replace it ?(Y/N) \"))\n",
    "    if replace.upper() == 'Y':      \n",
    "        shutil.rmtree(char)\n",
    "        os.mkdir(char)\n",
    "    elif replace.upper() == 'N':\n",
    "        print('\\nThe following folders already exist:')\n",
    "        for i in os.listdir(root_dir): \n",
    "            print(i)\n",
    "        char_name = str(input(\"\\nEnter a new name of the characteristics folder: \"))\n",
    "        char = os.path.join(root_dir, char_name)\n",
    "        if not os.path.exists(char):\n",
    "            os.mkdir(char)\n",
    "        else:\n",
    "            print(f\"{char_name} replaced\")\n",
    "            shutil.rmtree(char)\n",
    "            os.mkdir(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 10 # change steps to 1 to apply exponential decay\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return learning_rate * (0.1 ** int(epoch / steps))\n",
    "    \n",
    "best_model_address = os.path.join(char, 'best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 1 to monitor Validation Accuracy\n",
      "Press 2 to monitor Validation Loss\n",
      "Press 3 to monitor Training Accuracy\n",
      "Press 4 to monitor Training Loss\n",
      "4\n",
      "Enter number of epochs that will produce monitored quantity with no improvement after which training will be stopped: 10\n",
      "\n",
      "MONITORING TRAINING LOSS..........\n",
      "\n",
      "\n",
      "Training will stop if loss doesn't show any improvements for 10 epcohs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "monitor = int(input(\"Press 1 to monitor Validation Accuracy\\nPress 2 to monitor Validation Loss\\nPress 3 to monitor Training Accuracy\\nPress 4 to monitor Training Loss\\n\"))\n",
    "patience = int(input('Enter number of epochs that will produce monitored quantity with no improvement after which training will be stopped: '))\n",
    "\n",
    "\n",
    "if monitor == 1:\n",
    "    metric = 'val_accuracy'\n",
    "    mode = 'max'\n",
    "    print(\"\\nMONITORING VALIDATION ACCURACY..........\\n\")\n",
    "\n",
    "elif monitor == 2:\n",
    "    metric = 'val_loss'\n",
    "    mode = 'min'\n",
    "    print(\"\\nMONITORING VALIDATION LOSS..........\\n\")\n",
    "\n",
    "elif monitor == 3:\n",
    "    metric = 'accuracy'\n",
    "    mode = 'max'\n",
    "    print(\"\\nMONITORING TRAINING ACCURACY..........\\n\")\n",
    "\n",
    "elif monitor == 4:\n",
    "    metric = 'loss'\n",
    "    mode = 'min'\n",
    "    print(\"\\nMONITORING TRAINING LOSS..........\\n\")\n",
    "\n",
    "callback = [keras.callbacks.LearningRateScheduler(lr_schedule, verbose = 1),\n",
    "            keras.callbacks.EarlyStopping(monitor = metric, min_delta = 0.001, patience = patience, verbose=1, mode = mode, restore_best_weights = True),\n",
    "            keras.callbacks.ModelCheckpoint(best_model_address, monitor = metric, verbose=1, save_best_only=True, save_weights_only=False, mode = mode)]\n",
    "\n",
    "print(f\"\\nTraining will stop if {metric} doesn't show any improvements for {patience} epcohs\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16():\n",
    "    print(\"\\nTRAINING ON VGG16 MODEL:-\")\n",
    "\n",
    "    base_model = tf.keras.applications.VGG16(input_shape = dim, weights = 'imagenet', include_top = False)\n",
    "\n",
    "    x = base_model.output\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(256)(x)\n",
    "    \n",
    "    predictions = Dense(output_neurons, activation = output_activation)(x)  \n",
    "\n",
    "    model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "    train_base_model = str(input(\"Do you want to extract features using VGG16?(Y/N) \"))\n",
    "    if train_base_model.upper() == 'Y':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    elif train_base_model.upper() == 'N':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a 4-Class Classification\n"
     ]
    }
   ],
   "source": [
    "class_no = len(os.listdir(train_directory))\n",
    "\n",
    "print(\"This is a \" + str(class_no) + \"-Class Classification\")\n",
    "\n",
    "if class_no <= 2:\n",
    "    class_mode = 'binary'\n",
    "    output_activation = 'sigmoid'\n",
    "    output_neurons = 1\n",
    "    losses = 'binary_crossentropy'\n",
    "\n",
    "else:\n",
    "    class_mode = 'categorical'\n",
    "    output_activation = 'softmax'\n",
    "    output_neurons = class_no\n",
    "    losses = 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_selection():\n",
    "    print(\"\\nSelect a optimizer which will reduce the loss of the model.\\n\")\n",
    "\n",
    "    optimizer_select = int(input(\"Press 1 to select Stochastic Gradient Descent\\nPress 2 to select RMSprop\\nPress 3 to select Adagrad\\nPress 4 to select Adadelta\\nPress 5 to select Adam\\nPress 6 to select Adamax\\nPress 7 to select Nadam\\n\"))\n",
    "\n",
    "    if optimizer_select == 1:\n",
    "        optimizer = SGD(lr = learning_rate, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "\n",
    "    elif optimizer_select == 2:\n",
    "        optimizer = RMSprop(learning_rate, rho = 0.9)\n",
    "\n",
    "    elif optimizer_select == 3:\n",
    "        optimizer = Adagrad(learning_rate)\n",
    "\n",
    "    elif optimizer_select == 4:\n",
    "        optimizer = Adadelta(learning_rate, rho = 0.95)\n",
    "\n",
    "    elif optimizer_select == 5:\n",
    "        optimizer = Adam(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\n",
    "\n",
    "    elif optimizer_select == 6:\n",
    "        optimizer = Adamax(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999)\n",
    "\n",
    "    elif optimizer_select == 7:\n",
    "        optimizer = Nadam(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999)\n",
    "   \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Dimension(H or W): 128\n",
      "Press 1 for RGB \n",
      "Press 2 for Grayscale 1\n"
     ]
    }
   ],
   "source": [
    "h = int(input(\"Image Dimension(H or W): \"))\n",
    "w = h\n",
    "color = int(input(\"Press 1 for RGB \\nPress 2 for Grayscale \"))\n",
    "if color == 1:\n",
    "    color_mode = 'rgb'\n",
    "    dim = (h,w,3)\n",
    "elif color == 2:\n",
    "    color_mode = 'grayscale'\n",
    "    dim = (h,w,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 59120 images belonging to 4 classes.\n",
      "Found 12666 images belonging to 4 classes.\n",
      "Found 12666 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "train_generator = train_datagen.flow_from_directory(train_directory,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    class_mode = class_mode,\n",
    "                                                    color_mode = color_mode,\n",
    "                                                    target_size = (h,w),\n",
    "                                                    shuffle=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_directory,\n",
    "                                                              batch_size = batch_size,\n",
    "                                                              class_mode = class_mode,\n",
    "                                                              color_mode = color_mode,\n",
    "                                                              target_size = (h,w),\n",
    "                                                              shuffle=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "test_generator = test_datagen.flow_from_directory(test_directory,\n",
    "                                                  batch_size = batch_size,\n",
    "                                                  class_mode = class_mode,\n",
    "                                                  color_mode = color_mode,\n",
    "                                                  target_size = (h,w),\n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select a optimizer which will reduce the loss of the model.\n",
      "\n",
      "Press 1 to select Stochastic Gradient Descent\n",
      "Press 2 to select RMSprop\n",
      "Press 3 to select Adagrad\n",
      "Press 4 to select Adadelta\n",
      "Press 5 to select Adam\n",
      "Press 6 to select Adamax\n",
      "Press 7 to select Nadam\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "optimizer = optimizer_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING ON VGG16 MODEL:-\n",
      "Do you want to extract features using VGG16?(Y/N) y\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 16,813,124\n",
      "Trainable params: 16,813,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG16()\n",
    "model.compile(optimizer = optimizer, loss = losses, metrics = ['accuracy', \n",
    "                                                               tf.keras.metrics.Precision(), \n",
    "                                                               tf.keras.metrics.Recall(), \n",
    "                                                               tf.keras.metrics.TruePositives(), \n",
    "                                                               tf.keras.metrics.TrueNegatives(), \n",
    "                                                               tf.keras.metrics.FalsePositives(),\n",
    "                                                               tf.keras.metrics.FalseNegatives()])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n",
      "7390/7390 [==============================] - 414s 54ms/step - loss: 1.2751 - accuracy: 0.4419 - precision: 0.4172 - recall: 0.0140 - true_positives: 195.4087 - true_negatives: 88428.7101 - false_positives: 275.2867 - false_negatives: 29372.5902 - val_loss: 1.2341 - val_accuracy: 0.4435 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_true_positives: 0.0000e+00 - val_true_negatives: 37998.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 12666.0000\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.24148, saving model to /mnt/036b1314-13ad-429f-b9f9-07467946c5d7/Datasets/Health/OCT2017/vgg16/best_model.h5\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n",
      "7390/7390 [==============================] - 414s 56ms/step - loss: 1.2348 - accuracy: 0.4423 - precision: 0.3419 - recall: 0.0012 - true_positives: 32.7860 - true_negatives: 88658.1032 - false_positives: 45.8935 - false_negatives: 29535.2130 - val_loss: 1.2342 - val_accuracy: 0.4435 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_true_positives: 0.0000e+00 - val_true_negatives: 37998.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 12666.0000\n",
      "\n",
      "Epoch 00002: loss improved from 1.24148 to 1.23507, saving model to /mnt/036b1314-13ad-429f-b9f9-07467946c5d7/Datasets/Health/OCT2017/vgg16/best_model.h5\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n",
      "7390/7390 [==============================] - 419s 57ms/step - loss: 1.2331 - accuracy: 0.4440 - precision: 0.3962 - recall: 0.0018 - true_positives: 46.1452 - true_negatives: 88646.0088 - false_positives: 57.9880 - false_negatives: 29521.8537 - val_loss: 1.2342 - val_accuracy: 0.4435 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_true_positives: 0.0000e+00 - val_true_negatives: 37998.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 12666.0000\n",
      "\n",
      "Epoch 00003: loss improved from 1.23507 to 1.23482, saving model to /mnt/036b1314-13ad-429f-b9f9-07467946c5d7/Datasets/Health/OCT2017/vgg16/best_model.h5\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n",
      "7390/7390 [==============================] - 419s 57ms/step - loss: 1.2375 - accuracy: 0.4431 - precision: 0.1328 - recall: 3.5916e-04 - true_positives: 17.9828 - true_negatives: 88682.5467 - false_positives: 21.4500 - false_negatives: 29550.0161 - val_loss: 1.2337 - val_accuracy: 0.4435 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_true_positives: 0.0000e+00 - val_true_negatives: 37998.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 12666.0000\n",
      "\n",
      "Epoch 00004: loss improved from 1.23482 to 1.23479, saving model to /mnt/036b1314-13ad-429f-b9f9-07467946c5d7/Datasets/Health/OCT2017/vgg16/best_model.h5\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n",
      "7390/7390 [==============================] - 422s 57ms/step - loss: 1.2321 - accuracy: 0.4460 - precision: 0.3671 - recall: 4.0301e-04 - true_positives: 14.9533 - true_negatives: 88682.0143 - false_positives: 21.9824 - false_negatives: 29553.0456 - val_loss: 1.2346 - val_accuracy: 0.4435 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_true_positives: 0.0000e+00 - val_true_negatives: 37998.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 12666.0000\n",
      "\n",
      "Epoch 00005: loss improved from 1.23479 to 1.23453, saving model to /mnt/036b1314-13ad-429f-b9f9-07467946c5d7/Datasets/Health/OCT2017/vgg16/best_model.h5\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n",
      "7390/7390 [==============================] - 420s 57ms/step - loss: 1.2344 - accuracy: 0.4419 - precision: 0.2787 - recall: 1.8793e-04 - true_positives: 4.4585 - true_negatives: 88694.1882 - false_positives: 9.8086 - false_negatives: 29563.5404 - val_loss: 1.2360 - val_accuracy: 0.4435 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_true_positives: 0.0000e+00 - val_true_negatives: 37998.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 12666.0000\n",
      "\n",
      "Epoch 00006: loss did not improve from 1.23453\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n",
      "7390/7390 [==============================] - 418s 57ms/step - loss: 1.2358 - accuracy: 0.4426 - precision: 0.0000e+00 - recall: 0.0000e+00 - true_positives: 0.0000e+00 - true_negatives: 88703.9968 - false_positives: 0.0000e+00 - false_negatives: 29567.9989 - val_loss: 1.2344 - val_accuracy: 0.4435 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_true_positives: 0.0000e+00 - val_true_negatives: 37998.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 12666.0000\n",
      "\n",
      "Epoch 00007: loss improved from 1.23453 to 1.23434, saving model to /mnt/036b1314-13ad-429f-b9f9-07467946c5d7/Datasets/Health/OCT2017/vgg16/best_model.h5\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n",
      "7390/7390 [==============================] - 418s 57ms/step - loss: 1.2320 - accuracy: 0.4466 - precision: 0.0494 - recall: 7.4490e-06 - true_positives: 0.3953 - true_negatives: 88702.8107 - false_positives: 1.1860 - false_negatives: 29567.6036 - val_loss: 1.2335 - val_accuracy: 0.4435 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_true_positives: 0.0000e+00 - val_true_negatives: 37998.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 12666.0000\n",
      "\n",
      "Epoch 00008: loss improved from 1.23434 to 1.23433, saving model to /mnt/036b1314-13ad-429f-b9f9-07467946c5d7/Datasets/Health/OCT2017/vgg16/best_model.h5\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n",
      "7390/7390 [==============================] - 413s 56ms/step - loss: 1.2378 - accuracy: 0.4401 - precision: 0.0352 - recall: 1.5189e-05 - true_positives: 0.8429 - true_negatives: 88701.9497 - false_positives: 2.0471 - false_negatives: 29567.1560 - val_loss: 1.2338 - val_accuracy: 0.4435 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_true_positives: 0.0000e+00 - val_true_negatives: 37998.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 12666.0000\n",
      "\n",
      "Epoch 00009: loss improved from 1.23433 to 1.23431, saving model to /mnt/036b1314-13ad-429f-b9f9-07467946c5d7/Datasets/Health/OCT2017/vgg16/best_model.h5\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n",
      "7390/7390 [==============================] - 411s 56ms/step - loss: 1.2347 - accuracy: 0.4409 - precision: 0.2807 - recall: 3.6393e-04 - true_positives: 13.4638 - true_negatives: 88686.6869 - false_positives: 17.3098 - false_negatives: 29554.5351 - val_loss: 1.2336 - val_accuracy: 0.4435 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_true_positives: 0.0000e+00 - val_true_negatives: 37998.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 12666.0000\n",
      "\n",
      "Epoch 00010: loss improved from 1.23431 to 1.23412, saving model to /mnt/036b1314-13ad-429f-b9f9-07467946c5d7/Datasets/Health/OCT2017/vgg16/best_model.h5\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "7390/7390 [==============================] - 402s 54ms/step - loss: 1.2317 - accuracy: 0.4422 - precision: 0.0000e+00 - recall: 0.0000e+00 - true_positives: 0.0000e+00 - true_negatives: 88703.9968 - false_positives: 0.0000e+00 - false_negatives: 29567.9989 - val_loss: 1.2335 - val_accuracy: 0.4435 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_true_positives: 0.0000e+00 - val_true_negatives: 37998.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 12666.0000\n",
      "\n",
      "Epoch 00011: loss improved from 1.23412 to 1.23360, saving model to /mnt/036b1314-13ad-429f-b9f9-07467946c5d7/Datasets/Health/OCT2017/vgg16/best_model.h5\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "2924/7390 [==========>...................] - ETA: 3:47 - loss: 1.2322 - accuracy: 0.4417 - precision: 0.0000e+00 - recall: 0.0000e+00 - true_positives: 0.0000e+00 - true_negatives: 35088.0000 - false_positives: 0.0000e+00 - false_negatives: 11696.000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6978/1325136428.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/GPU:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     history = model.fit(train_generator,\n\u001b[0m\u001b[1;32m      4\u001b[0m                         \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/87433d53-66f3-438e-a7f4-fc990fe61283/PROJECTS/PRODUCTS/Computer-Vision-Research/env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/87433d53-66f3-438e-a7f4-fc990fe61283/PROJECTS/PRODUCTS/Computer-Vision-Research/env/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/87433d53-66f3-438e-a7f4-fc990fe61283/PROJECTS/PRODUCTS/Computer-Vision-Research/env/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/87433d53-66f3-438e-a7f4-fc990fe61283/PROJECTS/PRODUCTS/Computer-Vision-Research/env/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/87433d53-66f3-438e-a7f4-fc990fe61283/PROJECTS/PRODUCTS/Computer-Vision-Research/env/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/87433d53-66f3-438e-a7f4-fc990fe61283/PROJECTS/PRODUCTS/Computer-Vision-Research/env/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/87433d53-66f3-438e-a7f4-fc990fe61283/PROJECTS/PRODUCTS/Computer-Vision-Research/env/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/87433d53-66f3-438e-a7f4-fc990fe61283/PROJECTS/PRODUCTS/Computer-Vision-Research/env/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m           \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m           \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m' %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    start = time.time()\n",
    "    history = model.fit(train_generator,\n",
    "                        epochs = epoch,\n",
    "                        verbose = 1,\n",
    "                        callbacks = callback,\n",
    "                        validation_data = validation_generator,\n",
    "                        shuffle=True)\n",
    "\n",
    "    end = time.time()\n",
    "    duration = end-start\n",
    "\n",
    "train_score = model.evaluate(train_generator)\n",
    "val_score = model.evaluate(validation_generator)\n",
    "test_score = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Execution Time: {} seconds\".format(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "epochs=range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title('Training and validation accuracy vs Epochs')\n",
    "plt.legend()\n",
    "fig_name_eps = \"accuracy.eps\"\n",
    "plt.savefig(os.path.join(char, fig_name_eps))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title('Training and validation loss vs Epochs')\n",
    "plt.legend()\n",
    "fig_name_eps = \"loss.eps\"\n",
    "plt.savefig(os.path.join(char, fig_name_eps))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title('Training and validation loss vs Epochs')\n",
    "plt.legend()\n",
    "fig_name_eps = \"char.eps\"\n",
    "plt.savefig(os.path.join(char, fig_name_eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = train_score[1]*100\n",
    "validation_accuracy = val_score[1]*100\n",
    "test_accuracy = test_score[1]*100\n",
    "\n",
    "print(\"The training accuracy is: \" + str(training_accuracy) + ' %')\n",
    "print(\"The validation accuracy is: \" + str(validation_accuracy) + ' %')\n",
    "print(\"The test accuracy is: \" + str(test_accuracy) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = test_score[1]*100\n",
    "test_precision = test_score[2]*100\n",
    "test_recall = test_score[3]*100\n",
    "tp = int(test_score[4])\n",
    "tn = int(test_score[5])\n",
    "fp = int(test_score[6])\n",
    "fn = int(test_score[7])\n",
    "\n",
    "f1 = 2*((test_precision*test_recall)/(test_precision+test_recall))\n",
    "sensitivity = (tp/(tp+fn))*100\n",
    "specificity = (tn/(tn+fp))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Accuracy: {}\".format(test_accuracy))\n",
    "print(\"Test Precision: {}\".format(test_precision))\n",
    "print(\"Test Recall: {}\".format(test_recall))\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "print(\"Test Negetive: {}\".format(tn))\n",
    "print(\"False Positive: {}\".format(fp))\n",
    "print(\"False Negetive: {}\".format(fn))\n",
    "print(\"Sensitivity: {}\".format(sensitivity))\n",
    "print(\"Specificity: {}\".format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "\n",
    "readme_name_text = \"readme.txt\"\n",
    "print(f\"Please read the text file named {readme_name_text} for detailed information of the model.\")\n",
    "\n",
    "completeName_txt = os.path.join(char, readme_name_text) \n",
    "\n",
    "readme = open(completeName_txt, \"w\")\n",
    "\n",
    "if len(os.listdir(train_directory)) > 2:\n",
    "    readme.write(f\"This is a {len(os.listdir(train_directory))}-class CLASSIFICATION\")\n",
    "else:\n",
    "    readme.write(\"This is a BINARY CLASSIFICATION\")\n",
    "\n",
    "\n",
    "readme.write(\"\\n\\n--HYPERPARAMETERS--\\n\")\n",
    "readme.write(f\"\\nInitial Learning Rate = {learning_rate}\")\n",
    "readme.write(f\"\\nNo. of epochs = {len(acc)}\")\n",
    "readme.write(f\"\\nBatch Size = {batch_size}\")\n",
    "\n",
    "\n",
    "readme.write(\"\\n\\n--MODEL-PARAMETERS--\")\n",
    "readme.write(f\"\\nDropout for dense layer = {(int(d_dropout*100))} %\")\n",
    "readme.write(f\"\\nOptimizer = {optimizer}\\n\\n\")\n",
    "\n",
    "\n",
    "readme.write(\"Trained on a VGG16\\n\")\n",
    "with redirect_stdout(readme):\n",
    "    model.summary()\n",
    "        \n",
    "    \n",
    "readme.write(\"\\n\\n--MODEL-PERFORMANCE--\")\n",
    "readme.write(f\"\\nTest Accuracy = {test_accuracy} %\")\n",
    "readme.write(f\"\\nTest Precision = {test_precision} %\")\n",
    "readme.write(f\"\\nTest Recall = {test_recall} %\")\n",
    "readme.write(f\"\\nTrue Positive = {tp}\")\n",
    "readme.write(f\"\\nTrue Negetive = {tn}\")\n",
    "readme.write(f\"\\nFalse Positive = {fp}\")\n",
    "readme.write(f\"\\nFalse Negetive = {fn}\")\n",
    "readme.write(f\"\\nSensitivity = {sensitivity}\")\n",
    "readme.write(f\"\\nSpecificity = {specificity}\\n\\n\\n\")\n",
    "\n",
    "\n",
    "readme.write(\"\\n\\n--MODEL-CHARACTERISTICS--\")\n",
    "readme.write(f\"\\nacc = {acc}\")\n",
    "readme.write(f\"\\n\\nval_acc = {val_acc}\")\n",
    "readme.write(f\"\\n\\nloss = {loss}\")\n",
    "readme.write(f\"\\n\\nval_loss = {val_loss}\")\n",
    "\n",
    "\n",
    "readme.write(f\"\\n\\nExecution Time: {duration} seconds\")\n",
    "\n",
    "readme.write(\"\\n\\nCreated using Self-Regulated Image Classifier using Convolution Neural Network\")\n",
    "\n",
    "readme.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
