{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.applications import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16():\n",
    "    print(\"\\nTRAINING ON VGG16 MODEL:-\")\n",
    "\n",
    "    base_model = tf.keras.applications.VGG16(input_shape = dim, weights = 'imagenet', include_top = False)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(d_neurons)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(d_dropout)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    predictions = Dense(output_layer, activation = output_activation)(x)\n",
    "\n",
    "    model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "    train_base_model = str(input(\"Do you want to train the base model of VGG16?(Y/N) \"))\n",
    "    if train_base_model.upper() == 'Y':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    elif train_base_model.upper() == 'N':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg19():\n",
    "    print(\"\\nTRAINING ON VGG19 MODEL:-\")\n",
    "\n",
    "    base_model = tf.keras.applications.VGG19(input_shape = dim, weights = 'imagenet', include_top = False)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(d_neurons)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(d_dropout)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    predictions = Dense(output_layer, activation = output_activation)(x)\n",
    "\n",
    "    model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "    train_base_model = str(input(\"Do you want to train the base model of vgg19?(Y/N) \"))\n",
    "    if train_base_model.upper() == 'Y':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    elif train_base_model.upper() == 'N':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MobileNet():\n",
    "    print(\"\\nTRAINING ON MobileNet MODEL:-\")\n",
    "\n",
    "    base_model = tf.keras.applications.MobileNet(input_shape = dim, weights = 'imagenet', include_top = False)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(d_neurons)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(d_dropout)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    predictions = Dense(output_layer, activation = output_activation)(x)\n",
    "\n",
    "    model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "    train_base_model = str(input(\"Do you want to train the base model of MobileNet?(Y/N) \"))\n",
    "    if train_base_model.upper() == 'Y':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    elif train_base_model.upper() == 'N':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50():\n",
    "    print(\"\\nTRAINING ON ResNet50 MODEL:-\")\n",
    "\n",
    "    base_model = tf.keras.applications.ResNet50(input_shape = dim, weights = 'imagenet', include_top = False)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(d_neurons)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(d_dropout)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    predictions = Dense(output_layer, activation = output_activation)(x)\n",
    "\n",
    "    model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "    train_base_model = str(input(\"Do you want to train the base model of ResNet50?(Y/N) \"))\n",
    "    if train_base_model.upper() == 'Y':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    elif train_base_model.upper() == 'N':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionV3():\n",
    "    print(\"\\nTRAINING ON InceptionV3 MODEL:-\")\n",
    "    \n",
    "    base_model = tf.keras.applications.InceptionV3(input_shape = dim, weights = 'imagenet', include_top = False)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(d_neurons)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(d_dropout)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    predictions = Dense(output_layer, activation = output_activation)(x)\n",
    "\n",
    "    model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "    train_base_model = str(input(\"Do you want to train the base model of InceptionV3?(Y/N) \"))\n",
    "    if train_base_model.upper() == 'Y':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    elif train_base_model.upper() == 'N':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseNet121():\n",
    "    print(\"\\nTRAINING ON DenseNet121 MODEL:-\")\n",
    "\n",
    "    base_model = tf.keras.applications.DenseNet121(input_shape = dim, weights = 'imagenet', include_top = False)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(d_neurons)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(d_dropout)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    predictions = Dense(output_layer, activation = output_activation)(x)\n",
    "\n",
    "    model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "    train_base_model = str(input(\"Do you want to train the base model of DenseNet121?(Y/N) \"))\n",
    "    if train_base_model.upper() == 'Y':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    elif train_base_model.upper() == 'N':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xception():\n",
    "    print(\"\\nTRAINING ON Xception MODEL:-\")\n",
    "\n",
    "    base_model = tf.keras.applications.Xception(input_shape = dim, weights = 'imagenet', include_top = False)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(d_neurons)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(d_dropout)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    predictions = Dense(output_layer, activation = output_activation)(x)\n",
    "\n",
    "    model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "    train_base_model = str(input(\"Do you want to train the base model of Xception?(Y/N) \"))\n",
    "    if train_base_model.upper() == 'Y':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    elif train_base_model.upper() == 'N':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    no_layers = int(input('How many layers you want to use ? '))\n",
    "    no_filters = int(input('Put no. of filters in 1st conv2d layer: '))\n",
    "    no_conv = int(input('How many no. of convolution layers you want to use ? '))\n",
    "    f_dropout = int(input('Enter dropout for feature extraction: '))/100\n",
    "            \n",
    "    model = Sequential(name = 'CUSTOM')   # a void sequential list\n",
    "    \n",
    "    for l in range(no_layers):\n",
    "        m = 2**l  # m = increamental factor of filter\n",
    "        n = no_filters*m # n = no. of filters in convolution layer\n",
    "        for i in range(no_conv):\n",
    "            model.add(Conv2D(n, (3,3), padding = 'same', input_shape = dim))\n",
    "            model.add(LeakyReLU())\n",
    "        model.add(MaxPooling2D(2, 2))\n",
    "        model.add(Dropout(f_dropout))\n",
    "    \n",
    "    # flatten\n",
    "  \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # dense layer\n",
    "    m, n = 0, 0\n",
    "    for d in range(no_d_layers):\n",
    "        m = 2**d\n",
    "        n = d_neurons//m\n",
    "        model.add(Dense(n))\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(d_dropout))\n",
    "    model.add(Dense(output_layer, output_activation))\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_selection():\n",
    "    print(\"\\nSelect a optimizer which will reduce the loss of the model.\\n\")\n",
    "    optimizer_select = int(input(\"Press 1 to select Stochastic Gradient Descent\\nPress 2 to select RMSprop\\nPress 3 to select Adagrad\\nPress 4 to select Adadelta\\nPress 5 to select Adam\\nPress 6 to select Adamax\\nPress 7 to select Nadam\\n\"))\n",
    "\n",
    "    if optimizer_select == 1:\n",
    "        optimizer = SGD(lr = learning_rate, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "\n",
    "    elif optimizer_select == 2:\n",
    "        optimizer = RMSprop(learning_rate, rho = 0.9)\n",
    "\n",
    "    elif optimizer_select == 3:\n",
    "        optimizer = Adagrad(learning_rate)\n",
    "\n",
    "    elif optimizer_select == 4:\n",
    "        optimizer = Adadelta(learning_rate, rho = 0.95)\n",
    "\n",
    "    elif optimizer_select == 5:\n",
    "        optimizer = Adam(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\n",
    "\n",
    "    elif optimizer_select == 6:\n",
    "        optimizer = Adamax(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999)\n",
    "\n",
    "    elif optimizer_select == 7:\n",
    "        optimizer = Nadam(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999)\n",
    "   \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Dimension(H or W): 128\n"
     ]
    }
   ],
   "source": [
    "h = int(input(\"Image Dimension(H or W): \"))\n",
    "w = h\n",
    "dim = (h,w,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many dense layers you want to use ? 0\n",
      "Enter no.of neurons you want to use in 1st dense layer: 1\n",
      "Enter dropout for dense layer: 1\n"
     ]
    }
   ],
   "source": [
    "no_d_layers = int(input('How many dense layers you want to use ? '))\n",
    "d_neurons = int(input('Enter no.of neurons you want to use in 1st dense layer: '))\n",
    "d_dropout = int(input('Enter dropout for dense layer: '))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select a optimizer which will reduce the loss of the model.\n",
      "\n",
      "Press 1 to select Stochastic Gradient Descent\n",
      "Press 2 to select RMSprop\n",
      "Press 3 to select Adagrad\n",
      "Press 4 to select Adadelta\n",
      "Press 5 to select Adam\n",
      "Press 6 to select Adamax\n",
      "Press 7 to select Nadam\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = optimizer_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = 10\n",
    "output_activation = 'softmax'\n",
    "losses = 'mse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING ON Xception MODEL:-\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Xception() got an unexpected keyword argument 'input_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-08b912dbf7e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m model.compile(optimizer = optimizer, loss = losses, metrics = ['accuracy', \n\u001b[1;32m      3\u001b[0m                                                                \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTruePositives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-e210d8074c90>\u001b[0m in \u001b[0;36mXception\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTRAINING ON Xception MODEL:-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Xception() got an unexpected keyword argument 'input_shape'"
     ]
    }
   ],
   "source": [
    "model = Xception()\n",
    "model.compile(optimizer = optimizer, loss = losses, metrics = ['accuracy', \n",
    "                                                               tf.keras.metrics.Precision(), \n",
    "                                                               tf.keras.metrics.Recall(), \n",
    "                                                               tf.keras.metrics.TruePositives(), \n",
    "                                                               tf.keras.metrics.TrueNegatives(), \n",
    "                                                               tf.keras.metrics.FalsePositives(),\n",
    "                                                               tf.keras.metrics.FalseNegatives()])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
