{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if physical_devices != []:\n",
    "    print(\"Using GPU\")\n",
    "    for i in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(i, True)\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGGNet(dim, output_neurons, output_activation):\n",
    "    \"\"\"\n",
    "    dim = dimension of input tensor\n",
    "    output_neurons = number of neurons in output layers i.e. number of classes\n",
    "    output_activation = activation in output layer\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nTRAINING ON Custom VGG MODEL:-\")\n",
    "    \n",
    "    def block(tensor, conv_reps, n_filters):\n",
    "        \n",
    "        \"\"\"\n",
    "        x = previous tensor\n",
    "        n_conv = number of 2D convolution layers in each layer\n",
    "        n_filters = number of filters in each 2-D convolution layer\n",
    "        \"\"\"\n",
    "        \n",
    "        x = Conv2D(filters = n_filters, kernel_size = (3,3), padding = 'same')(tensor)\n",
    "        x = LeakyReLU()(x)\n",
    "        \n",
    "        for i in range(conv_reps-1):\n",
    "            x = Conv2D(filters = n_filters, kernel_size = (3,3), padding = 'same')(x)\n",
    "            x = LeakyReLU()(x)\n",
    "            \n",
    "        x = MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'same')(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    # input-layer\n",
    "    input = Input(shape = dim)\n",
    "        \n",
    "    # feature-extraction    \n",
    "    k = 64\n",
    "    x = block(input, conv_reps = 2, n_filters = k)\n",
    "    x = block(x, conv_reps = 2, n_filters = 2*k)\n",
    "    x = block(x, conv_reps = 3, n_filters = 4*k)\n",
    "    x = block(x, conv_reps = 3, n_filters = 8*k)\n",
    "    x = block(x, conv_reps = 3, n_filters = 16*k)\n",
    "    \n",
    "    # 3D -> 1D\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # fc-layers\n",
    "    for i in range(2):\n",
    "        x = Dense(4096)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "    \n",
    "    # output-layer\n",
    "    output = Dense(output_neurons, output_activation)(x)  \n",
    "    \n",
    "    # MODEL\n",
    "    model = Model(inputs = input, outputs = output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MobileNet(dim, output_neurons, output_activation):\n",
    "    \"\"\"\n",
    "    dim = dimension of input tensor\n",
    "    output_neurons = number of neurons in output layers i.e. number of classes\n",
    "    output_activation = activation in output layer\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nTRAINING ON Custom MobileNet MODEL:-\")\n",
    "    \n",
    "    def block(x, n_filters, d_strides):\n",
    "        \n",
    "        \"\"\"\n",
    "        x = previous tensor\n",
    "        n_filters = number of filters in each 2-D convolution layer\n",
    "        d_strides = stride in depthwise convolution layer\n",
    "        \"\"\"\n",
    "        \n",
    "        # depthwise\n",
    "        x = DepthwiseConv2D(kernel_size = (3,3), strides = d_strides, padding = 'same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "    \n",
    "        # pointwise\n",
    "        x = Conv2D(filters = n_filters, kernel_size = (1,1))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    # input-layer\n",
    "    input = Input(shape = dim)\n",
    "    \n",
    "    # feature-extraction\n",
    "    x = Conv2D(filters = 32, kernel_size = (3,3), strides = 2, padding = 'same')(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = block(x, n_filters = 64, d_strides = 1)\n",
    "    x = block(x, n_filters = 128, d_strides = 2)\n",
    "    x = block(x, n_filters = 128, d_strides = 1)\n",
    "    x = block(x, n_filters = 256, d_strides = 2)\n",
    "    x = block(x, n_filters = 256, d_strides = 1)\n",
    "    x = block(x, n_filters = 512, d_strides = 2)\n",
    "    \n",
    "    for i in range(5):\n",
    "        x = block(x, n_filters = 512, d_strides = 1)\n",
    "        \n",
    "    x = block(x, n_filters = 1024, d_strides = 2)\n",
    "    x = block(x, n_filters = 1024, d_strides = 1)\n",
    "    \n",
    "    # 3D -> 1D\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # output-layer\n",
    "    output = Dense(output_neurons, output_activation)(x)  \n",
    "    \n",
    "    # MODEL\n",
    "    model = Model(inputs = input, outputs = output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inception(dim, output_neurons, output_activation):\n",
    "    \"\"\"\n",
    "    dim = dimension of input tensor\n",
    "    output_neurons = number of neurons in output layers i.e. number of classes\n",
    "    output_activation = activation in output layer\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nTRAINING ON Inception MODEL:-\")\n",
    "    \n",
    "    def block(x, filters):\n",
    "        \"\"\"\n",
    "        x = previous tensor\n",
    "        filters = number of filters in each 2-D convolution layer\n",
    "        \"\"\"\n",
    "        \n",
    "        t1 = Conv2D(filters[0], kernel_size = (1,1))(x)\n",
    "        t1 = LeakyReLU()(t1)\n",
    "        \n",
    "        t2 = Conv2D(filters[1], kernel_size = (1,1))(x)\n",
    "        t2 = LeakyReLU()(t2)\n",
    "        t2 = Conv2D(filters[2], kernel_size = (3,3), padding = 'same')(t2)\n",
    "        t2 = LeakyReLU()(t2)\n",
    "        \n",
    "        t3 = Conv2D(filters[3], kernel_size = (1,1))(x)\n",
    "        t3 = LeakyReLU()(t3)\n",
    "        t3 = Conv2D(filters[4], kernel_size = (5,5), padding = 'same')(t3)\n",
    "        t3 = LeakyReLU()(t3)\n",
    "        \n",
    "        t4 = MaxPool2D(pool_size = (3,3), strides = 1, padding = 'same')(x)\n",
    "        t4 = Conv2D(filters[5], kernel_size = (1,1))(t4)\n",
    "        t4 = LeakyReLU()(t4)\n",
    "        \n",
    "        output = Concatenate()([t1, t2, t3, t4])\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    # input-layer\n",
    "    input = Input(shape = dim)\n",
    "    \n",
    "    x = Conv2D(filters = 64, kernel_size = (7,7), strides = 2, padding = 'same')(input)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPool2D(pool_size = (3,3), strides = 2, padding = 'same')(x)\n",
    "    \n",
    "    x = Conv2D(filters = 64, kernel_size = (1,1))(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Conv2D(filters = 192, kernel_size = (3,3), strides = 1, padding = 'same')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPool2D(pool_size = (3,3), strides = 2, padding = 'same')(x)\n",
    "    \n",
    "    x = block(x, [64, 96, 128, 16, 32, 32])\n",
    "    x = block(x, [128, 128, 192, 32, 96, 64])\n",
    "    x = MaxPool2D(pool_size = (3,3), strides = 2, padding = 'same')(x)\n",
    "    \n",
    "    x = block(x, [192, 96, 208, 16, 48, 64])\n",
    "    x = block(x, [160, 112, 224, 24, 64, 64])\n",
    "    x = block(x, [128, 128, 256, 24, 64, 64])\n",
    "    x = block(x, [112, 144, 288, 32, 64, 64])\n",
    "    x = block(x, [256, 160, 320, 32, 128, 128])\n",
    "    x = MaxPool2D(pool_size = (3,3), strides = 2, padding = 'same')(x)\n",
    "\n",
    "    x = block(x, [256, 160, 320, 32, 128, 128])\n",
    "    x = block(x, [384, 192, 384, 48, 128, 128])\n",
    "    \n",
    "    # 3D -> 1D\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    # output-layer\n",
    "    output = Dense(output_neurons, output_activation)(x)\n",
    "    \n",
    "    # MODEL\n",
    "    model = Model(inputs = input, outputs = output)    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(dim, output_neurons, output_activation):\n",
    "    \"\"\"\n",
    "    dim = dimension of input tensor\n",
    "    output_neurons = number of neurons in output layers i.e. number of classes\n",
    "    output_activation = activation in output layer\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nTRAINING ON ResNet50 MODEL:-\")\n",
    "    \n",
    "    def conv_batchnorm_leakyrelu(x, filters, kernel_size, strides=1):\n",
    "        \"\"\"\n",
    "        x = previous tensor\n",
    "        filters = number of filters in each 2-D convolution layer\n",
    "        kernel_size = kernel_size\n",
    "        strides = stride in convolution layer\n",
    "        \"\"\"\n",
    "        \n",
    "        x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def projection_block(tensor, filters, strides):\n",
    "        \"\"\"\n",
    "        tensor = previous tensor\n",
    "        filters = number of filters in each 2-D convolution layer\n",
    "        strides = stride in convolution layer\n",
    "        \"\"\"\n",
    "    \n",
    "        #left stream\n",
    "        x = conv_batchnorm_leakyrelu(tensor, filters=filters, kernel_size=(1,1), strides=1)\n",
    "        x = conv_batchnorm_leakyrelu(x, filters=filters, kernel_size=(3,3), strides=strides)\n",
    "        x = Conv2D(filters=4*filters, kernel_size=(1,1), strides=1)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        #right stream\n",
    "        shortcut = Conv2D(filters=4*filters, kernel_size=(1,1), strides=strides)(tensor)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "        x = Add()([shortcut, x])\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def identity_block(tensor, filters):\n",
    "        \"\"\"\n",
    "        tensor = previous tensor\n",
    "        filters = number of filters in each 2-D convolution layer\n",
    "        \"\"\"\n",
    "        \n",
    "        x = conv_batchnorm_leakyrelu(tensor, filters=filters, kernel_size=(1,1), strides=1)\n",
    "        x = conv_batchnorm_leakyrelu(x, filters=filters, kernel_size=(3,3), strides=1)\n",
    "        x = Conv2D(filters=4*filters, kernel_size=(1,1), strides=1)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Add()([tensor, x])\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def resnet_block(x, filters, reps, strides):\n",
    "        \"\"\"\n",
    "        x = previous tensor\n",
    "        filters = number of filters in each 2-D convolution layer\n",
    "        reps = repeatation of total resnet block [1st rep -> Project; (reps-1) rep -> Identitiy]\n",
    "        strides = stride in convolution layer\n",
    "        \"\"\"\n",
    "        \n",
    "        x = projection_block(x, filters, strides)\n",
    "        for _ in range(reps-1):\n",
    "            x = identity_block(x, filters)\n",
    "        return x \n",
    "    \n",
    "    \n",
    "    # input-layer\n",
    "    input = Input(shape=dim)\n",
    "    \n",
    "    # feature-extraction\n",
    "    x = conv_batchnorm_leakyrelu(input, filters=64, kernel_size=(7,7), strides=2)\n",
    "    x = MaxPool2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "    x = resnet_block(x, filters=64, reps=3, strides=1)\n",
    "    x = resnet_block(x, filters=128, reps=4, strides=2)\n",
    "    x = resnet_block(x, filters=256, reps=6, strides=2)\n",
    "    x = resnet_block(x, filters=512, reps=3, strides=2)\n",
    "\n",
    "    # 3D->1D\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # output-layer\n",
    "    output = Dense(output_neurons, output_activation)(x)  \n",
    "    \n",
    "    # MODEL\n",
    "    model = Model(inputs = input, outputs = output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseNet121(dim, output_neurons, output_activation):\n",
    "    \"\"\"\n",
    "    dim = dimension of input tensor\n",
    "    output_neurons = number of neurons in output layers i.e. number of classes\n",
    "    output_activation = activation in output layer\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nTRAINING ON DenseNet121 MODEL:-\")\n",
    "    \n",
    "    def batchnorm_leakyrelu_conv(x, filters, kernel_size):\n",
    "        \"\"\"\n",
    "        x = previous tensor\n",
    "        filters = number of filters in each 2-D convolution layer\n",
    "        kernel_size = kernel_size\n",
    "        \"\"\"\n",
    "        \n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
    "        return x\n",
    "    \n",
    "    def dense_block(tensor, k, reps):\n",
    "        \"\"\"\n",
    "        tensor = previous tensor\n",
    "        k = integer coefficient of number of filters\n",
    "        reps = repeatation of bn_rl_conv block\n",
    "        \"\"\"\n",
    "        \n",
    "        for _ in range(reps):\n",
    "            x = batchnorm_leakyrelu_conv(tensor, filters=4*k, kernel_size=1)\n",
    "            x = batchnorm_leakyrelu_conv(x, filters=k, kernel_size=3)\n",
    "            tensor = Concatenate()([tensor, x])\n",
    "        return tensor\n",
    "    \n",
    "    def transition_layer(x, theta):\n",
    "        \"\"\"\n",
    "        x = previous tensor\n",
    "        theta = a fraction by which number of filters should be reduced\n",
    "        \"\"\"\n",
    "        \n",
    "        f = int(tf.keras.backend.int_shape(x)[-1]*theta)\n",
    "        x = batchnorm_leakyrelu_conv(x, filters=f, kernel_size=1)\n",
    "        x = AvgPool2D(pool_size=2, strides=2, padding='same')(x)\n",
    "        return x \n",
    "    \n",
    "    k = 32\n",
    "    theta = 0.5\n",
    "    repetitions = 6, 12, 24, 16\n",
    "\n",
    "    input = Input(shape=dim)\n",
    "\n",
    "    x = Conv2D(2*k, 7, strides=2, padding='same')(input)\n",
    "    x = MaxPool2D(3, strides=2, padding='same')(x)\n",
    "\n",
    "    for reps in repetitions:\n",
    "        d = dense_block(x, k, reps)\n",
    "        x = transition_layer(d,theta)\n",
    "\n",
    "    x = GlobalAvgPool2D()(d)\n",
    "\n",
    "    output = Dense(output_neurons, output_activation)(x)  \n",
    "\n",
    "    model = Model(inputs = input, outputs = output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xception(dim, output_neurons, output_activation):\n",
    "    \"\"\"\n",
    "    dim = dimension of input tensor\n",
    "    output_neurons = number of neurons in output layers i.e. number of classes\n",
    "    output_activation = activation in output layer\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nTRAINING ON Xception MODEL:-\")\n",
    "    \n",
    "    def conv_bn(x, filters, kernel_size, strides=1):\n",
    "        \"\"\"\n",
    "        x = previous tensor\n",
    "        filters = number of filters in each 2-D convolution layer\n",
    "        kernel_size = kernel_size\n",
    "        strides = stride in convolution layer\n",
    "        \"\"\"\n",
    "        \n",
    "        x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        return x\n",
    "\n",
    "    def sep_conv_bn(x, filters, kernel_size, strides=1):\n",
    "        \"\"\"\n",
    "        x = previous tensor\n",
    "        filters = number of filters in each 2-D convolution layer\n",
    "        kernel_size = kernel_size\n",
    "        strides = stride in convolution layer\n",
    "        \"\"\"\n",
    "        \n",
    "        x = SeparableConv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        return x\n",
    "\n",
    "    def entry_flow(x):\n",
    "        \"\"\"\n",
    "        x = previous tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        x = conv_bn(x, filters=32, kernel_size=3, strides=2)\n",
    "        x = ReLU()(x)\n",
    "        x = conv_bn(x, filters=64, kernel_size=3)\n",
    "        tensor = ReLU()(x)\n",
    "\n",
    "        x = sep_conv_bn(tensor, filters=128, kernel_size=3)\n",
    "        x = ReLU()(x)\n",
    "        x = sep_conv_bn(x, filters=128, kernel_size=3)\n",
    "        x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "        tensor = conv_bn(tensor, filters=128, kernel_size=1, strides=2)\n",
    "\n",
    "        x = Add()([tensor,x])\n",
    "\n",
    "        x = ReLU()(x)\n",
    "        x = sep_conv_bn(x, filters=256, kernel_size=3)\n",
    "        x = ReLU()(x)\n",
    "        x = sep_conv_bn(x, filters=256, kernel_size=3)\n",
    "        x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "        tensor = conv_bn(tensor, filters=256, kernel_size=1, strides=2)\n",
    "\n",
    "        x = Add()([tensor,x])\n",
    "\n",
    "        x = ReLU()(x)\n",
    "        x = sep_conv_bn(x, filters=728, kernel_size=3)\n",
    "        x = ReLU()(x)\n",
    "        x = sep_conv_bn(x, filters=728, kernel_size=3)\n",
    "        x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "        tensor = conv_bn(tensor, filters=728, kernel_size=1, strides=2)\n",
    "\n",
    "        x = Add()([tensor,x])\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def middle_flow(tensor):\n",
    "        \"\"\"\n",
    "        tensor = previous tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        for _ in range(8):\n",
    "            x = ReLU()(tensor)\n",
    "            x = sep_conv_bn(x, filters=728, kernel_size=3)\n",
    "            x = ReLU()(x)\n",
    "            x = sep_conv_bn(x, filters=728, kernel_size=3)\n",
    "            x = ReLU()(x)\n",
    "            x = sep_conv_bn(x, filters=728, kernel_size=3)\n",
    "            \n",
    "            tensor = Add()([tensor,x])\n",
    "\n",
    "        return tensor       \n",
    "    \n",
    "    def exit_flow(tensor):\n",
    "        \"\"\"\n",
    "        tensor = previous tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        x = ReLU()(tensor)\n",
    "        x = sep_conv_bn(x, filters=728, kernel_size=3)\n",
    "        x = ReLU()(x)\n",
    "        x = sep_conv_bn(x, filters=1024, kernel_size=3)\n",
    "        x = MaxPool2D(3, strides=2, padding='same')(x)\n",
    "\n",
    "        tensor = conv_bn(tensor, filters=1024, kernel_size=1, strides=2)\n",
    "\n",
    "        x = Add()([tensor,x])\n",
    "\n",
    "        x = sep_conv_bn(x, filters=1536, kernel_size=3)\n",
    "        x = ReLU()(x)\n",
    "        x = sep_conv_bn(x, filters=2048, kernel_size=3)\n",
    "        x = ReLU()(x)    \n",
    "\n",
    "        x = GlobalAvgPool2D()(x)\n",
    "\n",
    "        x = Dense(output_neurons, output_activation)(x)  \n",
    "\n",
    "        return x\n",
    "\n",
    "    input = Input(shape=dim)\n",
    "\n",
    "    x = entry_flow(input)\n",
    "    x = middle_flow(x)\n",
    "    output = exit_flow(x)\n",
    "\n",
    "    model = Model(inputs = input, outputs = output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = int(input(\"Image Dimension(H or W): \"))\n",
    "w = h\n",
    "dim = (h,w,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_neurons = int(input(\"Number of classes: \"))\n",
    "\n",
    "if output_neurons > 1:\n",
    "    output_activation = 'softmax'\n",
    "else:\n",
    "    output_activation = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Press 1 for VGGNet\")\n",
    "print(\"Press 2 for MobileNet\")\n",
    "print(\"Press 3 for Inception\")\n",
    "print(\"Press 4 for ResNet50\")\n",
    "print(\"Press 5 for DenseNet121\")\n",
    "print(\"Press 6 for Xception\")\n",
    "\n",
    "model_select = int(input(\"\\nChoose model: \"))\n",
    "\n",
    "if model_select == 1:\n",
    "    model = VGGNet(dim, output_neurons, output_activation)\n",
    "if model_select == 2:\n",
    "    model = MobileNet(dim, output_neurons, output_activation)\n",
    "if model_select == 3:\n",
    "    model = Inception(dim, output_neurons, output_activation)\n",
    "if model_select == 4:\n",
    "    model = ResNet50(dim, output_neurons, output_activation)\n",
    "if model_select == 5:\n",
    "    model = DenseNet121(dim, output_neurons, output_activation)\n",
    "if model_select == 6:\n",
    "    model = Xception(dim, output_neurons, output_activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(\n",
    "    model,\n",
    "#     to_file=\"model.png\",\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\", # TB -> Vertical; LR -> Horizontal\n",
    "    expand_nested=False,\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
