{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if physical_devices != []:\n",
    "    print(\"Using GPU\")\n",
    "    for i in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(i, True)\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16():\n",
    "    print(\"\\nTRAINING ON VGG16 MODEL:-\")\n",
    "\n",
    "    full_model = tf.keras.applications.VGG16(input_shape = (224,224,3), weights = 'imagenet', include_top = True)\n",
    "    full_model.summary()\n",
    "    \n",
    "    no_d_layers = int(input('Dense with activation + Dropout for desnse layer = 1 dense layer \\nHow many of such dense layers you want to use ? '))\n",
    "    d_neurons = int(input('Enter no.of neurons you want to use in 1st dense layer: '))\n",
    "    d_dropout = int(input('Enter dropout rate for dense layer: '))/100\n",
    "    \n",
    "    base_model = tf.keras.applications.VGG16(input_shape = dim, weights = 'imagenet', include_top = False)\n",
    "\n",
    "    x = base_model.output\n",
    "    \n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    \n",
    "    m, n = 0, 0\n",
    "    for d in range(no_d_layers):\n",
    "        m = 2**d\n",
    "        n = d_neurons//m\n",
    "        x = Dense(n, kernel_regularizer=l2(lambd), bias_regularizer=l2(lambd))(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Dropout(d_dropout)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "    \n",
    "    predictions = Dense(output_neurons, activation = output_activation)(x)  \n",
    "\n",
    "    model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "    train_base_model = str(input(\"Do you want to extract features using VGG16?(Y/N) \"))\n",
    "    if train_base_model.upper() == 'Y':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    elif train_base_model.upper() == 'N':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG19():\n",
    "    print(\"\\nTRAINING ON VGG19 MODEL:-\")\n",
    "\n",
    "    full_model = tf.keras.applications.VGG19(input_shape = (224,224,3), weights = 'imagenet', include_top = True)\n",
    "    full_model.summary()\n",
    "    \n",
    "    no_d_layers = int(input('Dense with activation + Dropout for desnse layer = 1 dense layer \\nHow many of such dense layers you want to use ? '))\n",
    "    d_neurons = int(input('Enter no.of neurons you want to use in 1st dense layer: '))\n",
    "    d_dropout = int(input('Enter dropout rate for dense layer: '))/100\n",
    "    \n",
    "    base_model = tf.keras.applications.VGG19(input_shape = dim, weights = 'imagenet', include_top = False)\n",
    "\n",
    "    x = base_model.output\n",
    "    \n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    \n",
    "    m, n = 0, 0\n",
    "    for d in range(no_d_layers):\n",
    "        m = 2**d\n",
    "        n = d_neurons//m\n",
    "        x = Dense(n, kernel_regularizer=l2(lambd), bias_regularizer=l2(lambd))(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Dropout(d_dropout)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "    \n",
    "    predictions = Dense(output_neurons, activation = output_activation)(x)  \n",
    "\n",
    "    model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "    train_base_model = str(input(\"Do you want to extract features using VGG19?(Y/N) \"))\n",
    "    if train_base_model.upper() == 'Y':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    elif train_base_model.upper() == 'N':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MobileNet():\n",
    "    print(\"\\nTRAINING ON MobileNet MODEL:-\")\n",
    "\n",
    "    full_model = tf.keras.applications.MobileNet(input_shape = (224,224,3), \n",
    "                                                 weights = 'imagenet', \n",
    "                                                 include_top = True)\n",
    "    full_model.summary()\n",
    "    \n",
    "    no_d_layers = int(input('Dense with activation + Dropout for desnse layer = 1 dense layer \\nHow many of such dense layers you want to use ? '))\n",
    "    d_neurons = int(input('Enter no.of neurons you want to use in 1st dense layer: '))\n",
    "    d_dropout = int(input('Enter dropout rate for dense layer: '))/100\n",
    "    \n",
    "    base_model = tf.keras.applications.MobileNet(input_shape = dim, weights = 'imagenet', include_top = False)\n",
    "\n",
    "    x = base_model.output\n",
    "    \n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    \n",
    "    m, n = 0, 0\n",
    "    for d in range(no_d_layers):\n",
    "        m = 2**d\n",
    "        n = d_neurons//m\n",
    "        x = Dense(n, kernel_regularizer=l2(lambd), bias_regularizer=l2(lambd))(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Dropout(d_dropout)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "    \n",
    "    predictions = Dense(output_neurons, activation = output_activation)(x)  \n",
    "\n",
    "    model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "    train_base_model = str(input(\"Do you want to extract features using MobileNet?(Y/N) \"))\n",
    "    if train_base_model.upper() == 'Y':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    elif train_base_model.upper() == 'N':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50():\n",
    "    print(\"\\nTRAINING ON ResNet50 MODEL:-\")\n",
    "\n",
    "    full_model = tf.keras.applications.ResNet50(input_shape = (224,224,3), weights = 'imagenet', include_top = True)\n",
    "    full_model.summary()\n",
    "    \n",
    "    no_d_layers = int(input('Dense with activation + Dropout for desnse layer = 1 dense layer \\nHow many of such dense layers you want to use ? '))\n",
    "    d_neurons = int(input('Enter no.of neurons you want to use in 1st dense layer: '))\n",
    "    d_dropout = int(input('Enter dropout rate for dense layer: '))/100\n",
    "    \n",
    "    base_model = tf.keras.applications.ResNet50(input_shape = dim, weights = 'imagenet', include_top = False)\n",
    "\n",
    "    x = base_model.output\n",
    "    \n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    \n",
    "    m, n = 0, 0\n",
    "    for d in range(no_d_layers):\n",
    "        m = 2**d\n",
    "        n = d_neurons//m\n",
    "        x = Dense(n, kernel_regularizer=l2(lambd), bias_regularizer=l2(lambd))(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Dropout(d_dropout)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "    \n",
    "    predictions = Dense(output_neurons, activation = output_activation)(x)  \n",
    "\n",
    "    model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "    train_base_model = str(input(\"Do you want to extract features using ResNet50?(Y/N) \"))\n",
    "    if train_base_model.upper() == 'Y':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    elif train_base_model.upper() == 'N':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionV3():\n",
    "    print(\"\\nTRAINING ON InceptionV3 MODEL:-\")\n",
    "    \n",
    "    full_model = tf.keras.applications.InceptionV3(input_shape = (299,299,3), weights = 'imagenet', include_top = True)\n",
    "    full_model.summary()\n",
    "    \n",
    "    no_d_layers = int(input('Dense with activation + Dropout for desnse layer = 1 dense layer \\nHow many of such dense layers you want to use ? '))\n",
    "    d_neurons = int(input('Enter no.of neurons you want to use in 1st dense layer: '))\n",
    "    d_dropout = int(input('Enter dropout rate for dense layer: '))/100\n",
    "    \n",
    "    base_model = tf.keras.applications.InceptionV3(input_shape = dim, weights = 'imagenet', include_top = False)\n",
    "\n",
    "    x = base_model.output\n",
    "    \n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    \n",
    "    m, n = 0, 0\n",
    "    for d in range(no_d_layers):\n",
    "        m = 2**d\n",
    "        n = d_neurons//m\n",
    "        x = Dense(n, kernel_regularizer=l2(lambd), bias_regularizer=l2(lambd))(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Dropout(d_dropout)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "    \n",
    "    predictions = Dense(output_neurons, activation = output_activation)(x)  \n",
    "\n",
    "    model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "    train_base_model = str(input(\"Do you want to extract features using InceptionV3?(Y/N) \"))\n",
    "    if train_base_model.upper() == 'Y':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    elif train_base_model.upper() == 'N':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseNet121():\n",
    "    print(\"\\nTRAINING ON DenseNet121 MODEL:-\")\n",
    "    \n",
    "    full_model = tf.keras.applications.DenseNet121(input_shape = (224,224,3), weights = 'imagenet', include_top = True)\n",
    "    full_model.summary()\n",
    "    \n",
    "    no_d_layers = int(input('Dense with activation + Dropout for desnse layer = 1 dense layer \\nHow many of such dense layers you want to use ? '))\n",
    "    d_neurons = int(input('Enter no.of neurons you want to use in 1st dense layer: '))\n",
    "    d_dropout = int(input('Enter dropout rate for dense layer: '))/100\n",
    "    \n",
    "    base_model = tf.keras.applications.DenseNet121(input_shape = dim, weights = 'imagenet', include_top = False)\n",
    "\n",
    "    x = base_model.output\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    m, n = 0, 0\n",
    "    for d in range(no_d_layers):\n",
    "        m = 2**d\n",
    "        n = d_neurons//m\n",
    "        x = Dense(n, kernel_regularizer=l2(lambd), bias_regularizer=l2(lambd))(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Dropout(d_dropout)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "    \n",
    "    predictions = Dense(output_neurons, activation = output_activation)(x)  \n",
    "\n",
    "    model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "    train_base_model = str(input(\"Do you want to extract features using DenseNet121?(Y/N) \"))\n",
    "    if train_base_model.upper() == 'Y':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    elif train_base_model.upper() == 'N':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xception():\n",
    "    print(\"\\nTRAINING ON Xception MODEL:-\")\n",
    "\n",
    "    full_model = tf.keras.applications.Xception(input_shape = (299,299,3), weights = 'imagenet', include_top = True)\n",
    "    full_model.summary()\n",
    "    \n",
    "    no_d_layers = int(input('Dense with activation + Dropout for desnse layer = 1 dense layer \\nHow many of such dense layers you want to use ? '))\n",
    "    d_neurons = int(input('Enter no.of neurons you want to use in 1st dense layer: '))\n",
    "    d_dropout = int(input('Enter dropout rate for dense layer: '))/100\n",
    "    \n",
    "    base_model = tf.keras.applications.Xception(input_shape = dim, weights = 'imagenet', include_top = False)\n",
    "\n",
    "    x = base_model.output\n",
    "    \n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    \n",
    "    m, n = 0, 0\n",
    "    for d in range(no_d_layers):\n",
    "        m = 2**d\n",
    "        n = d_neurons//m\n",
    "        x = Dense(n, kernel_regularizer=l2(lambd), bias_regularizer=l2(lambd))(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Dropout(d_dropout)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "    \n",
    "    predictions = Dense(output_neurons, activation = output_activation)(x)    \n",
    "\n",
    "    model = Model(inputs = base_model.input, outputs=predictions)\n",
    "\n",
    "    train_base_model = str(input(\"Do you want to extract features using Xception?(Y/N) \"))\n",
    "    if train_base_model.upper() == 'Y':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "    elif train_base_model.upper() == 'N':\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classical_Model():\n",
    "    no_layers = int(input('Conv2d with activation + Max-pool + Dropout for feature extraction = 1 feature extraction layer \\nHow many of such feature extraction layers you want to use ? '))    \n",
    "    no_conv = int(input('How many conv2d layers you want to use in each feature extraction layer ? '))\n",
    "    no_filters = int(input('Put no. of filters in 1st conv2d layer: '))\n",
    "    size_filter = int(input('Enter size of filter (width or height): '))\n",
    "    f_dropout = int(input('Enter dropout rate for feature extraction: '))/100\n",
    "    \n",
    "    no_d_layers = int(input('Dense with activation + Dropout for desnse layer = 1 dense layer \\nHow many of such dense layers you want to use ? '))\n",
    "    d_neurons = int(input('Enter no.of neurons you want to use in 1st dense layer: '))\n",
    "    d_dropout = int(input('Enter dropout rate for dense layer: '))/100\n",
    "            \n",
    "    \n",
    "    model = Sequential(name = 'CUSTOM')\n",
    "    \n",
    "    \n",
    "    # feature extraction\n",
    "    m, n = 0, 0 # m = increamental factor of no. of filters, # n = total no. of filters in convolution layer\n",
    "    for l in range(no_layers):\n",
    "        m = 2**l  \n",
    "        n = no_filters*m \n",
    "        for i in range(no_conv):\n",
    "            model.add(Conv2D(n, \n",
    "                             (size_filter,size_filter), \n",
    "                             kernel_regularizer=l2(lambd), \n",
    "                             bias_regularizer=l2(lambd),\n",
    "                             padding = 'same', \n",
    "                             input_shape = dim))\n",
    "            model.add(LeakyReLU())\n",
    "        model.add(MaxPooling2D(2, 2))\n",
    "        model.add(Dropout(f_dropout))\n",
    "    \n",
    "    \n",
    "    # flatten\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    \n",
    "    # dense layer\n",
    "    m, n = 0, 0\n",
    "    for d in range(no_d_layers):\n",
    "        m = 2**d\n",
    "        n = d_neurons//m\n",
    "        model.add(Dense(n, kernel_regularizer=l2(lambd), bias_regularizer=l2(lambd)))\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(d_dropout))\n",
    "    model.add(Dense(output_neurons, output_activation))\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaded_model():\n",
    "    model_address = input(\"Model address: \")\n",
    "    model = load_model(model_address)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = int(input(\"Image Dimension(H or W): \"))\n",
    "w = h\n",
    "dim = (h,w,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_neurons = int(input(\"Number of classes: \"))\n",
    "\n",
    "if output_neurons > 1:\n",
    "    output_activation = 'softmax'\n",
    "else:\n",
    "    output_activation = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Press 1 for VGG16\")\n",
    "print(\"Press 2 for VGG19\")\n",
    "print(\"Press 3 for MobileNet\")\n",
    "print(\"Press 4 for InceptionV3\")\n",
    "print(\"Press 5 for ResNet\")\n",
    "print(\"Press 6 for DenseNet121\")\n",
    "print(\"Press 7 for Xception\")\n",
    "print(\"Press 8 for custom model\")\n",
    "print(\"Press 9 to load existing model\")\n",
    "\n",
    "model_select = int(input(\"\\nChoose model: \"))\n",
    "\n",
    "if model_select == 1:\n",
    "    model = VGG16()\n",
    "if model_select == 2:\n",
    "    model = VGG19()\n",
    "if model_select == 3:\n",
    "    model = MobileNet()\n",
    "if model_select == 4:\n",
    "    model = InceptionV3()\n",
    "if model_select == 5:\n",
    "    model = ResNet50()\n",
    "if model_select == 6:\n",
    "    model = DenseNet121()\n",
    "if model_select == 7:\n",
    "    model = Xception()\n",
    "if model_select == 8:\n",
    "    model = Custom_Model()\n",
    "if model_select == 9:\n",
    "    model = loaded_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
