{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100000000000000<float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import matplotlib\n",
    "import glob\n",
    "import operator\n",
    "import psutil\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if physical_devices != []:\n",
    "    print(\"Using GPU\")\n",
    "    for i in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(i, True)\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/mnt/87433d53-66f3-438e-a7f4-fc990fe61283/PROJECTS/JRF/sound-classification/specs'\n",
    "classify_train = os.path.join(root_dir, 'classify train')\n",
    "\n",
    "train_directory = os.path.join(classify_train, 'training')\n",
    "validation_directory = os.path.join(classify_train, 'validation')\n",
    "test_directory = os.path.join(classify_train, 'testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory, validation_directory, test_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter setting-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = float(input(\"Enter the initial learning rate: \"))\n",
    "epoch = int(input(\"Enter the maximum number of epochs: \"))\n",
    "batch_size = int(input(\"Enter batch size: \"))\n",
    "lambd = float(input(\"Enter lambda for L2 regularization: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characteristics folder\n",
    "Creating a seperate folder where 'classify train' belongs to store model and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_name = str(input(\"Enter name of the characteristics folder: \"))\n",
    "\n",
    "char = os.path.join(root_dir, char_name)\n",
    "\n",
    "if not os.path.exists(char):\n",
    "    os.mkdir(char)\n",
    "else:\n",
    "    replace = str(input(\"Folder already exists ! Do you want to replace it ?(Y/N) \"))\n",
    "    if replace.upper() == 'Y':      \n",
    "        shutil.rmtree(char)\n",
    "        os.mkdir(char)\n",
    "    elif replace.upper() == 'N':\n",
    "        print('\\nThe following folders already exist:')\n",
    "        for i in os.listdir(root_dir): \n",
    "            print(i)\n",
    "        char_name = str(input(\"\\nEnter a new name of the characteristics folder: \"))\n",
    "        char = os.path.join(root_dir, char_name)\n",
    "        if not os.path.exists(char):\n",
    "            os.mkdir(char)\n",
    "        else:\n",
    "            print(f\"{char_name} replaced\")\n",
    "            shutil.rmtree(char)\n",
    "            os.mkdir(char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 10 # change steps to 1 to apply exponential decay\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return learning_rate * (0.1 ** int(epoch / steps))\n",
    "    \n",
    "best_model_address = os.path.join(char, 'best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = int(input(\"Press 1 to monitor Validation Accuracy\\nPress 2 to monitor Validation Loss\\nPress 3 to monitor Training Accuracy\\nPress 4 to monitor Training Loss\\n\"))\n",
    "patience = int(input('Enter number of epochs that will produce monitored quantity with no improvement after which training will be stopped: '))\n",
    "\n",
    "\n",
    "if monitor == 1:\n",
    "    metric = 'val_accuracy'\n",
    "    mode = 'max'\n",
    "    print(\"\\nMONITORING VALIDATION ACCURACY..........\\n\")\n",
    "\n",
    "elif monitor == 2:\n",
    "    metric = 'val_loss'\n",
    "    mode = 'min'\n",
    "    print(\"\\nMONITORING VALIDATION LOSS..........\\n\")\n",
    "\n",
    "elif monitor == 3:\n",
    "    metric = 'accuracy'\n",
    "    mode = 'max'\n",
    "    print(\"\\nMONITORING TRAINING ACCURACY..........\\n\")\n",
    "\n",
    "elif monitor == 4:\n",
    "    metric = 'loss'\n",
    "    mode = 'min'\n",
    "    print(\"\\nMONITORING TRAINING LOSS..........\\n\")\n",
    "\n",
    "callback = [keras.callbacks.LearningRateScheduler(lr_schedule, verbose = 1),\n",
    "            keras.callbacks.EarlyStopping(monitor = metric, min_delta = 0.001, patience = patience, verbose=1, mode = mode, restore_best_weights = True),\n",
    "            keras.callbacks.ModelCheckpoint(best_model_address, monitor = metric, verbose=1, save_best_only=True, save_weights_only=False, mode = mode)]\n",
    "\n",
    "print(f\"\\nTraining will stop if {metric} doesn't show any improvements for {patience} epcohs\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classical_cnn(dim, output_neurons, output_activation):\n",
    "    print(\"\\nTRAINING ON classical_cnn MODEL:-\")\n",
    "    \n",
    "    \n",
    "    def block(tensor, conv_reps, n_filters):\n",
    "        x = Conv2D(filters = n_filters, kernel_size = (3,3), padding = 'same')(tensor)\n",
    "        x = LeakyReLU()(x)\n",
    "        \n",
    "        for i in range(conv_reps-1):\n",
    "            x = Conv2D(filters = n_filters, kernel_size = (3,3), padding = 'same')(x)\n",
    "            x = LeakyReLU()(x)\n",
    "            \n",
    "        x = MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'same')(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    input = Input(shape = dim)\n",
    "        \n",
    "    k = 8\n",
    "    x = block(input, conv_reps = 1, n_filters = k)\n",
    "    x = block(x, conv_reps = 1, n_filters = 2*k)\n",
    "    x = block(x, conv_reps = 1, n_filters = 4*k)\n",
    "    x = block(x, conv_reps = 1, n_filters = 8*k)\n",
    "    x = block(x, conv_reps = 1, n_filters = 16*k)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    dense_reps = 1\n",
    "    \n",
    "    for i in range(dense_reps):\n",
    "        x = Dense(128)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "    \n",
    "    output = Dense(output_neurons, output_activation)(x)  \n",
    "    \n",
    "    model = Model(inputs = input, outputs = output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_no = len(os.listdir(train_directory))\n",
    "\n",
    "print(\"This is a \" + str(class_no) + \"-Class Classification\")\n",
    "\n",
    "if class_no <= 2:\n",
    "    class_mode = 'binary'\n",
    "    output_activation = 'sigmoid'\n",
    "    output_neurons = 1\n",
    "    losses = 'binary_crossentropy'\n",
    "\n",
    "else:\n",
    "    class_mode = 'categorical'\n",
    "    output_activation = 'softmax'\n",
    "    output_neurons = class_no\n",
    "    losses = 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_selection():\n",
    "    print(\"\\nSelect a optimizer which will reduce the loss of the model.\\n\")\n",
    "\n",
    "    optimizer_select = int(input(\"Press 1 to select Stochastic Gradient Descent\\nPress 2 to select RMSprop\\nPress 3 to select Adagrad\\nPress 4 to select Adadelta\\nPress 5 to select Adam\\nPress 6 to select Adamax\\nPress 7 to select Nadam\\n\"))\n",
    "\n",
    "    if optimizer_select == 1:\n",
    "        optimizer = SGD(lr = learning_rate, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "\n",
    "    elif optimizer_select == 2:\n",
    "        optimizer = RMSprop(learning_rate, rho = 0.9)\n",
    "\n",
    "    elif optimizer_select == 3:\n",
    "        optimizer = Adagrad(learning_rate)\n",
    "\n",
    "    elif optimizer_select == 4:\n",
    "        optimizer = Adadelta(learning_rate, rho = 0.95)\n",
    "\n",
    "    elif optimizer_select == 5:\n",
    "        optimizer = Adam(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\n",
    "\n",
    "    elif optimizer_select == 6:\n",
    "        optimizer = Adamax(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999)\n",
    "\n",
    "    elif optimizer_select == 7:\n",
    "        optimizer = Nadam(learning_rate = learning_rate, beta_1 = 0.9, beta_2 = 0.999)\n",
    "   \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = int(input(\"Image Dimension(H or W): \"))\n",
    "w = h\n",
    "color = int(input(\"Press 1 for RGB \\nPress 2 for Grayscale \"))\n",
    "if color == 1:\n",
    "    color_mode = 'rgb'\n",
    "    dim = (h,w,3)\n",
    "elif color == 2:\n",
    "    color_mode = 'grayscale'\n",
    "    dim = (h,w,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "train_generator = train_datagen.flow_from_directory(train_directory,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    class_mode = class_mode,\n",
    "                                                    color_mode = color_mode,\n",
    "                                                    target_size = (h,w),\n",
    "                                                    shuffle=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_directory,\n",
    "                                                              batch_size = batch_size,\n",
    "                                                              class_mode = class_mode,\n",
    "                                                              color_mode = color_mode,\n",
    "                                                              target_size = (h,w),\n",
    "                                                              shuffle=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "test_generator = test_datagen.flow_from_directory(test_directory,\n",
    "                                                  batch_size = batch_size,\n",
    "                                                  class_mode = class_mode,\n",
    "                                                  color_mode = color_mode,\n",
    "                                                  target_size = (h,w),\n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizer_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = classical_cnn(dim, output_neurons, output_activation)\n",
    "model.compile(optimizer = optimizer, loss = losses, metrics = ['accuracy', \n",
    "                                                               tf.keras.metrics.Precision(), \n",
    "                                                               tf.keras.metrics.Recall(), \n",
    "                                                               tf.keras.metrics.TruePositives(), \n",
    "                                                               tf.keras.metrics.TrueNegatives(), \n",
    "                                                               tf.keras.metrics.FalsePositives(),\n",
    "                                                               tf.keras.metrics.FalseNegatives()])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    start = time.time()\n",
    "    history = model.fit(train_generator,\n",
    "                        epochs = epoch,\n",
    "                        verbose = 1,\n",
    "                        callbacks = callback,\n",
    "                        validation_data = validation_generator,\n",
    "                        shuffle=True)\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    duration = end-start\n",
    "\n",
    "train_score = model.evaluate(train_generator)\n",
    "val_score = model.evaluate(validation_generator)\n",
    "test_score = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Execution Time: {} seconds\".format(duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot characteristic curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "epochs=range(len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'r', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title('Training and validation accuracy vs Epochs')\n",
    "plt.legend()\n",
    "\n",
    "fig_name_eps = \"accuracy.eps\"\n",
    "fig_name_jpg = \"accuracy.jpg\"\n",
    "\n",
    "plt.savefig(os.path.join(char, fig_name_eps))\n",
    "plt.savefig(os.path.join(char, fig_name_jpg))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title('Training and validation loss vs Epochs')\n",
    "plt.legend()\n",
    "\n",
    "fig_name_eps = \"loss.eps\"\n",
    "fig_name_jpg = \"loss.jpg\"\n",
    "\n",
    "plt.savefig(os.path.join(char, fig_name_eps))\n",
    "plt.savefig(os.path.join(char, fig_name_jpg))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'r', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title('Training and validation loss vs Epochs')\n",
    "plt.legend()\n",
    "\n",
    "fig_name_eps = \"char.eps\"\n",
    "fig_name_jpg = \"char.jpg\"\n",
    "\n",
    "plt.savefig(os.path.join(char, fig_name_eps))\n",
    "plt.savefig(os.path.join(char, fig_name_jpg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = train_score[1]*100\n",
    "validation_accuracy = val_score[1]*100\n",
    "test_accuracy = test_score[1]*100\n",
    "\n",
    "print(\"The training accuracy is: \" + str(training_accuracy) + ' %')\n",
    "print(\"The validation accuracy is: \" + str(validation_accuracy) + ' %')\n",
    "print(\"The test accuracy is: \" + str(test_accuracy) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = test_score[1]*100\n",
    "test_precision = test_score[2]*100\n",
    "test_recall = test_score[3]*100\n",
    "tp = int(test_score[4])\n",
    "tn = int(test_score[5])\n",
    "fp = int(test_score[6])\n",
    "fn = int(test_score[7])\n",
    "\n",
    "f1 = 2*((test_precision*test_recall)/(test_precision+test_recall))\n",
    "sensitivity_k = (tp/(tp+fn))*100\n",
    "specificity_k = (tn/(tn+fp))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Accuracy: {}\".format(test_accuracy))\n",
    "print(\"Test Precision: {}\".format(test_precision))\n",
    "print(\"Test Recall: {}\".format(test_recall))\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "print(\"Test Negetive: {}\".format(tn))\n",
    "print(\"False Positive: {}\".format(fp))\n",
    "print(\"False Negetive: {}\".format(fn))\n",
    "print(\"Sensitivity_k: {}\".format(sensitivity_k))\n",
    "print(\"Specificity_k: {}\".format(specificity_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(y_true, y_pred, labels):\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix \n",
    "    \n",
    "    print(\"Calculating CLASSIFICATION REPORT: \")\n",
    "    classification_reports = classification_report(y_true, y_pred, target_names=labels)\n",
    "    print(classification_reports)\n",
    "\n",
    "    print(\"\\nCalculating SENSITIVITY & SPECIFICITY..........:\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    total = sum(sum(cm))\n",
    "    sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "\n",
    "    print(\"sensitivity = {:.4f}\".format(sensitivity))\n",
    "    print(\"specificity = {:.4f}\".format(specificity))\n",
    "    \n",
    "    return cm, classification_reports, sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat(cm, labels, char, file_name):\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=cm,\n",
    "                                    colorbar=True,\n",
    "                                    show_absolute=True,\n",
    "                                    class_names=labels,\n",
    "                                    show_normed=True)\n",
    "\n",
    "    plt.savefig(os.path.join(char, f'{file_name}.eps'))\n",
    "    plt.savefig(os.path.join(char, f'{file_name}.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = test_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification result (Scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_sklearn(test_directory, test_generator, class_no, best_model_address, dim):\n",
    "    test_class_list = []\n",
    "    for test_name in os.listdir(test_directory):\n",
    "        test = os.path.join(test_directory, test_name)\n",
    "        test_class_list.append(test)\n",
    "    test_class_list.sort()\n",
    "    \n",
    "    print(test_class_list)\n",
    "    \n",
    "    y_true = test_generator.classes\n",
    "    labels = test_generator.class_indices\n",
    "    \n",
    "    y_pred = []\n",
    "    tot = len(os.listdir(test_class_list[1]))*class_no\n",
    "\n",
    "    best_model = load_model(best_model_address)\n",
    "    \n",
    "    with tqdm(total=tot) as pbar:\n",
    "        for i in range(class_no):\n",
    "            for filename in os.listdir(test_class_list[i]):\n",
    "                file = os.path.join(test_class_list[i], filename)\n",
    "                \n",
    "                img = image.load_img(file, target_size=(dim[1], dim[0]))\n",
    "                x = image.img_to_array(img)\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "\n",
    "                im_arr = np.vstack([x])\n",
    "                \n",
    "#                 img = cv2.imread(file)\n",
    "#                 res = cv2.resize(img, (dim[0], dim[1]))\n",
    "#                 normed = res / 255.0\n",
    "#                 im_arr = normed.reshape(1, dim[0], dim[1], dim[2])\n",
    "\n",
    "                pred = best_model.predict(im_arr)\n",
    "                pred_categorical = keras.utils.to_categorical(pred)\n",
    "\n",
    "                if class_no >= 2:\n",
    "                    max_pred = np.argmax(pred)\n",
    "                else:\n",
    "                    max_pred = np.argmax(pred_categorical)\n",
    "\n",
    "                y_pred.append(max_pred)\n",
    "\n",
    "                pbar.set_description(\"Progress\")\n",
    "                pbar.update()\n",
    "                \n",
    "    return y_true, y_pred, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred, labels = pred_sklearn(test_directory, test_generator, class_no, best_model_address, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm, classification_reports_sklearn, sensitivity_sklearn, specificity_sklearn = report(y_true, y_pred, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat(cm, labels, char, 'confusion-matrix-sklearn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "\n",
    "readme_name_text = \"readme.txt\"\n",
    "print(f\"Please read the text file named {readme_name_text} for detailed information of the model.\")\n",
    "\n",
    "completeName_txt = os.path.join(char, readme_name_text) \n",
    "\n",
    "readme = open(completeName_txt, \"w\")\n",
    "\n",
    "if len(os.listdir(train_directory)) > 2:\n",
    "    readme.write(f\"This is a {len(os.listdir(train_directory))}-class CLASSIFICATION\")\n",
    "else:\n",
    "    readme.write(\"This is a BINARY CLASSIFICATION\")\n",
    "\n",
    "\n",
    "readme.write(\"\\n\\n--HYPERPARAMETERS--\\n\")\n",
    "readme.write(f\"\\nInitial Learning Rate = {learning_rate}\")\n",
    "readme.write(f\"\\nNo. of epochs = {len(acc)}\")\n",
    "readme.write(f\"\\nBatch Size = {batch_size}\")\n",
    "\n",
    "\n",
    "readme.write(\"\\n\\n--MODEL-PARAMETERS--\")\n",
    "# readme.write(f\"\\nDropout for feature extraction = {(int(f_dropout*100))} %\")\n",
    "# readme.write(f\"\\nDropout for dense layer = {(int(d_dropout*100))} %\")\n",
    "readme.write(f\"\\nOptimizer = {optimizer}\\n\\n\")\n",
    "\n",
    "\n",
    "readme.write(\"Trained on a Custom Prebuilt Model\\n\")\n",
    "# readme.write(f\"\\nFilter size = {size_filter}x{size_filter}\\n\\n\")\n",
    "with redirect_stdout(readme):\n",
    "    model.summary()\n",
    "        \n",
    "    \n",
    "readme.write(\"\\n\\n--MODEL-PERFORMANCE--\")\n",
    "readme.write(f\"\\nTest Accuracy = {test_accuracy} %\")\n",
    "readme.write(f\"\\nTest Precision = {test_precision} %\")\n",
    "readme.write(f\"\\nTest Recall = {test_recall} %\")\n",
    "readme.write(f\"\\nTrue Positive = {tp}\")\n",
    "readme.write(f\"\\nTrue Negetive = {tn}\")\n",
    "readme.write(f\"\\nFalse Positive = {fp}\")\n",
    "readme.write(f\"\\nFalse Negetive = {fn}\")\n",
    "readme.write(f\"\\nSensitivity_k = {sensitivity_k}\")\n",
    "readme.write(f\"\\nSpecificity_k = {specificity_k}\\n\\n\\n\")\n",
    "\n",
    "\n",
    "readme.write(\"\\n\\n--MODEL-CHARACTERISTICS--\")\n",
    "readme.write(f\"\\nacc = {acc}\")\n",
    "readme.write(f\"\\n\\nval_acc = {val_acc}\")\n",
    "readme.write(f\"\\n\\nloss = {loss}\")\n",
    "readme.write(f\"\\n\\nval_loss = {val_loss}\")\n",
    "\n",
    "\n",
    "readme.write(\"\\n\\n--Classification Report Keras--\\n\")\n",
    "readme.write(classification_reports_keras)\n",
    "readme.write(f\"\\nSensitivity = {sensitivity_keras*100} %\")\n",
    "readme.write(f\"\\nSpecificity = {specificity_keras*100} %\")\n",
    "\n",
    "readme.write(\"\\n\\n--Classification Report Scikit-learn--\\n\")\n",
    "readme.write(classification_reports_sklearn)\n",
    "readme.write(f\"\\nSensitivity = {sensitivity_sklearn*100} %\")\n",
    "readme.write(f\"\\nSpecificity = {specificity_sklearn*100} %\")\n",
    "\n",
    "\n",
    "readme.write(f\"\\nExecution Time: {duration} seconds\")\n",
    "\n",
    "readme.write(\"\\n\\nCreated using Self-Regulated Image Classifier using Convolution Neural Network\")\n",
    "\n",
    "readme.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
